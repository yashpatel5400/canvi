{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4212fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inp = \"data/lotka_volterra/train/inputs.npy\"\n",
    "train_oup = \"data/lotka_volterra/train/outputs.npy\"\n",
    "\n",
    "test_inp = \"data/lotka_volterra/test/inputs.npy\"\n",
    "test_oup = \"data/lotka_volterra/test/outputs.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec07cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_theta = torch.Tensor(np.load(train_inp))\n",
    "train_x = torch.Tensor(np.load(train_oup))\n",
    "\n",
    "calibration_size = 10_000\n",
    "test_theta_presplit = np.load(test_inp)\n",
    "test_x_presplit = np.load(test_oup)\n",
    "\n",
    "test_theta = torch.Tensor(test_theta_presplit[:-calibration_size])\n",
    "test_x = torch.Tensor(test_x_presplit[:-calibration_size])\n",
    "\n",
    "calibration_theta = torch.Tensor(test_theta_presplit[-calibration_size:])\n",
    "calibration_x = torch.Tensor(test_x_presplit[-calibration_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.distributions as D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gen_idx = 0\n",
    "\n",
    "def generate_data(n_pts, return_theta=False):\n",
    "    global gen_idx\n",
    "    theta, x = train_theta[gen_idx:gen_idx+n_pts], train_x[gen_idx:gen_idx+n_pts]\n",
    "    gen_idx += n_pts\n",
    "\n",
    "    if return_theta: \n",
    "        return theta, x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca0e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyknos.nflows import flows, transforms\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "from warnings import warn\n",
    "\n",
    "from pyknos.nflows import distributions as distributions_\n",
    "from pyknos.nflows import flows, transforms\n",
    "from pyknos.nflows.nn import nets\n",
    "from pyknos.nflows.transforms.splines import rational_quadratic\n",
    "from torch import Tensor, nn, relu, tanh, tensor, uint8\n",
    "\n",
    "from sbi.utils.sbiutils import (\n",
    "    standardizing_net,\n",
    "    standardizing_transform,\n",
    "    z_score_parser,\n",
    ")\n",
    "from sbi.utils.torchutils import create_alternating_binary_mask\n",
    "from sbi.utils.user_input_checks import check_data_device, check_embedding_net_device\n",
    "\n",
    "class ContextSplineMap(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network from `context` to the spline parameters.\n",
    "    We cannot use the resnet as conditioner to learn each dimension conditioned\n",
    "    on the other dimensions (because there is only one). Instead, we learn the\n",
    "    spline parameters directly. In the case of conditinal density estimation,\n",
    "    we make the spline parameters conditional on the context. This is\n",
    "    implemented in this class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        hidden_features: int,\n",
    "        context_features: int,\n",
    "        hidden_layers: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize neural network that learns to predict spline parameters.\n",
    "        Args:\n",
    "            in_features: Unused since there is no `conditioner` in 1D.\n",
    "            out_features: Number of spline parameters.\n",
    "            hidden_features: Number of hidden units.\n",
    "            context_features: Number of context features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # `self.hidden_features` is only defined such that nflows can infer\n",
    "        # a scaling factor for initializations.\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        # Use a non-linearity because otherwise, there will be a linear\n",
    "        # mapping from context features onto distribution parameters.\n",
    "\n",
    "        # Initialize with input layer.\n",
    "        layer_list = [nn.Linear(context_features, hidden_features), nn.ReLU()]\n",
    "        # Add hidden layers.\n",
    "        layer_list += [\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.ReLU(),\n",
    "        ] * hidden_layers\n",
    "        # Add output layer.\n",
    "        layer_list += [nn.Linear(hidden_features, out_features)]\n",
    "        self.spline_predictor = nn.Sequential(*layer_list)\n",
    "\n",
    "    def __call__(self, inputs: Tensor, context: Tensor, *args, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return parameters of the spline given the context.\n",
    "        Args:\n",
    "            inputs: Unused. It would usually be the other dimensions, but in\n",
    "                1D, there are no other dimensions.\n",
    "            context: Context features.\n",
    "        Returns:\n",
    "            Spline parameters.\n",
    "        \"\"\"\n",
    "        return self.spline_predictor(context)\n",
    "\n",
    "# Declan: this code from SBI library\n",
    "def build_nsf(\n",
    "    batch_x: Tensor,\n",
    "    batch_y: Tensor,\n",
    "    z_score_x: Optional[str] = \"independent\",\n",
    "    z_score_y: Optional[str] = \"independent\",\n",
    "    hidden_features: int = 50,\n",
    "    num_transforms: int = 5,\n",
    "    num_bins: int = 10,\n",
    "    embedding_net: nn.Module = nn.Identity(),\n",
    "    tail_bound: float = 3.0,\n",
    "    hidden_layers_spline_context: int = 1,\n",
    "    num_blocks: int = 2,\n",
    "    dropout_probability: float = 0.0,\n",
    "    use_batch_norm: bool = False,\n",
    "    **kwargs,\n",
    ") -> nn.Module:\n",
    "    \"\"\"Builds NSF p(x|y).\n",
    "    Args:\n",
    "        batch_x: Batch of xs, used to infer dimensionality and (optional) z-scoring.\n",
    "        batch_y: Batch of ys, used to infer dimensionality and (optional) z-scoring.\n",
    "        z_score_x: Whether to z-score xs passing into the network, can be one of:\n",
    "            - `none`, or None: do not z-score.\n",
    "            - `independent`: z-score each dimension independently.\n",
    "            - `structured`: treat dimensions as related, therefore compute mean and std\n",
    "            over the entire batch, instead of per-dimension. Should be used when each\n",
    "            sample is, for example, a time series or an image.\n",
    "        z_score_y: Whether to z-score ys passing into the network, same options as\n",
    "            z_score_x.\n",
    "        hidden_features: Number of hidden features.\n",
    "        num_transforms: Number of transforms.\n",
    "        num_bins: Number of bins used for the splines.\n",
    "        embedding_net: Optional embedding network for y.\n",
    "        tail_bound: tail bound for each spline.\n",
    "        hidden_layers_spline_context: number of hidden layers of the spline context net\n",
    "            for one-dimensional x.\n",
    "        num_blocks: number of blocks used for residual net for context embedding.\n",
    "        dropout_probability: dropout probability for regularization in residual net.\n",
    "        use_batch_norm: whether to use batch norm in residual net.\n",
    "        kwargs: Additional arguments that are passed by the build function but are not\n",
    "            relevant for maf and are therefore ignored.\n",
    "    Returns:\n",
    "        Neural network.\n",
    "    \"\"\"\n",
    "    x_numel = batch_x[0].numel()\n",
    "    # Infer the output dimensionality of the embedding_net by making a forward pass.\n",
    "    check_data_device(batch_x, batch_y)\n",
    "    check_embedding_net_device(embedding_net=embedding_net, datum=batch_y)\n",
    "    y_numel = embedding_net(batch_y[:1]).numel()\n",
    "\n",
    "    # Define mask function to alternate between predicted x-dimensions.\n",
    "    def mask_in_layer(i):\n",
    "        return create_alternating_binary_mask(features=x_numel, even=(i % 2 == 0))\n",
    "\n",
    "    # If x is just a scalar then use a dummy mask and learn spline parameters using the\n",
    "    # conditioning variables only.\n",
    "    if x_numel == 1:\n",
    "        # Conditioner ignores the data and uses the conditioning variables only.\n",
    "        conditioner = partial(\n",
    "            ContextSplineMap,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=y_numel,\n",
    "            hidden_layers=hidden_layers_spline_context,\n",
    "        )\n",
    "    else:\n",
    "        # Use conditional resnet as spline conditioner.\n",
    "        conditioner = partial(\n",
    "            nets.ResidualNet,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=y_numel,\n",
    "            num_blocks=num_blocks,\n",
    "            activation=relu,\n",
    "            dropout_probability=dropout_probability,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "        )\n",
    "\n",
    "    # Stack spline transforms.\n",
    "    transform_list = []\n",
    "    for i in range(num_transforms):\n",
    "        block = [\n",
    "            transforms.PiecewiseRationalQuadraticCouplingTransform(\n",
    "                mask=mask_in_layer(i) if x_numel > 1 else tensor([1], dtype=uint8),\n",
    "                transform_net_create_fn=conditioner,\n",
    "                num_bins=num_bins,\n",
    "                tails=\"linear\",\n",
    "                tail_bound=tail_bound,\n",
    "                apply_unconditional_transform=False,\n",
    "            )\n",
    "        ]\n",
    "        # Add LU transform only for high D x. Permutation makes sense only for more than\n",
    "        # one feature.\n",
    "        if x_numel > 1:\n",
    "            block.append(\n",
    "                transforms.LULinear(x_numel, identity_init=True),\n",
    "            )\n",
    "        transform_list += block\n",
    "\n",
    "    z_score_x_bool, structured_x = z_score_parser(z_score_x)\n",
    "    if z_score_x_bool:\n",
    "        # Prepend standardizing transform to nsf transforms.\n",
    "        transform_list = [\n",
    "            standardizing_transform(batch_x, structured_x)\n",
    "        ] + transform_list\n",
    "\n",
    "    z_score_y_bool, structured_y = z_score_parser(z_score_y)\n",
    "    if z_score_y_bool:\n",
    "        # Prepend standardizing transform to y-embedding.\n",
    "        embedding_net = nn.Sequential(\n",
    "            standardizing_net(batch_y, structured_y), embedding_net\n",
    "        )\n",
    "\n",
    "    distribution = distributions_.StandardNormal((x_numel,))\n",
    "\n",
    "    # Combine transforms.\n",
    "    transform = transforms.CompositeTransform(transform_list)\n",
    "    neural_net = flows.Flow(transform, distribution, embedding_net)\n",
    "\n",
    "    return neural_net\n",
    "\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.context_dim = dim\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Assumes context x is of shape (batch_size, self.context_dim)\n",
    "        '''\n",
    "        return self.dense(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a406aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, x = generate_data(100, return_theta=True) \n",
    "\n",
    "prior = D.Uniform(torch.tensor([-1., -1.]), torch.tensor([1., 1.]))\n",
    "a_dist = D.Uniform(-math.pi/2, math.pi/2)\n",
    "r_dist = D.Normal(0.1, .01)\n",
    "mb_size=100\n",
    "device='cuda:0'\n",
    "kwargs = {'prior': prior,\n",
    "        'a_dist': a_dist,\n",
    "        'r_dist': r_dist}\n",
    "\n",
    "# EXAMPLE BATCH FOR SHAPES\n",
    "z_dim = prior.sample().shape[-1]\n",
    "x_dim = x.shape[-1]\n",
    "num_obs_flow = mb_size\n",
    "fake_zs = torch.randn((mb_size, z_dim))\n",
    "fake_xs = torch.randn((mb_size, x_dim))\n",
    "encoder = build_nsf(fake_zs, fake_xs, z_score_x='none', z_score_y='none')\n",
    "\n",
    "encoder.to(device)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87b099ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss 6.595306396484375\n",
      "Iteration 1: loss 6.940694332122803\n",
      "Iteration 2: loss 10.058188438415527\n",
      "Iteration 3: loss 9.244202613830566\n",
      "Iteration 4: loss 8.401837348937988\n",
      "Iteration 5: loss 8.3871431350708\n",
      "Iteration 6: loss 7.676497459411621\n",
      "Iteration 7: loss 7.38270902633667\n",
      "Iteration 8: loss 7.512493133544922\n",
      "Iteration 9: loss 6.502581596374512\n",
      "Iteration 10: loss 6.163062572479248\n",
      "Iteration 11: loss 6.209468841552734\n",
      "Iteration 12: loss 5.748456954956055\n",
      "Iteration 13: loss 5.551697731018066\n",
      "Iteration 14: loss 5.724434852600098\n",
      "Iteration 15: loss 5.414478778839111\n",
      "Iteration 16: loss 5.426948070526123\n",
      "Iteration 17: loss 5.076007843017578\n",
      "Iteration 18: loss 4.883581161499023\n",
      "Iteration 19: loss 5.005739688873291\n",
      "Iteration 20: loss 5.891821384429932\n",
      "Iteration 21: loss 5.3931884765625\n",
      "Iteration 22: loss 5.335026741027832\n",
      "Iteration 23: loss 5.385631084442139\n",
      "Iteration 24: loss 5.147909641265869\n",
      "Iteration 25: loss 5.879788875579834\n",
      "Iteration 26: loss 4.891725540161133\n",
      "Iteration 27: loss 5.081981658935547\n",
      "Iteration 28: loss 4.857998371124268\n",
      "Iteration 29: loss 4.7902045249938965\n",
      "Iteration 30: loss 4.467832088470459\n",
      "Iteration 31: loss 4.9575300216674805\n",
      "Iteration 32: loss 5.665131568908691\n",
      "Iteration 33: loss 5.131932735443115\n",
      "Iteration 34: loss 5.04434061050415\n",
      "Iteration 35: loss 5.456507682800293\n",
      "Iteration 36: loss 4.273430824279785\n",
      "Iteration 37: loss 5.107813835144043\n",
      "Iteration 38: loss 4.766558647155762\n",
      "Iteration 39: loss 5.452900409698486\n",
      "Iteration 40: loss 5.266603469848633\n",
      "Iteration 41: loss 5.198604583740234\n",
      "Iteration 42: loss 5.739100933074951\n",
      "Iteration 43: loss 5.333102703094482\n",
      "Iteration 44: loss 5.375255107879639\n",
      "Iteration 45: loss 5.30558967590332\n",
      "Iteration 46: loss 4.586801528930664\n",
      "Iteration 47: loss 4.487555027008057\n",
      "Iteration 48: loss 5.4860076904296875\n",
      "Iteration 49: loss 4.819606304168701\n",
      "Iteration 50: loss 4.726752281188965\n",
      "Iteration 51: loss 4.510202407836914\n",
      "Iteration 52: loss 4.364386081695557\n",
      "Iteration 53: loss 4.775356769561768\n",
      "Iteration 54: loss 5.3258957862854\n",
      "Iteration 55: loss 5.381940841674805\n",
      "Iteration 56: loss 4.921587944030762\n",
      "Iteration 57: loss 4.614386081695557\n",
      "Iteration 58: loss 4.836942195892334\n",
      "Iteration 59: loss 5.018539905548096\n",
      "Iteration 60: loss 5.471836566925049\n",
      "Iteration 61: loss 4.664443492889404\n",
      "Iteration 62: loss 4.919434547424316\n",
      "Iteration 63: loss 4.570126533508301\n",
      "Iteration 64: loss 5.150318622589111\n",
      "Iteration 65: loss 4.993154048919678\n",
      "Iteration 66: loss 4.785019874572754\n",
      "Iteration 67: loss 4.8298234939575195\n",
      "Iteration 68: loss 5.311013221740723\n",
      "Iteration 69: loss 5.4667816162109375\n",
      "Iteration 70: loss 5.256484031677246\n",
      "Iteration 71: loss 5.533698558807373\n",
      "Iteration 72: loss 4.902195453643799\n",
      "Iteration 73: loss 5.077497959136963\n",
      "Iteration 74: loss 4.778444766998291\n",
      "Iteration 75: loss 4.851216793060303\n",
      "Iteration 76: loss 4.795837879180908\n",
      "Iteration 77: loss 4.982457160949707\n",
      "Iteration 78: loss 5.090996265411377\n",
      "Iteration 79: loss 4.393667697906494\n",
      "Iteration 80: loss 4.5383172035217285\n",
      "Iteration 81: loss 4.619657039642334\n",
      "Iteration 82: loss 4.318148136138916\n",
      "Iteration 83: loss 4.4017181396484375\n",
      "Iteration 84: loss 4.758090019226074\n",
      "Iteration 85: loss 4.415236949920654\n",
      "Iteration 86: loss 4.240647315979004\n",
      "Iteration 87: loss 4.014430522918701\n",
      "Iteration 88: loss 4.092731475830078\n",
      "Iteration 89: loss 4.12648344039917\n",
      "Iteration 90: loss 4.353001117706299\n",
      "Iteration 91: loss 3.802252769470215\n",
      "Iteration 92: loss 4.069777011871338\n",
      "Iteration 93: loss 4.3040900230407715\n",
      "Iteration 94: loss 4.003107070922852\n",
      "Iteration 95: loss 3.927647352218628\n",
      "Iteration 96: loss 4.038949489593506\n",
      "Iteration 97: loss 4.158405303955078\n",
      "Iteration 98: loss 4.00606632232666\n",
      "Iteration 99: loss 4.270620822906494\n",
      "Iteration 100: loss 3.8836669921875\n",
      "Iteration 101: loss 4.179182529449463\n",
      "Iteration 102: loss 3.883638858795166\n",
      "Iteration 103: loss 4.065566539764404\n",
      "Iteration 104: loss 4.490805625915527\n",
      "Iteration 105: loss 4.057837009429932\n",
      "Iteration 106: loss 4.2153120040893555\n",
      "Iteration 107: loss 4.049445152282715\n",
      "Iteration 108: loss 4.229144096374512\n",
      "Iteration 109: loss 3.5652716159820557\n",
      "Iteration 110: loss 4.119465351104736\n",
      "Iteration 111: loss 4.04142427444458\n",
      "Iteration 112: loss 3.9400863647460938\n",
      "Iteration 113: loss 4.14934778213501\n",
      "Iteration 114: loss 4.0803446769714355\n",
      "Iteration 115: loss 4.098145484924316\n",
      "Iteration 116: loss 4.142867565155029\n",
      "Iteration 117: loss 3.959548234939575\n",
      "Iteration 118: loss 4.028837203979492\n",
      "Iteration 119: loss 3.9305179119110107\n",
      "Iteration 120: loss 4.001589775085449\n",
      "Iteration 121: loss 3.9760639667510986\n",
      "Iteration 122: loss 3.840677499771118\n",
      "Iteration 123: loss 3.8605384826660156\n",
      "Iteration 124: loss 3.5438618659973145\n",
      "Iteration 125: loss 3.529984951019287\n",
      "Iteration 126: loss 4.042356967926025\n",
      "Iteration 127: loss 3.772571563720703\n",
      "Iteration 128: loss 3.9518322944641113\n",
      "Iteration 129: loss 3.879868984222412\n",
      "Iteration 130: loss 3.742716073989868\n",
      "Iteration 131: loss 3.6140761375427246\n",
      "Iteration 132: loss 3.9156243801116943\n",
      "Iteration 133: loss 3.9508306980133057\n",
      "Iteration 134: loss 4.108778476715088\n",
      "Iteration 135: loss 4.075965404510498\n",
      "Iteration 136: loss 3.8185529708862305\n",
      "Iteration 137: loss 4.007219314575195\n",
      "Iteration 138: loss 4.0139312744140625\n",
      "Iteration 139: loss 3.770725727081299\n",
      "Iteration 140: loss 3.9215922355651855\n",
      "Iteration 141: loss 4.519552707672119\n",
      "Iteration 142: loss 3.878249406814575\n",
      "Iteration 143: loss 3.77917218208313\n",
      "Iteration 144: loss 3.9544713497161865\n",
      "Iteration 145: loss 4.150343418121338\n",
      "Iteration 146: loss 4.172522068023682\n",
      "Iteration 147: loss 3.827695608139038\n",
      "Iteration 148: loss 3.6935057640075684\n",
      "Iteration 149: loss 3.7400450706481934\n",
      "Iteration 150: loss 3.544877290725708\n",
      "Iteration 151: loss 3.4768457412719727\n",
      "Iteration 152: loss 3.8179781436920166\n",
      "Iteration 153: loss 3.6967403888702393\n",
      "Iteration 154: loss 3.4999876022338867\n",
      "Iteration 155: loss 3.675797700881958\n",
      "Iteration 156: loss 3.9509313106536865\n",
      "Iteration 157: loss 3.735687732696533\n",
      "Iteration 158: loss 3.7781474590301514\n",
      "Iteration 159: loss 3.6105427742004395\n",
      "Iteration 160: loss 3.26908802986145\n",
      "Iteration 161: loss 3.589625835418701\n",
      "Iteration 162: loss 3.4995083808898926\n",
      "Iteration 163: loss 3.3589117527008057\n",
      "Iteration 164: loss 3.3203048706054688\n",
      "Iteration 165: loss 3.416923761367798\n",
      "Iteration 166: loss 3.324695587158203\n",
      "Iteration 167: loss 3.4176506996154785\n",
      "Iteration 168: loss 3.451408624649048\n",
      "Iteration 169: loss 3.6606881618499756\n",
      "Iteration 170: loss 3.42989182472229\n",
      "Iteration 171: loss 3.6104273796081543\n",
      "Iteration 172: loss 3.36138653755188\n",
      "Iteration 173: loss 3.4914510250091553\n",
      "Iteration 174: loss 3.434537649154663\n",
      "Iteration 175: loss 3.218003511428833\n",
      "Iteration 176: loss 3.626748561859131\n",
      "Iteration 177: loss 3.292914867401123\n",
      "Iteration 178: loss 3.406712055206299\n",
      "Iteration 179: loss 3.447021484375\n",
      "Iteration 180: loss 3.693058490753174\n",
      "Iteration 181: loss 3.342780113220215\n",
      "Iteration 182: loss 3.5346062183380127\n",
      "Iteration 183: loss 3.4595041275024414\n",
      "Iteration 184: loss 3.42850399017334\n",
      "Iteration 185: loss 3.4841716289520264\n",
      "Iteration 186: loss 3.3745641708374023\n",
      "Iteration 187: loss 3.4021666049957275\n",
      "Iteration 188: loss 3.440013885498047\n",
      "Iteration 189: loss 3.5350849628448486\n",
      "Iteration 190: loss 3.5680859088897705\n",
      "Iteration 191: loss 3.459547996520996\n",
      "Iteration 192: loss 3.556124210357666\n",
      "Iteration 193: loss 3.675605297088623\n",
      "Iteration 194: loss 3.8902721405029297\n",
      "Iteration 195: loss 3.495493173599243\n",
      "Iteration 196: loss 4.0476813316345215\n",
      "Iteration 197: loss 4.020634174346924\n",
      "Iteration 198: loss 4.2529497146606445\n",
      "Iteration 199: loss 3.974451780319214\n",
      "Iteration 200: loss 3.853668689727783\n",
      "Iteration 201: loss 3.8672282695770264\n",
      "Iteration 202: loss 3.9533305168151855\n",
      "Iteration 203: loss 3.6535861492156982\n",
      "Iteration 204: loss 3.7648518085479736\n",
      "Iteration 205: loss 3.52065110206604\n",
      "Iteration 206: loss 3.747670888900757\n",
      "Iteration 207: loss 3.7791929244995117\n",
      "Iteration 208: loss 3.900285482406616\n",
      "Iteration 209: loss 3.4473979473114014\n",
      "Iteration 210: loss 4.054132461547852\n",
      "Iteration 211: loss 3.9854612350463867\n",
      "Iteration 212: loss 3.530287027359009\n",
      "Iteration 213: loss 3.3760862350463867\n",
      "Iteration 214: loss 3.8987557888031006\n",
      "Iteration 215: loss 3.3818438053131104\n",
      "Iteration 216: loss 3.479419708251953\n",
      "Iteration 217: loss 3.6894173622131348\n",
      "Iteration 218: loss 3.7341747283935547\n",
      "Iteration 219: loss 3.911384105682373\n",
      "Iteration 220: loss 3.721959114074707\n",
      "Iteration 221: loss 3.7886242866516113\n",
      "Iteration 222: loss 3.44392991065979\n",
      "Iteration 223: loss 3.535228729248047\n",
      "Iteration 224: loss 3.3016011714935303\n",
      "Iteration 225: loss 3.5579946041107178\n",
      "Iteration 226: loss 3.4073259830474854\n",
      "Iteration 227: loss 3.59041690826416\n",
      "Iteration 228: loss 3.6506762504577637\n",
      "Iteration 229: loss 3.8568899631500244\n",
      "Iteration 230: loss 3.7562997341156006\n",
      "Iteration 231: loss 3.563380002975464\n",
      "Iteration 232: loss 3.521773099899292\n",
      "Iteration 233: loss 3.716620683670044\n",
      "Iteration 234: loss 3.960460662841797\n",
      "Iteration 235: loss 3.8533995151519775\n",
      "Iteration 236: loss 3.6805622577667236\n",
      "Iteration 237: loss 3.804293632507324\n",
      "Iteration 238: loss 3.818333148956299\n",
      "Iteration 239: loss 3.791038990020752\n",
      "Iteration 240: loss 3.613389730453491\n",
      "Iteration 241: loss 4.164155006408691\n",
      "Iteration 242: loss 3.7791569232940674\n",
      "Iteration 243: loss 3.8454136848449707\n",
      "Iteration 244: loss 4.085025310516357\n",
      "Iteration 245: loss 3.465930461883545\n",
      "Iteration 246: loss 3.9117448329925537\n",
      "Iteration 247: loss 3.571949005126953\n",
      "Iteration 248: loss 3.7999534606933594\n",
      "Iteration 249: loss 3.7342464923858643\n",
      "Iteration 250: loss 3.7577037811279297\n",
      "Iteration 251: loss 3.857970714569092\n",
      "Iteration 252: loss 3.959627866744995\n",
      "Iteration 253: loss 4.0532145500183105\n",
      "Iteration 254: loss 3.8458333015441895\n",
      "Iteration 255: loss 4.057851314544678\n",
      "Iteration 256: loss 3.3634748458862305\n",
      "Iteration 257: loss 4.157052993774414\n",
      "Iteration 258: loss 3.8643627166748047\n",
      "Iteration 259: loss 4.2359209060668945\n",
      "Iteration 260: loss 3.434300422668457\n",
      "Iteration 261: loss 3.8189146518707275\n",
      "Iteration 262: loss 3.5752665996551514\n",
      "Iteration 263: loss 3.8299686908721924\n",
      "Iteration 264: loss 3.4201550483703613\n",
      "Iteration 265: loss 3.787173271179199\n",
      "Iteration 266: loss 3.6805381774902344\n",
      "Iteration 267: loss 3.9471874237060547\n",
      "Iteration 268: loss 3.738525867462158\n",
      "Iteration 269: loss 3.6366655826568604\n",
      "Iteration 270: loss 3.431101083755493\n",
      "Iteration 271: loss 3.688727378845215\n",
      "Iteration 272: loss 3.4554290771484375\n",
      "Iteration 273: loss 3.5021233558654785\n",
      "Iteration 274: loss 3.41630220413208\n",
      "Iteration 275: loss 3.5293209552764893\n",
      "Iteration 276: loss 3.52042293548584\n",
      "Iteration 277: loss 3.4154961109161377\n",
      "Iteration 278: loss 3.474052667617798\n",
      "Iteration 279: loss 3.7357594966888428\n",
      "Iteration 280: loss 3.5976290702819824\n",
      "Iteration 281: loss 3.865495443344116\n",
      "Iteration 282: loss 3.561091899871826\n",
      "Iteration 283: loss 3.625864267349243\n",
      "Iteration 284: loss 3.4437103271484375\n",
      "Iteration 285: loss 3.656900644302368\n",
      "Iteration 286: loss 3.5745973587036133\n",
      "Iteration 287: loss 3.8275747299194336\n",
      "Iteration 288: loss 3.853286027908325\n",
      "Iteration 289: loss 3.3603508472442627\n",
      "Iteration 290: loss 3.516941785812378\n",
      "Iteration 291: loss 3.418065309524536\n",
      "Iteration 292: loss 3.42926287651062\n",
      "Iteration 293: loss 3.7173454761505127\n",
      "Iteration 294: loss 3.487299680709839\n",
      "Iteration 295: loss 3.263214111328125\n",
      "Iteration 296: loss 3.4348366260528564\n",
      "Iteration 297: loss 3.5013060569763184\n",
      "Iteration 298: loss 3.349170446395874\n",
      "Iteration 299: loss 3.4732725620269775\n",
      "Iteration 300: loss 3.474634885787964\n",
      "Iteration 301: loss 3.4220573902130127\n",
      "Iteration 302: loss 3.4875364303588867\n",
      "Iteration 303: loss 3.455479621887207\n",
      "Iteration 304: loss 3.378085136413574\n",
      "Iteration 305: loss 3.369256019592285\n",
      "Iteration 306: loss 3.201573610305786\n",
      "Iteration 307: loss 3.2368316650390625\n",
      "Iteration 308: loss 3.34104323387146\n",
      "Iteration 309: loss 3.1890130043029785\n",
      "Iteration 310: loss 3.5108659267425537\n",
      "Iteration 311: loss 3.2827742099761963\n",
      "Iteration 312: loss 3.686161994934082\n",
      "Iteration 313: loss 3.289247751235962\n",
      "Iteration 314: loss 3.349571466445923\n",
      "Iteration 315: loss 3.396148204803467\n",
      "Iteration 316: loss 3.4369709491729736\n",
      "Iteration 317: loss 3.1447081565856934\n",
      "Iteration 318: loss 3.310882568359375\n",
      "Iteration 319: loss 3.2136170864105225\n",
      "Iteration 320: loss 3.1945745944976807\n",
      "Iteration 321: loss 3.316941976547241\n",
      "Iteration 322: loss 3.317857503890991\n",
      "Iteration 323: loss 3.2157673835754395\n",
      "Iteration 324: loss 3.2722039222717285\n",
      "Iteration 325: loss 3.3629400730133057\n",
      "Iteration 326: loss 3.1931097507476807\n",
      "Iteration 327: loss 3.178818941116333\n",
      "Iteration 328: loss 2.980311155319214\n",
      "Iteration 329: loss 3.58739972114563\n",
      "Iteration 330: loss 3.6360490322113037\n",
      "Iteration 331: loss 3.583726644515991\n",
      "Iteration 332: loss 3.4057159423828125\n",
      "Iteration 333: loss 3.4351284503936768\n",
      "Iteration 334: loss 3.5165061950683594\n",
      "Iteration 335: loss 3.3922412395477295\n",
      "Iteration 336: loss 3.1294500827789307\n",
      "Iteration 337: loss 3.733483076095581\n",
      "Iteration 338: loss 3.281888246536255\n",
      "Iteration 339: loss 3.0267553329467773\n",
      "Iteration 340: loss 3.306260824203491\n",
      "Iteration 341: loss 3.0383214950561523\n",
      "Iteration 342: loss 3.211066722869873\n",
      "Iteration 343: loss 3.3916194438934326\n",
      "Iteration 344: loss 3.316376209259033\n",
      "Iteration 345: loss 3.097571849822998\n",
      "Iteration 346: loss 3.0824835300445557\n",
      "Iteration 347: loss 3.1008148193359375\n",
      "Iteration 348: loss 3.1985185146331787\n",
      "Iteration 349: loss 3.423915386199951\n",
      "Iteration 350: loss 3.3112001419067383\n",
      "Iteration 351: loss 3.160590648651123\n",
      "Iteration 352: loss 3.012617826461792\n",
      "Iteration 353: loss 3.204725980758667\n",
      "Iteration 354: loss 3.327575922012329\n",
      "Iteration 355: loss 3.3162648677825928\n",
      "Iteration 356: loss 3.480988025665283\n",
      "Iteration 357: loss 3.102536201477051\n",
      "Iteration 358: loss 3.252531051635742\n",
      "Iteration 359: loss 3.1034929752349854\n",
      "Iteration 360: loss 3.3110837936401367\n",
      "Iteration 361: loss 3.3037309646606445\n",
      "Iteration 362: loss 3.200538158416748\n",
      "Iteration 363: loss 3.3411266803741455\n",
      "Iteration 364: loss 3.541364908218384\n",
      "Iteration 365: loss 3.2730984687805176\n",
      "Iteration 366: loss 3.308321475982666\n",
      "Iteration 367: loss 3.319739580154419\n",
      "Iteration 368: loss 3.349921226501465\n",
      "Iteration 369: loss 3.144253730773926\n",
      "Iteration 370: loss 3.1273305416107178\n",
      "Iteration 371: loss 3.0925471782684326\n",
      "Iteration 372: loss 3.51029896736145\n",
      "Iteration 373: loss 3.157771348953247\n",
      "Iteration 374: loss 3.273838520050049\n",
      "Iteration 375: loss 3.213428258895874\n",
      "Iteration 376: loss 3.3596935272216797\n",
      "Iteration 377: loss 3.235598564147949\n",
      "Iteration 378: loss 3.2765471935272217\n",
      "Iteration 379: loss 3.3079686164855957\n",
      "Iteration 380: loss 3.3729875087738037\n",
      "Iteration 381: loss 2.9839189052581787\n",
      "Iteration 382: loss 3.3575565814971924\n",
      "Iteration 383: loss 3.087174654006958\n",
      "Iteration 384: loss 3.3006014823913574\n",
      "Iteration 385: loss 3.272325277328491\n",
      "Iteration 386: loss 3.297637462615967\n",
      "Iteration 387: loss 3.3131768703460693\n",
      "Iteration 388: loss 3.283090353012085\n",
      "Iteration 389: loss 3.037445068359375\n",
      "Iteration 390: loss 3.094244956970215\n",
      "Iteration 391: loss 3.1087658405303955\n",
      "Iteration 392: loss 3.120453119277954\n",
      "Iteration 393: loss 3.1578807830810547\n",
      "Iteration 394: loss 3.17460298538208\n",
      "Iteration 395: loss 3.4872734546661377\n",
      "Iteration 396: loss 3.028132915496826\n",
      "Iteration 397: loss 3.23049259185791\n",
      "Iteration 398: loss 3.259413480758667\n",
      "Iteration 399: loss 3.2171618938446045\n",
      "Iteration 400: loss 3.053867816925049\n",
      "Iteration 401: loss 3.1798527240753174\n",
      "Iteration 402: loss 3.147130250930786\n",
      "Iteration 403: loss 3.141509532928467\n",
      "Iteration 404: loss 2.9578020572662354\n",
      "Iteration 405: loss 3.0346596240997314\n",
      "Iteration 406: loss 2.8862459659576416\n",
      "Iteration 407: loss 3.102107524871826\n",
      "Iteration 408: loss 2.965257406234741\n",
      "Iteration 409: loss 3.0295608043670654\n",
      "Iteration 410: loss 3.22103214263916\n",
      "Iteration 411: loss 3.038675546646118\n",
      "Iteration 412: loss 3.4984333515167236\n",
      "Iteration 413: loss 3.098065137863159\n",
      "Iteration 414: loss 3.381786346435547\n",
      "Iteration 415: loss 3.271930456161499\n",
      "Iteration 416: loss 3.0952444076538086\n",
      "Iteration 417: loss 3.064000129699707\n",
      "Iteration 418: loss 3.378615617752075\n",
      "Iteration 419: loss 3.164438486099243\n",
      "Iteration 420: loss 3.291592597961426\n",
      "Iteration 421: loss 3.4285333156585693\n",
      "Iteration 422: loss 3.876080274581909\n",
      "Iteration 423: loss 3.8429014682769775\n",
      "Iteration 424: loss 3.630009174346924\n",
      "Iteration 425: loss 3.742335796356201\n",
      "Iteration 426: loss 3.974597454071045\n",
      "Iteration 427: loss 4.066600322723389\n",
      "Iteration 428: loss 3.8013927936553955\n",
      "Iteration 429: loss 3.699505567550659\n",
      "Iteration 430: loss 3.402225971221924\n",
      "Iteration 431: loss 3.6160171031951904\n",
      "Iteration 432: loss 3.3686070442199707\n",
      "Iteration 433: loss 3.607499599456787\n",
      "Iteration 434: loss 3.57496976852417\n",
      "Iteration 435: loss 3.718207597732544\n",
      "Iteration 436: loss 3.336948871612549\n",
      "Iteration 437: loss 3.270487070083618\n",
      "Iteration 438: loss 3.4258105754852295\n",
      "Iteration 439: loss 3.4506454467773438\n",
      "Iteration 440: loss 3.263593912124634\n",
      "Iteration 441: loss 3.453144073486328\n",
      "Iteration 442: loss 3.568347692489624\n",
      "Iteration 443: loss 3.3383708000183105\n",
      "Iteration 444: loss 3.4101078510284424\n",
      "Iteration 445: loss 3.2302770614624023\n",
      "Iteration 446: loss 3.2785394191741943\n",
      "Iteration 447: loss 3.650563955307007\n",
      "Iteration 448: loss 3.355827808380127\n",
      "Iteration 449: loss 3.413458824157715\n",
      "Iteration 450: loss 3.4282896518707275\n",
      "Iteration 451: loss 3.2629940509796143\n",
      "Iteration 452: loss 3.4605658054351807\n",
      "Iteration 453: loss 3.407308340072632\n",
      "Iteration 454: loss 3.34494686126709\n",
      "Iteration 455: loss 3.264685869216919\n",
      "Iteration 456: loss 3.4070513248443604\n",
      "Iteration 457: loss 3.1360673904418945\n",
      "Iteration 458: loss 3.407146453857422\n",
      "Iteration 459: loss 3.2930736541748047\n",
      "Iteration 460: loss 3.3927361965179443\n",
      "Iteration 461: loss 3.3614795207977295\n",
      "Iteration 462: loss 3.1158268451690674\n",
      "Iteration 463: loss 3.002675771713257\n",
      "Iteration 464: loss 3.4301695823669434\n",
      "Iteration 465: loss 3.1049766540527344\n",
      "Iteration 466: loss 3.464406728744507\n",
      "Iteration 467: loss 3.1787707805633545\n",
      "Iteration 468: loss 3.2782773971557617\n",
      "Iteration 469: loss 3.5634562969207764\n",
      "Iteration 470: loss 3.4725444316864014\n",
      "Iteration 471: loss 3.02468204498291\n",
      "Iteration 472: loss 3.3698153495788574\n",
      "Iteration 473: loss 3.264299154281616\n",
      "Iteration 474: loss 3.2095818519592285\n",
      "Iteration 475: loss 3.252861261367798\n",
      "Iteration 476: loss 3.178377866744995\n",
      "Iteration 477: loss 3.375784158706665\n",
      "Iteration 478: loss 3.0818233489990234\n",
      "Iteration 479: loss 3.271609306335449\n",
      "Iteration 480: loss 3.294522523880005\n",
      "Iteration 481: loss 3.400480270385742\n",
      "Iteration 482: loss 3.180121421813965\n",
      "Iteration 483: loss 3.260105609893799\n",
      "Iteration 484: loss 3.2761223316192627\n",
      "Iteration 485: loss 3.109288215637207\n",
      "Iteration 486: loss 3.1676552295684814\n",
      "Iteration 487: loss 3.4227654933929443\n",
      "Iteration 488: loss 3.1079046726226807\n",
      "Iteration 489: loss 3.2057156562805176\n",
      "Iteration 490: loss 3.505974769592285\n",
      "Iteration 491: loss 3.0178794860839844\n",
      "Iteration 492: loss 3.445261240005493\n",
      "Iteration 493: loss 3.302154541015625\n",
      "Iteration 494: loss 3.202944278717041\n",
      "Iteration 495: loss 3.13735032081604\n",
      "Iteration 496: loss 3.2756452560424805\n",
      "Iteration 497: loss 3.27245831489563\n",
      "Iteration 498: loss 3.4212260246276855\n",
      "Iteration 499: loss 3.5227136611938477\n",
      "Iteration 500: loss 3.13222336769104\n",
      "Iteration 501: loss 3.3154916763305664\n",
      "Iteration 502: loss 3.0678884983062744\n",
      "Iteration 503: loss 2.991185188293457\n",
      "Iteration 504: loss 3.2236828804016113\n",
      "Iteration 505: loss 3.5347654819488525\n",
      "Iteration 506: loss 3.3080697059631348\n",
      "Iteration 507: loss 3.377875328063965\n",
      "Iteration 508: loss 3.429671049118042\n",
      "Iteration 509: loss 3.358333110809326\n",
      "Iteration 510: loss 3.426664352416992\n",
      "Iteration 511: loss 3.479874849319458\n",
      "Iteration 512: loss 3.495067596435547\n",
      "Iteration 513: loss 3.5523784160614014\n",
      "Iteration 514: loss 3.2932610511779785\n",
      "Iteration 515: loss 3.454714775085449\n",
      "Iteration 516: loss 3.511281728744507\n",
      "Iteration 517: loss 3.6097679138183594\n",
      "Iteration 518: loss 3.8411026000976562\n",
      "Iteration 519: loss 3.9315152168273926\n",
      "Iteration 520: loss 3.766421318054199\n",
      "Iteration 521: loss 3.7580811977386475\n",
      "Iteration 522: loss 3.7782135009765625\n",
      "Iteration 523: loss 3.6161088943481445\n",
      "Iteration 524: loss 3.7229833602905273\n",
      "Iteration 525: loss 4.0994791984558105\n",
      "Iteration 526: loss 4.472743511199951\n",
      "Iteration 527: loss 3.8624773025512695\n",
      "Iteration 528: loss 3.7149574756622314\n",
      "Iteration 529: loss 3.7253592014312744\n",
      "Iteration 530: loss 3.4287545680999756\n",
      "Iteration 531: loss 3.8772435188293457\n",
      "Iteration 532: loss 4.0039286613464355\n",
      "Iteration 533: loss 4.038618564605713\n",
      "Iteration 534: loss 4.029752254486084\n",
      "Iteration 535: loss 4.193854331970215\n",
      "Iteration 536: loss 3.934684991836548\n",
      "Iteration 537: loss 3.975098133087158\n",
      "Iteration 538: loss 3.6482954025268555\n",
      "Iteration 539: loss 3.7776401042938232\n",
      "Iteration 540: loss 3.6826860904693604\n",
      "Iteration 541: loss 3.825387716293335\n",
      "Iteration 542: loss 3.8710403442382812\n",
      "Iteration 543: loss 3.633107900619507\n",
      "Iteration 544: loss 3.4387524127960205\n",
      "Iteration 545: loss 3.6045773029327393\n",
      "Iteration 546: loss 3.2475993633270264\n",
      "Iteration 547: loss 3.8241820335388184\n",
      "Iteration 548: loss 3.8246281147003174\n",
      "Iteration 549: loss 3.5540480613708496\n",
      "Iteration 550: loss 3.785356044769287\n",
      "Iteration 551: loss 3.785712718963623\n",
      "Iteration 552: loss 3.629767417907715\n",
      "Iteration 553: loss 3.5739095211029053\n",
      "Iteration 554: loss 3.5964114665985107\n",
      "Iteration 555: loss 3.473411798477173\n",
      "Iteration 556: loss 3.25427508354187\n",
      "Iteration 557: loss 3.17269229888916\n",
      "Iteration 558: loss 3.4699223041534424\n",
      "Iteration 559: loss 3.428643226623535\n",
      "Iteration 560: loss 3.214736223220825\n",
      "Iteration 561: loss 3.4495832920074463\n",
      "Iteration 562: loss 3.2200253009796143\n",
      "Iteration 563: loss 3.3173577785491943\n",
      "Iteration 564: loss 3.3363964557647705\n",
      "Iteration 565: loss 3.297616720199585\n",
      "Iteration 566: loss 3.133923292160034\n",
      "Iteration 567: loss 3.290377378463745\n",
      "Iteration 568: loss 3.3106486797332764\n",
      "Iteration 569: loss 3.3364927768707275\n",
      "Iteration 570: loss 3.524348258972168\n",
      "Iteration 571: loss 3.7403364181518555\n",
      "Iteration 572: loss 3.594064950942993\n",
      "Iteration 573: loss 3.8519198894500732\n",
      "Iteration 574: loss 3.6017870903015137\n",
      "Iteration 575: loss 3.6980180740356445\n",
      "Iteration 576: loss 3.6383984088897705\n",
      "Iteration 577: loss 3.624843120574951\n",
      "Iteration 578: loss 3.4849300384521484\n",
      "Iteration 579: loss 3.53338885307312\n",
      "Iteration 580: loss 3.3381173610687256\n",
      "Iteration 581: loss 3.3529858589172363\n",
      "Iteration 582: loss 3.5901854038238525\n",
      "Iteration 583: loss 3.7351157665252686\n",
      "Iteration 584: loss 3.61165189743042\n",
      "Iteration 585: loss 3.5652804374694824\n",
      "Iteration 586: loss 3.527778148651123\n",
      "Iteration 587: loss 3.322070598602295\n",
      "Iteration 588: loss 3.9315757751464844\n",
      "Iteration 589: loss 3.764397382736206\n",
      "Iteration 590: loss 3.411959648132324\n",
      "Iteration 591: loss 3.5216546058654785\n",
      "Iteration 592: loss 3.5588371753692627\n",
      "Iteration 593: loss 3.7168726921081543\n",
      "Iteration 594: loss 3.407839775085449\n",
      "Iteration 595: loss 3.546245574951172\n",
      "Iteration 596: loss 3.7906246185302734\n",
      "Iteration 597: loss 3.570565700531006\n",
      "Iteration 598: loss 3.697786808013916\n",
      "Iteration 599: loss 3.562906503677368\n",
      "Iteration 600: loss 3.42256760597229\n",
      "Iteration 601: loss 3.5504090785980225\n",
      "Iteration 602: loss 3.482424736022949\n",
      "Iteration 603: loss 4.007613658905029\n",
      "Iteration 604: loss 4.396386623382568\n",
      "Iteration 605: loss 3.7648303508758545\n",
      "Iteration 606: loss 3.7887797355651855\n",
      "Iteration 607: loss 3.599660634994507\n",
      "Iteration 608: loss 3.56368350982666\n",
      "Iteration 609: loss 3.5884368419647217\n",
      "Iteration 610: loss 3.290748119354248\n",
      "Iteration 611: loss 3.6717019081115723\n",
      "Iteration 612: loss 3.4795846939086914\n",
      "Iteration 613: loss 3.311460494995117\n",
      "Iteration 614: loss 3.2318296432495117\n",
      "Iteration 615: loss 3.4322688579559326\n",
      "Iteration 616: loss 3.4135076999664307\n",
      "Iteration 617: loss 3.253349542617798\n",
      "Iteration 618: loss 3.2092809677124023\n",
      "Iteration 619: loss 3.341942310333252\n",
      "Iteration 620: loss 3.350768566131592\n",
      "Iteration 621: loss 3.397153854370117\n",
      "Iteration 622: loss 3.44878888130188\n",
      "Iteration 623: loss 3.645275115966797\n",
      "Iteration 624: loss 3.91586971282959\n",
      "Iteration 625: loss 3.2270495891571045\n",
      "Iteration 626: loss 3.286238431930542\n",
      "Iteration 627: loss 3.730250358581543\n",
      "Iteration 628: loss 3.716677665710449\n",
      "Iteration 629: loss 3.636831283569336\n",
      "Iteration 630: loss 3.7516982555389404\n",
      "Iteration 631: loss 3.346649646759033\n",
      "Iteration 632: loss 3.4129979610443115\n",
      "Iteration 633: loss 3.798424005508423\n",
      "Iteration 634: loss 4.027280807495117\n",
      "Iteration 635: loss 3.604262590408325\n",
      "Iteration 636: loss 3.4146623611450195\n",
      "Iteration 637: loss 3.4287548065185547\n",
      "Iteration 638: loss 3.405365228652954\n",
      "Iteration 639: loss 3.5763237476348877\n",
      "Iteration 640: loss 3.365324020385742\n",
      "Iteration 641: loss 3.1012895107269287\n",
      "Iteration 642: loss 3.607752561569214\n",
      "Iteration 643: loss 3.695024251937866\n",
      "Iteration 644: loss 3.1911230087280273\n",
      "Iteration 645: loss 3.608293056488037\n",
      "Iteration 646: loss 3.730548620223999\n",
      "Iteration 647: loss 3.664069175720215\n",
      "Iteration 648: loss 3.7600529193878174\n",
      "Iteration 649: loss 3.4964067935943604\n",
      "Iteration 650: loss 3.8368349075317383\n",
      "Iteration 651: loss 3.7619926929473877\n",
      "Iteration 652: loss 3.3637588024139404\n",
      "Iteration 653: loss 4.177496910095215\n",
      "Iteration 654: loss 3.6521155834198\n",
      "Iteration 655: loss 3.724578380584717\n",
      "Iteration 656: loss 3.493913173675537\n",
      "Iteration 657: loss 3.6118955612182617\n",
      "Iteration 658: loss 4.0498046875\n",
      "Iteration 659: loss 4.007984638214111\n",
      "Iteration 660: loss 3.6816303730010986\n",
      "Iteration 661: loss 3.8998401165008545\n",
      "Iteration 662: loss 3.533207893371582\n",
      "Iteration 663: loss 3.481455087661743\n",
      "Iteration 664: loss 3.6042919158935547\n",
      "Iteration 665: loss 3.417961359024048\n",
      "Iteration 666: loss 3.917316198348999\n",
      "Iteration 667: loss 3.5762712955474854\n",
      "Iteration 668: loss 3.4199535846710205\n",
      "Iteration 669: loss 4.14818000793457\n",
      "Iteration 670: loss 3.7782833576202393\n",
      "Iteration 671: loss 3.5764875411987305\n",
      "Iteration 672: loss 3.7976438999176025\n",
      "Iteration 673: loss 3.2967326641082764\n",
      "Iteration 674: loss 3.2221856117248535\n",
      "Iteration 675: loss 3.3724968433380127\n",
      "Iteration 676: loss 3.424593448638916\n",
      "Iteration 677: loss 3.8376121520996094\n",
      "Iteration 678: loss 3.461517810821533\n",
      "Iteration 679: loss 3.907288074493408\n",
      "Iteration 680: loss 3.7803845405578613\n",
      "Iteration 681: loss 3.378654956817627\n",
      "Iteration 682: loss 3.1340527534484863\n",
      "Iteration 683: loss 3.6469180583953857\n",
      "Iteration 684: loss 3.4042179584503174\n",
      "Iteration 685: loss 3.3709819316864014\n",
      "Iteration 686: loss 4.000576972961426\n",
      "Iteration 687: loss 3.7246105670928955\n",
      "Iteration 688: loss 3.371236801147461\n",
      "Iteration 689: loss 3.1963658332824707\n",
      "Iteration 690: loss 3.242198944091797\n",
      "Iteration 691: loss 3.5789756774902344\n",
      "Iteration 692: loss 4.069957256317139\n",
      "Iteration 693: loss 3.5613420009613037\n",
      "Iteration 694: loss 3.4376659393310547\n",
      "Iteration 695: loss 3.164780855178833\n",
      "Iteration 696: loss 3.1664538383483887\n",
      "Iteration 697: loss 3.453484058380127\n",
      "Iteration 698: loss 3.7850024700164795\n",
      "Iteration 699: loss 3.715768337249756\n",
      "Iteration 700: loss 3.660698413848877\n",
      "Iteration 701: loss 3.4382498264312744\n",
      "Iteration 702: loss 3.5743277072906494\n",
      "Iteration 703: loss 3.6081719398498535\n",
      "Iteration 704: loss 3.558201313018799\n",
      "Iteration 705: loss 3.7210938930511475\n",
      "Iteration 706: loss 3.418768882751465\n",
      "Iteration 707: loss 3.603133201599121\n",
      "Iteration 708: loss 4.105191707611084\n",
      "Iteration 709: loss 3.435101270675659\n",
      "Iteration 710: loss 3.0987651348114014\n",
      "Iteration 711: loss 3.5289394855499268\n",
      "Iteration 712: loss 3.7301886081695557\n",
      "Iteration 713: loss 3.3221960067749023\n",
      "Iteration 714: loss 3.5584323406219482\n",
      "Iteration 715: loss 3.432682514190674\n",
      "Iteration 716: loss 3.6198742389678955\n",
      "Iteration 717: loss 3.5827722549438477\n",
      "Iteration 718: loss 3.196956157684326\n",
      "Iteration 719: loss 3.291325092315674\n",
      "Iteration 720: loss 3.4106853008270264\n",
      "Iteration 721: loss 3.527092218399048\n",
      "Iteration 722: loss 3.52978253364563\n",
      "Iteration 723: loss 3.445436716079712\n",
      "Iteration 724: loss 3.363804340362549\n",
      "Iteration 725: loss 3.5788514614105225\n",
      "Iteration 726: loss 3.3379130363464355\n",
      "Iteration 727: loss 3.6299426555633545\n",
      "Iteration 728: loss 3.3403172492980957\n",
      "Iteration 729: loss 3.233316659927368\n",
      "Iteration 730: loss 3.3445615768432617\n",
      "Iteration 731: loss 3.216156482696533\n",
      "Iteration 732: loss 3.173093557357788\n",
      "Iteration 733: loss 3.281320810317993\n",
      "Iteration 734: loss 3.2707126140594482\n",
      "Iteration 735: loss 3.565676212310791\n",
      "Iteration 736: loss 3.504053831100464\n",
      "Iteration 737: loss 3.663985252380371\n",
      "Iteration 738: loss 3.875441312789917\n",
      "Iteration 739: loss 4.916696071624756\n",
      "Iteration 740: loss 4.036022186279297\n",
      "Iteration 741: loss 3.3970961570739746\n",
      "Iteration 742: loss 3.9211807250976562\n",
      "Iteration 743: loss 3.79672908782959\n",
      "Iteration 744: loss 3.7009451389312744\n",
      "Iteration 745: loss 3.6808598041534424\n",
      "Iteration 746: loss 3.396127939224243\n",
      "Iteration 747: loss 3.2895898818969727\n",
      "Iteration 748: loss 3.2683348655700684\n",
      "Iteration 749: loss 3.3363614082336426\n",
      "Iteration 750: loss 3.2221245765686035\n",
      "Iteration 751: loss 3.5564379692077637\n",
      "Iteration 752: loss 3.645721912384033\n",
      "Iteration 753: loss 3.554051637649536\n",
      "Iteration 754: loss 4.545160293579102\n",
      "Iteration 755: loss 3.5164918899536133\n",
      "Iteration 756: loss 3.9341506958007812\n",
      "Iteration 757: loss 4.315272331237793\n",
      "Iteration 758: loss 3.873835563659668\n",
      "Iteration 759: loss 3.6812314987182617\n",
      "Iteration 760: loss 3.765397310256958\n",
      "Iteration 761: loss 3.9115781784057617\n",
      "Iteration 762: loss 4.069870948791504\n",
      "Iteration 763: loss 4.089571952819824\n",
      "Iteration 764: loss 3.718522310256958\n",
      "Iteration 765: loss 3.370948314666748\n",
      "Iteration 766: loss 3.703697443008423\n",
      "Iteration 767: loss 3.379855155944824\n",
      "Iteration 768: loss 3.6522393226623535\n",
      "Iteration 769: loss 3.4645748138427734\n",
      "Iteration 770: loss 3.5022647380828857\n",
      "Iteration 771: loss 3.8485002517700195\n",
      "Iteration 772: loss 3.6309123039245605\n",
      "Iteration 773: loss 3.6217260360717773\n",
      "Iteration 774: loss 3.8680260181427\n",
      "Iteration 775: loss 3.652071952819824\n",
      "Iteration 776: loss 3.747103214263916\n",
      "Iteration 777: loss 3.765587568283081\n",
      "Iteration 778: loss 3.5759410858154297\n",
      "Iteration 779: loss 3.5763094425201416\n",
      "Iteration 780: loss 3.6711974143981934\n",
      "Iteration 781: loss 3.6992390155792236\n",
      "Iteration 782: loss 3.3421308994293213\n",
      "Iteration 783: loss 3.55705189704895\n",
      "Iteration 784: loss 3.5117528438568115\n",
      "Iteration 785: loss 3.7517852783203125\n",
      "Iteration 786: loss 3.205005407333374\n",
      "Iteration 787: loss 3.2086644172668457\n",
      "Iteration 788: loss 3.3882391452789307\n",
      "Iteration 789: loss 3.3372392654418945\n",
      "Iteration 790: loss 3.278052806854248\n",
      "Iteration 791: loss 3.2375476360321045\n",
      "Iteration 792: loss 3.364917516708374\n",
      "Iteration 793: loss 3.291675329208374\n",
      "Iteration 794: loss 3.4591710567474365\n",
      "Iteration 795: loss 2.935309886932373\n",
      "Iteration 796: loss 3.34246563911438\n",
      "Iteration 797: loss 3.600627899169922\n",
      "Iteration 798: loss 3.2768008708953857\n",
      "Iteration 799: loss 3.347487688064575\n",
      "Iteration 800: loss 3.3352468013763428\n",
      "Iteration 801: loss 3.2564568519592285\n",
      "Iteration 802: loss 3.492560863494873\n",
      "Iteration 803: loss 3.223595142364502\n",
      "Iteration 804: loss 3.317558526992798\n",
      "Iteration 805: loss 3.4561455249786377\n",
      "Iteration 806: loss 3.578665018081665\n",
      "Iteration 807: loss 3.5239858627319336\n",
      "Iteration 808: loss 3.428164005279541\n",
      "Iteration 809: loss 3.26166033744812\n",
      "Iteration 810: loss 3.3380491733551025\n",
      "Iteration 811: loss 3.66804838180542\n",
      "Iteration 812: loss 3.691466808319092\n",
      "Iteration 813: loss 3.2070400714874268\n",
      "Iteration 814: loss 3.0591282844543457\n",
      "Iteration 815: loss 3.3656272888183594\n",
      "Iteration 816: loss 3.3110880851745605\n",
      "Iteration 817: loss 3.4586398601531982\n",
      "Iteration 818: loss 3.1651599407196045\n",
      "Iteration 819: loss 3.2408394813537598\n",
      "Iteration 820: loss 3.0735366344451904\n",
      "Iteration 821: loss 3.1283764839172363\n",
      "Iteration 822: loss 3.1550166606903076\n",
      "Iteration 823: loss 3.2883219718933105\n",
      "Iteration 824: loss 3.27062726020813\n",
      "Iteration 825: loss 3.0034592151641846\n",
      "Iteration 826: loss 3.1781444549560547\n",
      "Iteration 827: loss 3.368035316467285\n",
      "Iteration 828: loss 3.2319722175598145\n",
      "Iteration 829: loss 3.2829127311706543\n",
      "Iteration 830: loss 3.1425039768218994\n",
      "Iteration 831: loss 3.2907514572143555\n",
      "Iteration 832: loss 3.216594696044922\n",
      "Iteration 833: loss 3.369812488555908\n",
      "Iteration 834: loss 3.2307400703430176\n",
      "Iteration 835: loss 3.511367082595825\n",
      "Iteration 836: loss 3.2980425357818604\n",
      "Iteration 837: loss 3.21761155128479\n",
      "Iteration 838: loss 3.461733818054199\n",
      "Iteration 839: loss 3.1533358097076416\n",
      "Iteration 840: loss 3.4828617572784424\n",
      "Iteration 841: loss 3.185789108276367\n",
      "Iteration 842: loss 3.3145153522491455\n",
      "Iteration 843: loss 3.1222805976867676\n",
      "Iteration 844: loss 3.316962718963623\n",
      "Iteration 845: loss 3.1346466541290283\n",
      "Iteration 846: loss 3.5980093479156494\n",
      "Iteration 847: loss 3.526506185531616\n",
      "Iteration 848: loss 3.356135845184326\n",
      "Iteration 849: loss 3.123326301574707\n",
      "Iteration 850: loss 3.343944549560547\n",
      "Iteration 851: loss 3.2118585109710693\n",
      "Iteration 852: loss 3.2455668449401855\n",
      "Iteration 853: loss 3.3640153408050537\n",
      "Iteration 854: loss 3.246365547180176\n",
      "Iteration 855: loss 3.5640532970428467\n",
      "Iteration 856: loss 3.4760818481445312\n",
      "Iteration 857: loss 3.5754125118255615\n",
      "Iteration 858: loss 3.3762950897216797\n",
      "Iteration 859: loss 3.460308074951172\n",
      "Iteration 860: loss 3.513859748840332\n",
      "Iteration 861: loss 3.3047306537628174\n",
      "Iteration 862: loss 3.5811729431152344\n",
      "Iteration 863: loss 3.396419048309326\n",
      "Iteration 864: loss 3.6931984424591064\n",
      "Iteration 865: loss 4.074883460998535\n",
      "Iteration 866: loss 3.60537052154541\n",
      "Iteration 867: loss 3.438196897506714\n",
      "Iteration 868: loss 3.417877674102783\n",
      "Iteration 869: loss 3.4269347190856934\n",
      "Iteration 870: loss 3.369556188583374\n",
      "Iteration 871: loss 3.2274606227874756\n",
      "Iteration 872: loss 3.128453254699707\n",
      "Iteration 873: loss 3.1323907375335693\n",
      "Iteration 874: loss 3.035102128982544\n",
      "Iteration 875: loss 3.0813655853271484\n",
      "Iteration 876: loss 3.385369300842285\n",
      "Iteration 877: loss 3.04079532623291\n",
      "Iteration 878: loss 3.107328414916992\n",
      "Iteration 879: loss 3.013871669769287\n",
      "Iteration 880: loss 3.1562511920928955\n",
      "Iteration 881: loss 3.1889097690582275\n",
      "Iteration 882: loss 3.1967880725860596\n",
      "Iteration 883: loss 3.0547807216644287\n",
      "Iteration 884: loss 3.101362943649292\n",
      "Iteration 885: loss 3.1079955101013184\n",
      "Iteration 886: loss 3.187511444091797\n",
      "Iteration 887: loss 4.165009021759033\n",
      "Iteration 888: loss 3.7878432273864746\n",
      "Iteration 889: loss 3.6777703762054443\n",
      "Iteration 890: loss 4.275558948516846\n",
      "Iteration 891: loss 4.657585620880127\n",
      "Iteration 892: loss 4.821393966674805\n",
      "Iteration 893: loss 5.142765998840332\n",
      "Iteration 894: loss 4.982655048370361\n",
      "Iteration 895: loss 4.279634475708008\n",
      "Iteration 896: loss 4.603640556335449\n",
      "Iteration 897: loss 4.775643825531006\n",
      "Iteration 898: loss 4.324583053588867\n",
      "Iteration 899: loss 4.559295177459717\n",
      "Iteration 900: loss 4.966525077819824\n",
      "Iteration 901: loss 4.512421607971191\n",
      "Iteration 902: loss 5.1488566398620605\n",
      "Iteration 903: loss 4.591814041137695\n",
      "Iteration 904: loss 4.555757999420166\n",
      "Iteration 905: loss 4.41310453414917\n",
      "Iteration 906: loss 3.9686248302459717\n",
      "Iteration 907: loss 4.363648414611816\n",
      "Iteration 908: loss 4.563361644744873\n",
      "Iteration 909: loss 4.519246578216553\n",
      "Iteration 910: loss 4.262311935424805\n",
      "Iteration 911: loss 4.586568355560303\n",
      "Iteration 912: loss 4.488935470581055\n",
      "Iteration 913: loss 4.264488220214844\n",
      "Iteration 914: loss 4.043398380279541\n",
      "Iteration 915: loss 4.658177375793457\n",
      "Iteration 916: loss 3.903505802154541\n",
      "Iteration 917: loss 4.398594856262207\n",
      "Iteration 918: loss 4.502902030944824\n",
      "Iteration 919: loss 3.9282491207122803\n",
      "Iteration 920: loss 4.36023473739624\n",
      "Iteration 921: loss 4.235531330108643\n",
      "Iteration 922: loss 3.804081916809082\n",
      "Iteration 923: loss 3.9144136905670166\n",
      "Iteration 924: loss 4.02732515335083\n",
      "Iteration 925: loss 4.325992107391357\n",
      "Iteration 926: loss 3.826237678527832\n",
      "Iteration 927: loss 3.9432220458984375\n",
      "Iteration 928: loss 3.5169286727905273\n",
      "Iteration 929: loss 3.6264119148254395\n",
      "Iteration 930: loss 3.5896859169006348\n",
      "Iteration 931: loss 3.525855541229248\n",
      "Iteration 932: loss 3.3457140922546387\n",
      "Iteration 933: loss 3.333752393722534\n",
      "Iteration 934: loss 3.4238672256469727\n",
      "Iteration 935: loss 3.4067535400390625\n",
      "Iteration 936: loss 3.2642204761505127\n",
      "Iteration 937: loss 3.1269214153289795\n",
      "Iteration 938: loss 3.416086435317993\n",
      "Iteration 939: loss 3.2319700717926025\n",
      "Iteration 940: loss 3.153998374938965\n",
      "Iteration 941: loss 3.40408992767334\n",
      "Iteration 942: loss 3.01025390625\n",
      "Iteration 943: loss 3.195852041244507\n",
      "Iteration 944: loss 2.9440181255340576\n",
      "Iteration 945: loss 3.1567065715789795\n",
      "Iteration 946: loss 3.2639071941375732\n",
      "Iteration 947: loss 3.2685835361480713\n",
      "Iteration 948: loss 3.405726194381714\n",
      "Iteration 949: loss 3.1260287761688232\n",
      "Iteration 950: loss 3.0603411197662354\n",
      "Iteration 951: loss 3.167029857635498\n",
      "Iteration 952: loss 3.103048086166382\n",
      "Iteration 953: loss 3.126467227935791\n",
      "Iteration 954: loss 3.3123815059661865\n",
      "Iteration 955: loss 2.9249801635742188\n",
      "Iteration 956: loss 3.2754998207092285\n",
      "Iteration 957: loss 3.7581377029418945\n",
      "Iteration 958: loss 3.245488166809082\n",
      "Iteration 959: loss 3.327334403991699\n",
      "Iteration 960: loss 3.30298113822937\n",
      "Iteration 961: loss 3.203693151473999\n",
      "Iteration 962: loss 3.4722442626953125\n",
      "Iteration 963: loss 3.1994032859802246\n",
      "Iteration 964: loss 3.3113865852355957\n",
      "Iteration 965: loss 3.3146862983703613\n",
      "Iteration 966: loss 3.095125436782837\n",
      "Iteration 967: loss 3.319223642349243\n",
      "Iteration 968: loss 3.313974618911743\n",
      "Iteration 969: loss 3.377933979034424\n",
      "Iteration 970: loss 3.3068273067474365\n",
      "Iteration 971: loss 3.1981141567230225\n",
      "Iteration 972: loss 3.1460723876953125\n",
      "Iteration 973: loss 3.0692875385284424\n",
      "Iteration 974: loss 3.2349867820739746\n",
      "Iteration 975: loss 3.0925471782684326\n",
      "Iteration 976: loss 3.2105278968811035\n",
      "Iteration 977: loss 3.1350951194763184\n",
      "Iteration 978: loss 3.0887863636016846\n",
      "Iteration 979: loss 3.1191930770874023\n",
      "Iteration 980: loss 2.9009664058685303\n",
      "Iteration 981: loss 3.13028621673584\n",
      "Iteration 982: loss 3.0857906341552734\n",
      "Iteration 983: loss 2.9768636226654053\n",
      "Iteration 984: loss 2.857825517654419\n",
      "Iteration 985: loss 3.058854818344116\n",
      "Iteration 986: loss 2.8695292472839355\n",
      "Iteration 987: loss 2.882554292678833\n",
      "Iteration 988: loss 2.9437968730926514\n",
      "Iteration 989: loss 3.0416831970214844\n",
      "Iteration 990: loss 2.989006280899048\n",
      "Iteration 991: loss 3.156451463699341\n",
      "Iteration 992: loss 2.887171983718872\n",
      "Iteration 993: loss 3.215120792388916\n",
      "Iteration 994: loss 3.1186609268188477\n",
      "Iteration 995: loss 3.1902318000793457\n",
      "Iteration 996: loss 2.9546802043914795\n",
      "Iteration 997: loss 3.040330648422241\n",
      "Iteration 998: loss 3.115825653076172\n",
      "Iteration 999: loss 3.064923048019409\n",
      "Iteration 1000: loss 2.953430652618408\n",
      "Iteration 1001: loss 2.968975782394409\n",
      "Iteration 1002: loss 2.9387741088867188\n",
      "Iteration 1003: loss 2.9985313415527344\n",
      "Iteration 1004: loss 3.035824775695801\n",
      "Iteration 1005: loss 2.9297661781311035\n",
      "Iteration 1006: loss 2.9343459606170654\n",
      "Iteration 1007: loss 2.95770001411438\n",
      "Iteration 1008: loss 2.9863522052764893\n",
      "Iteration 1009: loss 2.9402830600738525\n",
      "Iteration 1010: loss 2.783412218093872\n",
      "Iteration 1011: loss 2.8408682346343994\n",
      "Iteration 1012: loss 2.975247621536255\n",
      "Iteration 1013: loss 3.0485081672668457\n",
      "Iteration 1014: loss 3.311819076538086\n",
      "Iteration 1015: loss 3.145965576171875\n",
      "Iteration 1016: loss 3.134345054626465\n",
      "Iteration 1017: loss 3.134925365447998\n",
      "Iteration 1018: loss 3.1603152751922607\n",
      "Iteration 1019: loss 3.005186080932617\n",
      "Iteration 1020: loss 3.036059617996216\n",
      "Iteration 1021: loss 3.0164577960968018\n",
      "Iteration 1022: loss 2.9286022186279297\n",
      "Iteration 1023: loss 2.9608514308929443\n",
      "Iteration 1024: loss 2.851102113723755\n",
      "Iteration 1025: loss 2.937655210494995\n",
      "Iteration 1026: loss 3.0093448162078857\n",
      "Iteration 1027: loss 3.1321709156036377\n",
      "Iteration 1028: loss 3.0331695079803467\n",
      "Iteration 1029: loss 2.932506561279297\n",
      "Iteration 1030: loss 2.832291841506958\n",
      "Iteration 1031: loss 3.109541177749634\n",
      "Iteration 1032: loss 2.8874151706695557\n",
      "Iteration 1033: loss 3.0065159797668457\n",
      "Iteration 1034: loss 3.0913076400756836\n",
      "Iteration 1035: loss 2.9267125129699707\n",
      "Iteration 1036: loss 2.965155601501465\n",
      "Iteration 1037: loss 2.9288012981414795\n",
      "Iteration 1038: loss 3.006690502166748\n",
      "Iteration 1039: loss 2.8501696586608887\n",
      "Iteration 1040: loss 2.760993480682373\n",
      "Iteration 1041: loss 2.8831334114074707\n",
      "Iteration 1042: loss 2.758673667907715\n",
      "Iteration 1043: loss 2.835660219192505\n",
      "Iteration 1044: loss 3.132951259613037\n",
      "Iteration 1045: loss 3.1134910583496094\n",
      "Iteration 1046: loss 2.9114646911621094\n",
      "Iteration 1047: loss 3.138983726501465\n",
      "Iteration 1048: loss 2.8049652576446533\n",
      "Iteration 1049: loss 3.070744514465332\n",
      "Iteration 1050: loss 2.998546600341797\n",
      "Iteration 1051: loss 2.8883721828460693\n",
      "Iteration 1052: loss 2.9331161975860596\n",
      "Iteration 1053: loss 2.830146312713623\n",
      "Iteration 1054: loss 2.9108335971832275\n",
      "Iteration 1055: loss 2.9932024478912354\n",
      "Iteration 1056: loss 2.941352367401123\n",
      "Iteration 1057: loss 2.8851418495178223\n",
      "Iteration 1058: loss 2.9403557777404785\n",
      "Iteration 1059: loss 2.885406494140625\n",
      "Iteration 1060: loss 2.949646234512329\n",
      "Iteration 1061: loss 2.977113962173462\n",
      "Iteration 1062: loss 3.0095431804656982\n",
      "Iteration 1063: loss 2.878530740737915\n",
      "Iteration 1064: loss 3.083225727081299\n",
      "Iteration 1065: loss 2.9452340602874756\n",
      "Iteration 1066: loss 2.831864595413208\n",
      "Iteration 1067: loss 3.0016887187957764\n",
      "Iteration 1068: loss 2.912675142288208\n",
      "Iteration 1069: loss 2.805281639099121\n",
      "Iteration 1070: loss 2.890493392944336\n",
      "Iteration 1071: loss 2.9159722328186035\n",
      "Iteration 1072: loss 2.975400924682617\n",
      "Iteration 1073: loss 3.02386474609375\n",
      "Iteration 1074: loss 2.9796040058135986\n",
      "Iteration 1075: loss 3.0908868312835693\n",
      "Iteration 1076: loss 2.7890071868896484\n",
      "Iteration 1077: loss 2.9586398601531982\n",
      "Iteration 1078: loss 3.0868327617645264\n",
      "Iteration 1079: loss 3.0793163776397705\n",
      "Iteration 1080: loss 3.1511638164520264\n",
      "Iteration 1081: loss 2.8931431770324707\n",
      "Iteration 1082: loss 2.9041569232940674\n",
      "Iteration 1083: loss 3.0458648204803467\n",
      "Iteration 1084: loss 2.785710334777832\n",
      "Iteration 1085: loss 2.979004144668579\n",
      "Iteration 1086: loss 2.9988698959350586\n",
      "Iteration 1087: loss 2.9811432361602783\n",
      "Iteration 1088: loss 2.9410698413848877\n",
      "Iteration 1089: loss 2.9052116870880127\n",
      "Iteration 1090: loss 3.0637972354888916\n",
      "Iteration 1091: loss 2.8098583221435547\n",
      "Iteration 1092: loss 2.8892977237701416\n",
      "Iteration 1093: loss 2.89448881149292\n",
      "Iteration 1094: loss 2.901270627975464\n",
      "Iteration 1095: loss 2.7383036613464355\n",
      "Iteration 1096: loss 2.90486741065979\n",
      "Iteration 1097: loss 2.8550915718078613\n",
      "Iteration 1098: loss 2.940467357635498\n",
      "Iteration 1099: loss 2.973904848098755\n",
      "Iteration 1100: loss 2.7728874683380127\n",
      "Iteration 1101: loss 2.9924516677856445\n",
      "Iteration 1102: loss 2.9585607051849365\n",
      "Iteration 1103: loss 2.805891752243042\n",
      "Iteration 1104: loss 2.8868467807769775\n",
      "Iteration 1105: loss 2.756072998046875\n",
      "Iteration 1106: loss 3.074860095977783\n",
      "Iteration 1107: loss 3.6593992710113525\n",
      "Iteration 1108: loss 3.9962844848632812\n",
      "Iteration 1109: loss 3.5502617359161377\n",
      "Iteration 1110: loss 4.304845333099365\n",
      "Iteration 1111: loss 4.087696552276611\n",
      "Iteration 1112: loss 3.9307973384857178\n",
      "Iteration 1113: loss 4.1756696701049805\n",
      "Iteration 1114: loss 3.4962382316589355\n",
      "Iteration 1115: loss 3.4745776653289795\n",
      "Iteration 1116: loss 3.300262451171875\n",
      "Iteration 1117: loss 3.502310037612915\n",
      "Iteration 1118: loss 3.4885854721069336\n",
      "Iteration 1119: loss 3.794945478439331\n",
      "Iteration 1120: loss 3.991007089614868\n",
      "Iteration 1121: loss 3.708259105682373\n",
      "Iteration 1122: loss 3.812626361846924\n",
      "Iteration 1123: loss 3.8483641147613525\n",
      "Iteration 1124: loss 3.746591806411743\n",
      "Iteration 1125: loss 3.451124906539917\n",
      "Iteration 1126: loss 3.6678378582000732\n",
      "Iteration 1127: loss 3.71274733543396\n",
      "Iteration 1128: loss 3.309089183807373\n",
      "Iteration 1129: loss 3.585566520690918\n",
      "Iteration 1130: loss 3.866206645965576\n",
      "Iteration 1131: loss 3.9947142601013184\n",
      "Iteration 1132: loss 3.42474102973938\n",
      "Iteration 1133: loss 3.4261114597320557\n",
      "Iteration 1134: loss 3.46895170211792\n",
      "Iteration 1135: loss 3.238811492919922\n",
      "Iteration 1136: loss 3.5747933387756348\n",
      "Iteration 1137: loss 3.365473747253418\n",
      "Iteration 1138: loss 3.5019352436065674\n",
      "Iteration 1139: loss 3.486332893371582\n",
      "Iteration 1140: loss 3.358793258666992\n",
      "Iteration 1141: loss 3.562998056411743\n",
      "Iteration 1142: loss 3.4319121837615967\n",
      "Iteration 1143: loss 3.506472587585449\n",
      "Iteration 1144: loss 3.329935312271118\n",
      "Iteration 1145: loss 3.779667377471924\n",
      "Iteration 1146: loss 3.362133741378784\n",
      "Iteration 1147: loss 3.141239881515503\n",
      "Iteration 1148: loss 3.276437997817993\n",
      "Iteration 1149: loss 3.541008949279785\n",
      "Iteration 1150: loss 3.2670085430145264\n",
      "Iteration 1151: loss 3.4993879795074463\n",
      "Iteration 1152: loss 3.6324028968811035\n",
      "Iteration 1153: loss 3.228100538253784\n",
      "Iteration 1154: loss 3.746288299560547\n",
      "Iteration 1155: loss 3.478949785232544\n",
      "Iteration 1156: loss 3.5200014114379883\n",
      "Iteration 1157: loss 3.9112439155578613\n",
      "Iteration 1158: loss 4.123612403869629\n",
      "Iteration 1159: loss 3.8513646125793457\n",
      "Iteration 1160: loss 3.392646312713623\n",
      "Iteration 1161: loss 3.237703800201416\n",
      "Iteration 1162: loss 3.7601778507232666\n",
      "Iteration 1163: loss 3.5495641231536865\n",
      "Iteration 1164: loss 3.280266046524048\n",
      "Iteration 1165: loss 3.2373223304748535\n",
      "Iteration 1166: loss 3.58494234085083\n",
      "Iteration 1167: loss 3.252514600753784\n",
      "Iteration 1168: loss 3.575016736984253\n",
      "Iteration 1169: loss 3.3876726627349854\n",
      "Iteration 1170: loss 3.5452487468719482\n",
      "Iteration 1171: loss 3.4623095989227295\n",
      "Iteration 1172: loss 3.276310920715332\n",
      "Iteration 1173: loss 3.2862939834594727\n",
      "Iteration 1174: loss 3.274646520614624\n",
      "Iteration 1175: loss 3.5623865127563477\n",
      "Iteration 1176: loss 3.169912099838257\n",
      "Iteration 1177: loss 3.1219682693481445\n",
      "Iteration 1178: loss 3.29378342628479\n",
      "Iteration 1179: loss 3.149745464324951\n",
      "Iteration 1180: loss 3.241145610809326\n",
      "Iteration 1181: loss 3.2092716693878174\n",
      "Iteration 1182: loss 3.3910841941833496\n",
      "Iteration 1183: loss 3.1431334018707275\n",
      "Iteration 1184: loss 2.971251964569092\n",
      "Iteration 1185: loss 2.9920852184295654\n",
      "Iteration 1186: loss 3.2648534774780273\n",
      "Iteration 1187: loss 3.177412271499634\n",
      "Iteration 1188: loss 3.2522597312927246\n",
      "Iteration 1189: loss 3.2397210597991943\n",
      "Iteration 1190: loss 3.298948049545288\n",
      "Iteration 1191: loss 3.001845359802246\n",
      "Iteration 1192: loss 3.2280519008636475\n",
      "Iteration 1193: loss 3.1819729804992676\n",
      "Iteration 1194: loss 3.050544261932373\n",
      "Iteration 1195: loss 3.2186217308044434\n",
      "Iteration 1196: loss 3.041982889175415\n",
      "Iteration 1197: loss 3.366243839263916\n",
      "Iteration 1198: loss 3.2780609130859375\n",
      "Iteration 1199: loss 3.2757351398468018\n",
      "Iteration 1200: loss 3.06862211227417\n",
      "Iteration 1201: loss 3.332589626312256\n",
      "Iteration 1202: loss 3.2544658184051514\n",
      "Iteration 1203: loss 3.0722241401672363\n",
      "Iteration 1204: loss 3.310819387435913\n",
      "Iteration 1205: loss 3.05279278755188\n",
      "Iteration 1206: loss 3.0418505668640137\n",
      "Iteration 1207: loss 2.9941177368164062\n",
      "Iteration 1208: loss 3.103907346725464\n",
      "Iteration 1209: loss 3.3059184551239014\n",
      "Iteration 1210: loss 3.028400182723999\n",
      "Iteration 1211: loss 3.2713429927825928\n",
      "Iteration 1212: loss 3.0002529621124268\n",
      "Iteration 1213: loss 3.145902633666992\n",
      "Iteration 1214: loss 3.2610630989074707\n",
      "Iteration 1215: loss 3.137752056121826\n",
      "Iteration 1216: loss 3.277622699737549\n",
      "Iteration 1217: loss 2.914515256881714\n",
      "Iteration 1218: loss 3.332914352416992\n",
      "Iteration 1219: loss 3.204338312149048\n",
      "Iteration 1220: loss 3.1553163528442383\n",
      "Iteration 1221: loss 2.9087278842926025\n",
      "Iteration 1222: loss 3.185190439224243\n",
      "Iteration 1223: loss 3.2669591903686523\n",
      "Iteration 1224: loss 3.1235103607177734\n",
      "Iteration 1225: loss 3.3887829780578613\n",
      "Iteration 1226: loss 3.0698843002319336\n",
      "Iteration 1227: loss 3.117560386657715\n",
      "Iteration 1228: loss 3.1464903354644775\n",
      "Iteration 1229: loss 3.365734577178955\n",
      "Iteration 1230: loss 3.3558242321014404\n",
      "Iteration 1231: loss 3.056353807449341\n",
      "Iteration 1232: loss 3.0970425605773926\n",
      "Iteration 1233: loss 3.20919132232666\n",
      "Iteration 1234: loss 3.3715221881866455\n",
      "Iteration 1235: loss 3.1365482807159424\n",
      "Iteration 1236: loss 2.9164695739746094\n",
      "Iteration 1237: loss 3.209712028503418\n",
      "Iteration 1238: loss 3.3654751777648926\n",
      "Iteration 1239: loss 3.0588526725769043\n",
      "Iteration 1240: loss 3.009256601333618\n",
      "Iteration 1241: loss 3.139946222305298\n",
      "Iteration 1242: loss 3.283430814743042\n",
      "Iteration 1243: loss 3.147005319595337\n",
      "Iteration 1244: loss 3.1840765476226807\n",
      "Iteration 1245: loss 3.4187824726104736\n",
      "Iteration 1246: loss 3.4551360607147217\n",
      "Iteration 1247: loss 3.2081432342529297\n",
      "Iteration 1248: loss 3.3126542568206787\n",
      "Iteration 1249: loss 3.499656915664673\n",
      "Iteration 1250: loss 3.2655491828918457\n",
      "Iteration 1251: loss 3.324066638946533\n",
      "Iteration 1252: loss 3.0627760887145996\n",
      "Iteration 1253: loss 3.089329242706299\n",
      "Iteration 1254: loss 3.1305580139160156\n",
      "Iteration 1255: loss 3.324840545654297\n",
      "Iteration 1256: loss 3.3868954181671143\n",
      "Iteration 1257: loss 3.0643367767333984\n",
      "Iteration 1258: loss 3.1473491191864014\n",
      "Iteration 1259: loss 3.4199090003967285\n",
      "Iteration 1260: loss 3.1005401611328125\n",
      "Iteration 1261: loss 2.982287645339966\n",
      "Iteration 1262: loss 3.198887348175049\n",
      "Iteration 1263: loss 3.3683292865753174\n",
      "Iteration 1264: loss 3.269768714904785\n",
      "Iteration 1265: loss 3.3729007244110107\n",
      "Iteration 1266: loss 3.4724273681640625\n",
      "Iteration 1267: loss 3.2531051635742188\n",
      "Iteration 1268: loss 3.0514652729034424\n",
      "Iteration 1269: loss 3.0532805919647217\n",
      "Iteration 1270: loss 3.0758931636810303\n",
      "Iteration 1271: loss 2.905121326446533\n",
      "Iteration 1272: loss 3.1469013690948486\n",
      "Iteration 1273: loss 3.1531622409820557\n",
      "Iteration 1274: loss 3.213369131088257\n",
      "Iteration 1275: loss 3.2378804683685303\n",
      "Iteration 1276: loss 3.417604923248291\n",
      "Iteration 1277: loss 2.9857428073883057\n",
      "Iteration 1278: loss 3.469083786010742\n",
      "Iteration 1279: loss 3.1136345863342285\n",
      "Iteration 1280: loss 3.1398491859436035\n",
      "Iteration 1281: loss 3.032998561859131\n",
      "Iteration 1282: loss 3.3434014320373535\n",
      "Iteration 1283: loss 3.0802927017211914\n",
      "Iteration 1284: loss 3.2996580600738525\n",
      "Iteration 1285: loss 3.405863046646118\n",
      "Iteration 1286: loss 3.2286479473114014\n",
      "Iteration 1287: loss 3.430856227874756\n",
      "Iteration 1288: loss 3.196291446685791\n",
      "Iteration 1289: loss 3.4284136295318604\n",
      "Iteration 1290: loss 3.1817052364349365\n",
      "Iteration 1291: loss 3.1617016792297363\n",
      "Iteration 1292: loss 3.252199411392212\n",
      "Iteration 1293: loss 3.145780563354492\n",
      "Iteration 1294: loss 3.1140246391296387\n",
      "Iteration 1295: loss 3.261326313018799\n",
      "Iteration 1296: loss 3.2052407264709473\n",
      "Iteration 1297: loss 3.0019750595092773\n",
      "Iteration 1298: loss 3.0269267559051514\n",
      "Iteration 1299: loss 3.2026031017303467\n",
      "Iteration 1300: loss 3.4157304763793945\n",
      "Iteration 1301: loss 3.175873279571533\n",
      "Iteration 1302: loss 3.162266254425049\n",
      "Iteration 1303: loss 3.217705011367798\n",
      "Iteration 1304: loss 3.118496894836426\n",
      "Iteration 1305: loss 3.0825793743133545\n",
      "Iteration 1306: loss 3.0995934009552\n",
      "Iteration 1307: loss 3.389488458633423\n",
      "Iteration 1308: loss 3.2894701957702637\n",
      "Iteration 1309: loss 2.905501365661621\n",
      "Iteration 1310: loss 3.153850555419922\n",
      "Iteration 1311: loss 3.1940956115722656\n",
      "Iteration 1312: loss 3.1044015884399414\n",
      "Iteration 1313: loss 3.295736312866211\n",
      "Iteration 1314: loss 3.0886943340301514\n",
      "Iteration 1315: loss 3.190462589263916\n",
      "Iteration 1316: loss 2.9079174995422363\n",
      "Iteration 1317: loss 3.1750590801239014\n",
      "Iteration 1318: loss 3.0143046379089355\n",
      "Iteration 1319: loss 3.0635151863098145\n",
      "Iteration 1320: loss 2.933450937271118\n",
      "Iteration 1321: loss 3.1873779296875\n",
      "Iteration 1322: loss 3.069201707839966\n",
      "Iteration 1323: loss 3.153208017349243\n",
      "Iteration 1324: loss 3.0104260444641113\n",
      "Iteration 1325: loss 3.0218918323516846\n",
      "Iteration 1326: loss 3.1651055812835693\n",
      "Iteration 1327: loss 3.061535596847534\n",
      "Iteration 1328: loss 3.0872650146484375\n",
      "Iteration 1329: loss 3.107167959213257\n",
      "Iteration 1330: loss 3.1320343017578125\n",
      "Iteration 1331: loss 3.055345296859741\n",
      "Iteration 1332: loss 2.88692307472229\n",
      "Iteration 1333: loss 2.9940831661224365\n",
      "Iteration 1334: loss 3.1862950325012207\n",
      "Iteration 1335: loss 3.145732879638672\n",
      "Iteration 1336: loss 2.9844744205474854\n",
      "Iteration 1337: loss 3.0172483921051025\n",
      "Iteration 1338: loss 3.013550043106079\n",
      "Iteration 1339: loss 3.0786516666412354\n",
      "Iteration 1340: loss 3.3435239791870117\n",
      "Iteration 1341: loss 3.16459584236145\n",
      "Iteration 1342: loss 3.253268241882324\n",
      "Iteration 1343: loss 3.247796058654785\n",
      "Iteration 1344: loss 3.2772841453552246\n",
      "Iteration 1345: loss 2.997608184814453\n",
      "Iteration 1346: loss 3.064239978790283\n",
      "Iteration 1347: loss 3.2662134170532227\n",
      "Iteration 1348: loss 3.145819664001465\n",
      "Iteration 1349: loss 3.3660192489624023\n",
      "Iteration 1350: loss 3.119832992553711\n",
      "Iteration 1351: loss 3.107253313064575\n",
      "Iteration 1352: loss 2.9943835735321045\n",
      "Iteration 1353: loss 3.014946460723877\n",
      "Iteration 1354: loss 3.2962703704833984\n",
      "Iteration 1355: loss 3.2328100204467773\n",
      "Iteration 1356: loss 3.6315200328826904\n",
      "Iteration 1357: loss 3.520136594772339\n",
      "Iteration 1358: loss 4.130131721496582\n",
      "Iteration 1359: loss 3.793541193008423\n",
      "Iteration 1360: loss 3.2528157234191895\n",
      "Iteration 1361: loss 3.387345552444458\n",
      "Iteration 1362: loss 3.165602445602417\n",
      "Iteration 1363: loss 3.4519364833831787\n",
      "Iteration 1364: loss 3.296196460723877\n",
      "Iteration 1365: loss 3.3577091693878174\n",
      "Iteration 1366: loss 3.490161895751953\n",
      "Iteration 1367: loss 3.5319318771362305\n",
      "Iteration 1368: loss 3.5887725353240967\n",
      "Iteration 1369: loss 3.5368640422821045\n",
      "Iteration 1370: loss 3.7106099128723145\n",
      "Iteration 1371: loss 4.009638786315918\n",
      "Iteration 1372: loss 3.988800525665283\n",
      "Iteration 1373: loss 3.7582006454467773\n",
      "Iteration 1374: loss 3.3096656799316406\n",
      "Iteration 1375: loss 3.5536673069000244\n",
      "Iteration 1376: loss 3.5205225944519043\n",
      "Iteration 1377: loss 3.4235050678253174\n",
      "Iteration 1378: loss 3.439274311065674\n",
      "Iteration 1379: loss 3.658885955810547\n",
      "Iteration 1380: loss 3.7938220500946045\n",
      "Iteration 1381: loss 3.6687748432159424\n",
      "Iteration 1382: loss 3.4809842109680176\n",
      "Iteration 1383: loss 3.4924609661102295\n",
      "Iteration 1384: loss 3.64884090423584\n",
      "Iteration 1385: loss 3.4845635890960693\n",
      "Iteration 1386: loss 3.577051877975464\n",
      "Iteration 1387: loss 3.573047161102295\n",
      "Iteration 1388: loss 3.407562255859375\n",
      "Iteration 1389: loss 3.469905376434326\n",
      "Iteration 1390: loss 3.56331729888916\n",
      "Iteration 1391: loss 3.3722875118255615\n",
      "Iteration 1392: loss 3.476290702819824\n",
      "Iteration 1393: loss 3.385706663131714\n",
      "Iteration 1394: loss 3.628168821334839\n",
      "Iteration 1395: loss 3.3308184146881104\n",
      "Iteration 1396: loss 3.2897653579711914\n",
      "Iteration 1397: loss 3.2000389099121094\n",
      "Iteration 1398: loss 3.3410098552703857\n",
      "Iteration 1399: loss 3.205845355987549\n",
      "Iteration 1400: loss 3.4033260345458984\n",
      "Iteration 1401: loss 3.0430846214294434\n",
      "Iteration 1402: loss 3.0682666301727295\n",
      "Iteration 1403: loss 3.228940963745117\n",
      "Iteration 1404: loss 3.235694408416748\n",
      "Iteration 1405: loss 3.0947723388671875\n",
      "Iteration 1406: loss 3.2675881385803223\n",
      "Iteration 1407: loss 3.1437339782714844\n",
      "Iteration 1408: loss 3.1888210773468018\n",
      "Iteration 1409: loss 3.329892873764038\n",
      "Iteration 1410: loss 3.037219524383545\n",
      "Iteration 1411: loss 2.9695143699645996\n",
      "Iteration 1412: loss 3.0035111904144287\n",
      "Iteration 1413: loss 2.7832000255584717\n",
      "Iteration 1414: loss 3.0630276203155518\n",
      "Iteration 1415: loss 2.8406145572662354\n",
      "Iteration 1416: loss 3.1510815620422363\n",
      "Iteration 1417: loss 3.4007933139801025\n",
      "Iteration 1418: loss 3.412527084350586\n",
      "Iteration 1419: loss 3.1402275562286377\n",
      "Iteration 1420: loss 3.021282196044922\n",
      "Iteration 1421: loss 2.877175807952881\n",
      "Iteration 1422: loss 2.7412657737731934\n",
      "Iteration 1423: loss 3.3693978786468506\n",
      "Iteration 1424: loss 3.112779378890991\n",
      "Iteration 1425: loss 3.0072758197784424\n",
      "Iteration 1426: loss 2.957646608352661\n",
      "Iteration 1427: loss 3.0252721309661865\n",
      "Iteration 1428: loss 3.4620440006256104\n",
      "Iteration 1429: loss 3.775033473968506\n",
      "Iteration 1430: loss 3.2114274501800537\n",
      "Iteration 1431: loss 3.2756264209747314\n",
      "Iteration 1432: loss 3.28121018409729\n",
      "Iteration 1433: loss 3.8082165718078613\n",
      "Iteration 1434: loss 3.636648416519165\n",
      "Iteration 1435: loss 3.7458789348602295\n",
      "Iteration 1436: loss 3.704183578491211\n",
      "Iteration 1437: loss 3.6181395053863525\n",
      "Iteration 1438: loss 3.428455352783203\n",
      "Iteration 1439: loss 3.691420793533325\n",
      "Iteration 1440: loss 3.4222252368927\n",
      "Iteration 1441: loss 3.5373406410217285\n",
      "Iteration 1442: loss 3.596311569213867\n",
      "Iteration 1443: loss 3.444059133529663\n",
      "Iteration 1444: loss 3.7896275520324707\n",
      "Iteration 1445: loss 3.8266351222991943\n",
      "Iteration 1446: loss 3.7812774181365967\n",
      "Iteration 1447: loss 3.649123430252075\n",
      "Iteration 1448: loss 3.5950262546539307\n",
      "Iteration 1449: loss 3.8148019313812256\n",
      "Iteration 1450: loss 3.9212868213653564\n",
      "Iteration 1451: loss 3.5399391651153564\n",
      "Iteration 1452: loss 3.4028563499450684\n",
      "Iteration 1453: loss 3.4487597942352295\n",
      "Iteration 1454: loss 3.175171375274658\n",
      "Iteration 1455: loss 3.322896957397461\n",
      "Iteration 1456: loss 3.1596407890319824\n",
      "Iteration 1457: loss 3.2738335132598877\n",
      "Iteration 1458: loss 3.1288814544677734\n",
      "Iteration 1459: loss 3.176023483276367\n",
      "Iteration 1460: loss 3.201030731201172\n",
      "Iteration 1461: loss 3.3698952198028564\n",
      "Iteration 1462: loss 3.074286937713623\n",
      "Iteration 1463: loss 3.3276607990264893\n",
      "Iteration 1464: loss 2.9559805393218994\n",
      "Iteration 1465: loss 3.004948616027832\n",
      "Iteration 1466: loss 3.1478207111358643\n",
      "Iteration 1467: loss 3.156433343887329\n",
      "Iteration 1468: loss 3.154669761657715\n",
      "Iteration 1469: loss 3.05924129486084\n",
      "Iteration 1470: loss 3.2709274291992188\n",
      "Iteration 1471: loss 3.1652169227600098\n",
      "Iteration 1472: loss 3.3256895542144775\n",
      "Iteration 1473: loss 3.3297009468078613\n",
      "Iteration 1474: loss 3.1919915676116943\n",
      "Iteration 1475: loss 3.167668342590332\n",
      "Iteration 1476: loss 2.9366307258605957\n",
      "Iteration 1477: loss 3.196892738342285\n",
      "Iteration 1478: loss 3.049994468688965\n",
      "Iteration 1479: loss 3.237680196762085\n",
      "Iteration 1480: loss 3.103843927383423\n",
      "Iteration 1481: loss 2.7705202102661133\n",
      "Iteration 1482: loss 2.929398775100708\n",
      "Iteration 1483: loss 3.0402672290802\n",
      "Iteration 1484: loss 3.066605806350708\n",
      "Iteration 1485: loss 2.86592698097229\n",
      "Iteration 1486: loss 2.9355406761169434\n",
      "Iteration 1487: loss 2.947993516921997\n",
      "Iteration 1488: loss 3.014986515045166\n",
      "Iteration 1489: loss 3.007918119430542\n",
      "Iteration 1490: loss 3.318382501602173\n",
      "Iteration 1491: loss 2.956526041030884\n",
      "Iteration 1492: loss 3.1247482299804688\n",
      "Iteration 1493: loss 3.0764925479888916\n",
      "Iteration 1494: loss 2.852863073348999\n",
      "Iteration 1495: loss 2.918954372406006\n",
      "Iteration 1496: loss 2.932603597640991\n",
      "Iteration 1497: loss 3.002363920211792\n",
      "Iteration 1498: loss 3.232462167739868\n",
      "Iteration 1499: loss 3.1002120971679688\n",
      "Iteration 1500: loss 3.1686501502990723\n",
      "Iteration 1501: loss 3.206930160522461\n",
      "Iteration 1502: loss 2.9559175968170166\n",
      "Iteration 1503: loss 3.4303693771362305\n",
      "Iteration 1504: loss 3.626460075378418\n",
      "Iteration 1505: loss 3.095494270324707\n",
      "Iteration 1506: loss 3.5905888080596924\n",
      "Iteration 1507: loss 3.429271697998047\n",
      "Iteration 1508: loss 3.6328513622283936\n",
      "Iteration 1509: loss 3.6380467414855957\n",
      "Iteration 1510: loss 3.3907418251037598\n",
      "Iteration 1511: loss 3.5563273429870605\n",
      "Iteration 1512: loss 3.627385377883911\n",
      "Iteration 1513: loss 4.2075419425964355\n",
      "Iteration 1514: loss 4.182511329650879\n",
      "Iteration 1515: loss 3.9540820121765137\n",
      "Iteration 1516: loss 4.074628829956055\n",
      "Iteration 1517: loss 4.254131317138672\n",
      "Iteration 1518: loss 3.7750585079193115\n",
      "Iteration 1519: loss 3.651855707168579\n",
      "Iteration 1520: loss 3.168213367462158\n",
      "Iteration 1521: loss 3.7572314739227295\n",
      "Iteration 1522: loss 3.278780937194824\n",
      "Iteration 1523: loss 3.3922910690307617\n",
      "Iteration 1524: loss 3.4582202434539795\n",
      "Iteration 1525: loss 3.101008176803589\n",
      "Iteration 1526: loss 3.2862370014190674\n",
      "Iteration 1527: loss 3.2961513996124268\n",
      "Iteration 1528: loss 3.0633983612060547\n",
      "Iteration 1529: loss 3.3157567977905273\n",
      "Iteration 1530: loss 3.1165196895599365\n",
      "Iteration 1531: loss 3.202065944671631\n",
      "Iteration 1532: loss 2.9315178394317627\n",
      "Iteration 1533: loss 2.997659921646118\n",
      "Iteration 1534: loss 2.9883885383605957\n",
      "Iteration 1535: loss 3.093970775604248\n",
      "Iteration 1536: loss 3.2824249267578125\n",
      "Iteration 1537: loss 3.1828339099884033\n",
      "Iteration 1538: loss 2.7638847827911377\n",
      "Iteration 1539: loss 3.0921828746795654\n",
      "Iteration 1540: loss 2.9594671726226807\n",
      "Iteration 1541: loss 3.049426317214966\n",
      "Iteration 1542: loss 3.1323986053466797\n",
      "Iteration 1543: loss 3.2056124210357666\n",
      "Iteration 1544: loss 2.996415615081787\n",
      "Iteration 1545: loss 3.2181107997894287\n",
      "Iteration 1546: loss 3.308688163757324\n",
      "Iteration 1547: loss 3.0679075717926025\n",
      "Iteration 1548: loss 3.175240993499756\n",
      "Iteration 1549: loss 3.113576650619507\n",
      "Iteration 1550: loss 3.3854856491088867\n",
      "Iteration 1551: loss 3.1070587635040283\n",
      "Iteration 1552: loss 2.9488039016723633\n",
      "Iteration 1553: loss 3.1582653522491455\n",
      "Iteration 1554: loss 2.9804675579071045\n",
      "Iteration 1555: loss 2.921013832092285\n",
      "Iteration 1556: loss 3.135197401046753\n",
      "Iteration 1557: loss 3.200533151626587\n",
      "Iteration 1558: loss 3.132002830505371\n",
      "Iteration 1559: loss 3.221191644668579\n",
      "Iteration 1560: loss 3.3156116008758545\n",
      "Iteration 1561: loss 3.31024169921875\n",
      "Iteration 1562: loss 3.1118266582489014\n",
      "Iteration 1563: loss 3.49945330619812\n",
      "Iteration 1564: loss 3.3979814052581787\n",
      "Iteration 1565: loss 3.2764744758605957\n",
      "Iteration 1566: loss 3.174433469772339\n",
      "Iteration 1567: loss 3.2344744205474854\n",
      "Iteration 1568: loss 3.071904182434082\n",
      "Iteration 1569: loss 2.983506917953491\n",
      "Iteration 1570: loss 3.158510684967041\n",
      "Iteration 1571: loss 3.086533784866333\n",
      "Iteration 1572: loss 3.1387956142425537\n",
      "Iteration 1573: loss 3.130129098892212\n",
      "Iteration 1574: loss 3.0451838970184326\n",
      "Iteration 1575: loss 3.0120983123779297\n",
      "Iteration 1576: loss 2.99605655670166\n",
      "Iteration 1577: loss 3.4173474311828613\n",
      "Iteration 1578: loss 3.046450138092041\n",
      "Iteration 1579: loss 3.0781054496765137\n",
      "Iteration 1580: loss 3.093351364135742\n",
      "Iteration 1581: loss 3.003384828567505\n",
      "Iteration 1582: loss 3.0990941524505615\n",
      "Iteration 1583: loss 3.028437376022339\n",
      "Iteration 1584: loss 2.7742462158203125\n",
      "Iteration 1585: loss 2.826272487640381\n",
      "Iteration 1586: loss 2.904470205307007\n",
      "Iteration 1587: loss 3.087392807006836\n",
      "Iteration 1588: loss 3.0638678073883057\n",
      "Iteration 1589: loss 2.9707982540130615\n",
      "Iteration 1590: loss 2.9765918254852295\n",
      "Iteration 1591: loss 2.993215799331665\n",
      "Iteration 1592: loss 3.0016772747039795\n",
      "Iteration 1593: loss 3.1866378784179688\n",
      "Iteration 1594: loss 2.9107704162597656\n",
      "Iteration 1595: loss 2.96490216255188\n",
      "Iteration 1596: loss 3.246351957321167\n",
      "Iteration 1597: loss 2.8897764682769775\n",
      "Iteration 1598: loss 2.898594379425049\n",
      "Iteration 1599: loss 2.825726270675659\n",
      "Iteration 1600: loss 2.933967113494873\n",
      "Iteration 1601: loss 2.8966386318206787\n",
      "Iteration 1602: loss 3.026524066925049\n",
      "Iteration 1603: loss 2.662184715270996\n",
      "Iteration 1604: loss 2.9080169200897217\n",
      "Iteration 1605: loss 2.841198682785034\n",
      "Iteration 1606: loss 2.896454334259033\n",
      "Iteration 1607: loss 3.1564929485321045\n",
      "Iteration 1608: loss 3.131254196166992\n",
      "Iteration 1609: loss 2.7514050006866455\n",
      "Iteration 1610: loss 2.86779522895813\n",
      "Iteration 1611: loss 3.179410219192505\n",
      "Iteration 1612: loss 2.9836809635162354\n",
      "Iteration 1613: loss 3.1912734508514404\n",
      "Iteration 1614: loss 3.108708143234253\n",
      "Iteration 1615: loss 2.9419450759887695\n",
      "Iteration 1616: loss 3.068241596221924\n",
      "Iteration 1617: loss 2.8618714809417725\n",
      "Iteration 1618: loss 3.062335252761841\n",
      "Iteration 1619: loss 2.894617795944214\n",
      "Iteration 1620: loss 3.0575854778289795\n",
      "Iteration 1621: loss 2.996274948120117\n",
      "Iteration 1622: loss 2.9712109565734863\n",
      "Iteration 1623: loss 3.0523464679718018\n",
      "Iteration 1624: loss 2.936377763748169\n",
      "Iteration 1625: loss 2.7448461055755615\n",
      "Iteration 1626: loss 3.1086931228637695\n",
      "Iteration 1627: loss 2.9616363048553467\n",
      "Iteration 1628: loss 2.7401978969573975\n",
      "Iteration 1629: loss 2.9635472297668457\n",
      "Iteration 1630: loss 3.2159218788146973\n",
      "Iteration 1631: loss 2.869953155517578\n",
      "Iteration 1632: loss 3.009183883666992\n",
      "Iteration 1633: loss 3.104766845703125\n",
      "Iteration 1634: loss 2.86669659614563\n",
      "Iteration 1635: loss 2.986555814743042\n",
      "Iteration 1636: loss 2.999276876449585\n",
      "Iteration 1637: loss 2.9997477531433105\n",
      "Iteration 1638: loss 2.8824222087860107\n",
      "Iteration 1639: loss 2.9342775344848633\n",
      "Iteration 1640: loss 2.975698232650757\n",
      "Iteration 1641: loss 2.7836742401123047\n",
      "Iteration 1642: loss 2.9377312660217285\n",
      "Iteration 1643: loss 3.068415403366089\n",
      "Iteration 1644: loss 3.100977659225464\n",
      "Iteration 1645: loss 3.042389392852783\n",
      "Iteration 1646: loss 2.988293409347534\n",
      "Iteration 1647: loss 2.924988031387329\n",
      "Iteration 1648: loss 3.116903066635132\n",
      "Iteration 1649: loss 2.973263740539551\n",
      "Iteration 1650: loss 3.016101121902466\n",
      "Iteration 1651: loss 2.7929203510284424\n",
      "Iteration 1652: loss 3.007915496826172\n",
      "Iteration 1653: loss 2.7696609497070312\n",
      "Iteration 1654: loss 3.004206418991089\n",
      "Iteration 1655: loss 2.7433409690856934\n",
      "Iteration 1656: loss 2.7347824573516846\n",
      "Iteration 1657: loss 2.83190655708313\n",
      "Iteration 1658: loss 2.9120876789093018\n",
      "Iteration 1659: loss 2.983391761779785\n",
      "Iteration 1660: loss 3.0340232849121094\n",
      "Iteration 1661: loss 2.9871013164520264\n",
      "Iteration 1662: loss 2.9372761249542236\n",
      "Iteration 1663: loss 2.9437010288238525\n",
      "Iteration 1664: loss 3.087148427963257\n",
      "Iteration 1665: loss 2.936844825744629\n",
      "Iteration 1666: loss 2.9660940170288086\n",
      "Iteration 1667: loss 2.800690174102783\n",
      "Iteration 1668: loss 2.8933794498443604\n",
      "Iteration 1669: loss 3.062471866607666\n",
      "Iteration 1670: loss 3.2110629081726074\n",
      "Iteration 1671: loss 2.8908205032348633\n",
      "Iteration 1672: loss 2.964904308319092\n",
      "Iteration 1673: loss 3.034235715866089\n",
      "Iteration 1674: loss 3.1845409870147705\n",
      "Iteration 1675: loss 3.1577844619750977\n",
      "Iteration 1676: loss 2.9892382621765137\n",
      "Iteration 1677: loss 2.7191851139068604\n",
      "Iteration 1678: loss 2.9475011825561523\n",
      "Iteration 1679: loss 3.170001268386841\n",
      "Iteration 1680: loss 2.8735721111297607\n",
      "Iteration 1681: loss 3.1170830726623535\n",
      "Iteration 1682: loss 3.0996642112731934\n",
      "Iteration 1683: loss 2.868626117706299\n",
      "Iteration 1684: loss 3.073192596435547\n",
      "Iteration 1685: loss 2.943347692489624\n",
      "Iteration 1686: loss 2.7963414192199707\n",
      "Iteration 1687: loss 3.017787456512451\n",
      "Iteration 1688: loss 2.7887954711914062\n",
      "Iteration 1689: loss 2.9977235794067383\n",
      "Iteration 1690: loss 2.9649314880371094\n",
      "Iteration 1691: loss 2.9448022842407227\n",
      "Iteration 1692: loss 3.101430892944336\n",
      "Iteration 1693: loss 2.941751718521118\n",
      "Iteration 1694: loss 3.1664323806762695\n",
      "Iteration 1695: loss 2.9256398677825928\n",
      "Iteration 1696: loss 2.8985681533813477\n",
      "Iteration 1697: loss 3.0071446895599365\n",
      "Iteration 1698: loss 3.093575954437256\n",
      "Iteration 1699: loss 2.886831521987915\n",
      "Iteration 1700: loss 2.9869205951690674\n",
      "Iteration 1701: loss 3.061894416809082\n",
      "Iteration 1702: loss 3.0708885192871094\n",
      "Iteration 1703: loss 2.9346349239349365\n",
      "Iteration 1704: loss 2.8765220642089844\n",
      "Iteration 1705: loss 2.989482879638672\n",
      "Iteration 1706: loss 3.226876735687256\n",
      "Iteration 1707: loss 3.042121171951294\n",
      "Iteration 1708: loss 3.39298939704895\n",
      "Iteration 1709: loss 3.224138021469116\n",
      "Iteration 1710: loss 3.284623384475708\n",
      "Iteration 1711: loss 3.2726824283599854\n",
      "Iteration 1712: loss 3.374927282333374\n",
      "Iteration 1713: loss 3.3185644149780273\n",
      "Iteration 1714: loss 3.1911144256591797\n",
      "Iteration 1715: loss 3.0363943576812744\n",
      "Iteration 1716: loss 3.222330331802368\n",
      "Iteration 1717: loss 3.227289915084839\n",
      "Iteration 1718: loss 3.185852527618408\n",
      "Iteration 1719: loss 2.937779426574707\n",
      "Iteration 1720: loss 3.100008487701416\n",
      "Iteration 1721: loss 2.985992908477783\n",
      "Iteration 1722: loss 2.95560622215271\n",
      "Iteration 1723: loss 3.1802382469177246\n",
      "Iteration 1724: loss 3.1318023204803467\n",
      "Iteration 1725: loss 3.493607759475708\n",
      "Iteration 1726: loss 3.1298375129699707\n",
      "Iteration 1727: loss 3.042790174484253\n",
      "Iteration 1728: loss 2.9429469108581543\n",
      "Iteration 1729: loss 3.0895791053771973\n",
      "Iteration 1730: loss 3.06516170501709\n",
      "Iteration 1731: loss 3.101341485977173\n",
      "Iteration 1732: loss 3.024986505508423\n",
      "Iteration 1733: loss 3.2575323581695557\n",
      "Iteration 1734: loss 3.1260008811950684\n",
      "Iteration 1735: loss 3.0804436206817627\n",
      "Iteration 1736: loss 3.324284315109253\n",
      "Iteration 1737: loss 3.1478402614593506\n",
      "Iteration 1738: loss 3.071692943572998\n",
      "Iteration 1739: loss 2.9577391147613525\n",
      "Iteration 1740: loss 3.1727354526519775\n",
      "Iteration 1741: loss 3.4247045516967773\n",
      "Iteration 1742: loss 3.088932752609253\n",
      "Iteration 1743: loss 3.312037944793701\n",
      "Iteration 1744: loss 2.9363951683044434\n",
      "Iteration 1745: loss 3.139453411102295\n",
      "Iteration 1746: loss 3.2124428749084473\n",
      "Iteration 1747: loss 3.1795806884765625\n",
      "Iteration 1748: loss 3.1074821949005127\n",
      "Iteration 1749: loss 3.148948907852173\n",
      "Iteration 1750: loss 3.362748146057129\n",
      "Iteration 1751: loss 3.0894036293029785\n",
      "Iteration 1752: loss 3.326005697250366\n",
      "Iteration 1753: loss 3.0979089736938477\n",
      "Iteration 1754: loss 3.158966541290283\n",
      "Iteration 1755: loss 3.3654088973999023\n",
      "Iteration 1756: loss 2.887669563293457\n",
      "Iteration 1757: loss 3.080667734146118\n",
      "Iteration 1758: loss 3.1784231662750244\n",
      "Iteration 1759: loss 3.0466597080230713\n",
      "Iteration 1760: loss 2.903395652770996\n",
      "Iteration 1761: loss 2.9987823963165283\n",
      "Iteration 1762: loss 3.214311361312866\n",
      "Iteration 1763: loss 3.033433675765991\n",
      "Iteration 1764: loss 2.988043785095215\n",
      "Iteration 1765: loss 3.0683319568634033\n",
      "Iteration 1766: loss 3.081390857696533\n",
      "Iteration 1767: loss 3.1650454998016357\n",
      "Iteration 1768: loss 2.8816184997558594\n",
      "Iteration 1769: loss 3.201547861099243\n",
      "Iteration 1770: loss 3.1703124046325684\n",
      "Iteration 1771: loss 3.2645833492279053\n",
      "Iteration 1772: loss 2.903620481491089\n",
      "Iteration 1773: loss 3.212517023086548\n",
      "Iteration 1774: loss 2.9996440410614014\n",
      "Iteration 1775: loss 3.103076696395874\n",
      "Iteration 1776: loss 2.995457410812378\n",
      "Iteration 1777: loss 3.148287296295166\n",
      "Iteration 1778: loss 3.0634233951568604\n",
      "Iteration 1779: loss 3.0546157360076904\n",
      "Iteration 1780: loss 3.084179639816284\n",
      "Iteration 1781: loss 3.016995668411255\n",
      "Iteration 1782: loss 3.107592821121216\n",
      "Iteration 1783: loss 2.9924426078796387\n",
      "Iteration 1784: loss 2.8730461597442627\n",
      "Iteration 1785: loss 2.9458677768707275\n",
      "Iteration 1786: loss 2.795833110809326\n",
      "Iteration 1787: loss 3.01613450050354\n",
      "Iteration 1788: loss 2.8533661365509033\n",
      "Iteration 1789: loss 2.976674795150757\n",
      "Iteration 1790: loss 2.9230563640594482\n",
      "Iteration 1791: loss 2.872034788131714\n",
      "Iteration 1792: loss 3.1910858154296875\n",
      "Iteration 1793: loss 3.019530773162842\n",
      "Iteration 1794: loss 3.225170135498047\n",
      "Iteration 1795: loss 3.140394449234009\n",
      "Iteration 1796: loss 3.0909154415130615\n",
      "Iteration 1797: loss 2.8104708194732666\n",
      "Iteration 1798: loss 2.8765764236450195\n",
      "Iteration 1799: loss 3.2593986988067627\n",
      "Iteration 1800: loss 3.145989418029785\n",
      "Iteration 1801: loss 2.99634051322937\n",
      "Iteration 1802: loss 3.0306591987609863\n",
      "Iteration 1803: loss 3.2576074600219727\n",
      "Iteration 1804: loss 3.196467161178589\n",
      "Iteration 1805: loss 3.1920714378356934\n",
      "Iteration 1806: loss 3.0166091918945312\n",
      "Iteration 1807: loss 2.87404465675354\n",
      "Iteration 1808: loss 2.9184648990631104\n",
      "Iteration 1809: loss 2.979431629180908\n",
      "Iteration 1810: loss 2.8723602294921875\n",
      "Iteration 1811: loss 2.981722593307495\n",
      "Iteration 1812: loss 2.9328083992004395\n",
      "Iteration 1813: loss 2.9340264797210693\n",
      "Iteration 1814: loss 3.0367431640625\n",
      "Iteration 1815: loss 2.9737961292266846\n",
      "Iteration 1816: loss 2.8268542289733887\n",
      "Iteration 1817: loss 2.88417911529541\n",
      "Iteration 1818: loss 2.877244234085083\n",
      "Iteration 1819: loss 2.8024284839630127\n",
      "Iteration 1820: loss 2.8415520191192627\n",
      "Iteration 1821: loss 3.038323402404785\n",
      "Iteration 1822: loss 2.85433030128479\n",
      "Iteration 1823: loss 3.0077977180480957\n",
      "Iteration 1824: loss 2.9657609462738037\n",
      "Iteration 1825: loss 2.823787212371826\n",
      "Iteration 1826: loss 2.9387850761413574\n",
      "Iteration 1827: loss 2.790316104888916\n",
      "Iteration 1828: loss 2.9043078422546387\n",
      "Iteration 1829: loss 2.761188268661499\n",
      "Iteration 1830: loss 2.9746813774108887\n",
      "Iteration 1831: loss 3.0655839443206787\n",
      "Iteration 1832: loss 2.947394847869873\n",
      "Iteration 1833: loss 2.9382314682006836\n",
      "Iteration 1834: loss 3.016883134841919\n",
      "Iteration 1835: loss 2.7326390743255615\n",
      "Iteration 1836: loss 2.9779415130615234\n",
      "Iteration 1837: loss 2.969548463821411\n",
      "Iteration 1838: loss 3.1928977966308594\n",
      "Iteration 1839: loss 3.0692718029022217\n",
      "Iteration 1840: loss 3.109332323074341\n",
      "Iteration 1841: loss 3.015996217727661\n",
      "Iteration 1842: loss 2.739926815032959\n",
      "Iteration 1843: loss 3.065241575241089\n",
      "Iteration 1844: loss 2.9271371364593506\n",
      "Iteration 1845: loss 2.9576220512390137\n",
      "Iteration 1846: loss 3.2000997066497803\n",
      "Iteration 1847: loss 2.766929864883423\n",
      "Iteration 1848: loss 2.830554246902466\n",
      "Iteration 1849: loss 3.063446044921875\n",
      "Iteration 1850: loss 2.867342472076416\n",
      "Iteration 1851: loss 2.843398332595825\n",
      "Iteration 1852: loss 2.838379383087158\n",
      "Iteration 1853: loss 3.0305843353271484\n",
      "Iteration 1854: loss 2.866621255874634\n",
      "Iteration 1855: loss 2.7344985008239746\n",
      "Iteration 1856: loss 2.9193339347839355\n",
      "Iteration 1857: loss 3.0494062900543213\n",
      "Iteration 1858: loss 2.934054136276245\n",
      "Iteration 1859: loss 2.8874380588531494\n",
      "Iteration 1860: loss 2.925936222076416\n",
      "Iteration 1861: loss 2.8011720180511475\n",
      "Iteration 1862: loss 2.9675395488739014\n",
      "Iteration 1863: loss 2.7490594387054443\n",
      "Iteration 1864: loss 2.968590021133423\n",
      "Iteration 1865: loss 2.980177640914917\n",
      "Iteration 1866: loss 2.9294662475585938\n",
      "Iteration 1867: loss 2.8547635078430176\n",
      "Iteration 1868: loss 2.9904491901397705\n",
      "Iteration 1869: loss 2.7352471351623535\n",
      "Iteration 1870: loss 3.0448973178863525\n",
      "Iteration 1871: loss 2.856529474258423\n",
      "Iteration 1872: loss 2.6784496307373047\n",
      "Iteration 1873: loss 2.8854217529296875\n",
      "Iteration 1874: loss 2.9397904872894287\n",
      "Iteration 1875: loss 3.078036069869995\n",
      "Iteration 1876: loss 2.7997097969055176\n",
      "Iteration 1877: loss 2.88399600982666\n",
      "Iteration 1878: loss 2.9466629028320312\n",
      "Iteration 1879: loss 2.8461265563964844\n",
      "Iteration 1880: loss 2.685106039047241\n",
      "Iteration 1881: loss 2.91131591796875\n",
      "Iteration 1882: loss 2.9378533363342285\n",
      "Iteration 1883: loss 2.8351335525512695\n",
      "Iteration 1884: loss 2.8158886432647705\n",
      "Iteration 1885: loss 2.8791918754577637\n",
      "Iteration 1886: loss 2.8970189094543457\n",
      "Iteration 1887: loss 2.841517210006714\n",
      "Iteration 1888: loss 2.9011571407318115\n",
      "Iteration 1889: loss 2.7906389236450195\n",
      "Iteration 1890: loss 2.714715003967285\n",
      "Iteration 1891: loss 2.887315034866333\n",
      "Iteration 1892: loss 2.764991283416748\n",
      "Iteration 1893: loss 3.0242726802825928\n",
      "Iteration 1894: loss 2.8051836490631104\n",
      "Iteration 1895: loss 3.0958163738250732\n",
      "Iteration 1896: loss 2.9942424297332764\n",
      "Iteration 1897: loss 2.7166826725006104\n",
      "Iteration 1898: loss 2.969602584838867\n",
      "Iteration 1899: loss 2.8568050861358643\n",
      "Iteration 1900: loss 3.0382299423217773\n",
      "Iteration 1901: loss 2.8324344158172607\n",
      "Iteration 1902: loss 2.910952091217041\n",
      "Iteration 1903: loss 3.0252151489257812\n",
      "Iteration 1904: loss 2.799024820327759\n",
      "Iteration 1905: loss 2.8276312351226807\n",
      "Iteration 1906: loss 2.8263280391693115\n",
      "Iteration 1907: loss 2.8414995670318604\n",
      "Iteration 1908: loss 2.948951244354248\n",
      "Iteration 1909: loss 2.8692266941070557\n",
      "Iteration 1910: loss 2.968268871307373\n",
      "Iteration 1911: loss 2.9097588062286377\n",
      "Iteration 1912: loss 2.731506824493408\n",
      "Iteration 1913: loss 2.7762467861175537\n",
      "Iteration 1914: loss 2.9832959175109863\n",
      "Iteration 1915: loss 2.8204455375671387\n",
      "Iteration 1916: loss 2.8635027408599854\n",
      "Iteration 1917: loss 2.8966033458709717\n",
      "Iteration 1918: loss 2.867255210876465\n",
      "Iteration 1919: loss 2.6760363578796387\n",
      "Iteration 1920: loss 2.859130382537842\n",
      "Iteration 1921: loss 2.79162335395813\n",
      "Iteration 1922: loss 2.7114150524139404\n",
      "Iteration 1923: loss 2.859678268432617\n",
      "Iteration 1924: loss 2.962742567062378\n",
      "Iteration 1925: loss 2.7437872886657715\n",
      "Iteration 1926: loss 2.894888162612915\n",
      "Iteration 1927: loss 2.8939049243927\n",
      "Iteration 1928: loss 2.947469472885132\n",
      "Iteration 1929: loss 2.922961473464966\n",
      "Iteration 1930: loss 3.2003979682922363\n",
      "Iteration 1931: loss 3.00921630859375\n",
      "Iteration 1932: loss 2.902588129043579\n",
      "Iteration 1933: loss 2.78560209274292\n",
      "Iteration 1934: loss 2.9819371700286865\n",
      "Iteration 1935: loss 2.7032389640808105\n",
      "Iteration 1936: loss 2.6413424015045166\n",
      "Iteration 1937: loss 2.910966396331787\n",
      "Iteration 1938: loss 2.6772427558898926\n",
      "Iteration 1939: loss 3.0942955017089844\n",
      "Iteration 1940: loss 2.9433019161224365\n",
      "Iteration 1941: loss 2.9287655353546143\n",
      "Iteration 1942: loss 3.1285388469696045\n",
      "Iteration 1943: loss 2.8437938690185547\n",
      "Iteration 1944: loss 2.763911724090576\n",
      "Iteration 1945: loss 2.9317893981933594\n",
      "Iteration 1946: loss 2.931328058242798\n",
      "Iteration 1947: loss 2.952481508255005\n",
      "Iteration 1948: loss 3.0333590507507324\n",
      "Iteration 1949: loss 3.0044493675231934\n",
      "Iteration 1950: loss 2.8691091537475586\n",
      "Iteration 1951: loss 2.8240315914154053\n",
      "Iteration 1952: loss 2.874905586242676\n",
      "Iteration 1953: loss 2.790081024169922\n",
      "Iteration 1954: loss 2.8560335636138916\n",
      "Iteration 1955: loss 2.8675949573516846\n",
      "Iteration 1956: loss 2.757658004760742\n",
      "Iteration 1957: loss 2.908073902130127\n",
      "Iteration 1958: loss 2.9986164569854736\n",
      "Iteration 1959: loss 2.8284823894500732\n",
      "Iteration 1960: loss 2.9791131019592285\n",
      "Iteration 1961: loss 2.662261486053467\n",
      "Iteration 1962: loss 2.775547742843628\n",
      "Iteration 1963: loss 2.7433700561523438\n",
      "Iteration 1964: loss 2.910565137863159\n",
      "Iteration 1965: loss 2.9589149951934814\n",
      "Iteration 1966: loss 2.8232674598693848\n",
      "Iteration 1967: loss 2.7650811672210693\n",
      "Iteration 1968: loss 2.844761610031128\n",
      "Iteration 1969: loss 2.935253143310547\n",
      "Iteration 1970: loss 2.983332872390747\n",
      "Iteration 1971: loss 2.858548402786255\n",
      "Iteration 1972: loss 2.8515849113464355\n",
      "Iteration 1973: loss 2.7277607917785645\n",
      "Iteration 1974: loss 2.9284613132476807\n",
      "Iteration 1975: loss 2.8532512187957764\n",
      "Iteration 1976: loss 2.7641732692718506\n",
      "Iteration 1977: loss 2.876166820526123\n",
      "Iteration 1978: loss 2.6971611976623535\n",
      "Iteration 1979: loss 2.854318141937256\n",
      "Iteration 1980: loss 2.829644203186035\n",
      "Iteration 1981: loss 3.309189796447754\n",
      "Iteration 1982: loss 2.9635555744171143\n",
      "Iteration 1983: loss 2.983698606491089\n",
      "Iteration 1984: loss 2.8241686820983887\n",
      "Iteration 1985: loss 2.827754259109497\n",
      "Iteration 1986: loss 2.8933584690093994\n",
      "Iteration 1987: loss 2.814066171646118\n",
      "Iteration 1988: loss 2.859623908996582\n",
      "Iteration 1989: loss 2.74021053314209\n",
      "Iteration 1990: loss 2.8264360427856445\n",
      "Iteration 1991: loss 2.902125597000122\n",
      "Iteration 1992: loss 2.8807458877563477\n",
      "Iteration 1993: loss 2.8828375339508057\n",
      "Iteration 1994: loss 3.2395434379577637\n",
      "Iteration 1995: loss 2.978593111038208\n",
      "Iteration 1996: loss 3.433889150619507\n",
      "Iteration 1997: loss 3.5080864429473877\n",
      "Iteration 1998: loss 2.833024740219116\n",
      "Iteration 1999: loss 3.091756582260132\n",
      "Iteration 2000: loss 3.5212135314941406\n",
      "Iteration 2001: loss 2.9770419597625732\n",
      "Iteration 2002: loss 2.9896647930145264\n",
      "Iteration 2003: loss 3.0346617698669434\n",
      "Iteration 2004: loss 3.0307743549346924\n",
      "Iteration 2005: loss 3.14369797706604\n",
      "Iteration 2006: loss 2.901031970977783\n",
      "Iteration 2007: loss 2.9662094116210938\n",
      "Iteration 2008: loss 3.0833423137664795\n",
      "Iteration 2009: loss 3.174607992172241\n",
      "Iteration 2010: loss 3.182002544403076\n",
      "Iteration 2011: loss 2.893582582473755\n",
      "Iteration 2012: loss 2.9419054985046387\n",
      "Iteration 2013: loss 2.9233789443969727\n",
      "Iteration 2014: loss 3.0171923637390137\n",
      "Iteration 2015: loss 2.8439955711364746\n",
      "Iteration 2016: loss 2.9811742305755615\n",
      "Iteration 2017: loss 2.7626397609710693\n",
      "Iteration 2018: loss 2.929483652114868\n",
      "Iteration 2019: loss 2.9668407440185547\n",
      "Iteration 2020: loss 2.8539750576019287\n",
      "Iteration 2021: loss 2.9103612899780273\n",
      "Iteration 2022: loss 2.9515793323516846\n",
      "Iteration 2023: loss 2.9166338443756104\n",
      "Iteration 2024: loss 3.103367805480957\n",
      "Iteration 2025: loss 3.0404083728790283\n",
      "Iteration 2026: loss 2.8645617961883545\n",
      "Iteration 2027: loss 2.90606427192688\n",
      "Iteration 2028: loss 2.969419240951538\n",
      "Iteration 2029: loss 2.8366644382476807\n",
      "Iteration 2030: loss 2.7970757484436035\n",
      "Iteration 2031: loss 2.944739818572998\n",
      "Iteration 2032: loss 2.85518479347229\n",
      "Iteration 2033: loss 3.1029887199401855\n",
      "Iteration 2034: loss 2.977712392807007\n",
      "Iteration 2035: loss 2.960474729537964\n",
      "Iteration 2036: loss 3.053431987762451\n",
      "Iteration 2037: loss 2.8533501625061035\n",
      "Iteration 2038: loss 2.9692654609680176\n",
      "Iteration 2039: loss 3.167729616165161\n",
      "Iteration 2040: loss 2.8273069858551025\n",
      "Iteration 2041: loss 2.769843101501465\n",
      "Iteration 2042: loss 2.900845527648926\n",
      "Iteration 2043: loss 3.20232892036438\n",
      "Iteration 2044: loss 2.875478506088257\n",
      "Iteration 2045: loss 2.844902992248535\n",
      "Iteration 2046: loss 3.1377902030944824\n",
      "Iteration 2047: loss 3.0486679077148438\n",
      "Iteration 2048: loss 2.983834743499756\n",
      "Iteration 2049: loss 3.1475017070770264\n",
      "Iteration 2050: loss 3.148637056350708\n",
      "Iteration 2051: loss 3.250161647796631\n",
      "Iteration 2052: loss 3.128153085708618\n",
      "Iteration 2053: loss 3.2448205947875977\n",
      "Iteration 2054: loss 2.994828939437866\n",
      "Iteration 2055: loss 3.1721389293670654\n",
      "Iteration 2056: loss 3.153005838394165\n",
      "Iteration 2057: loss 3.2854440212249756\n",
      "Iteration 2058: loss 3.3121447563171387\n",
      "Iteration 2059: loss 3.1902897357940674\n",
      "Iteration 2060: loss 3.5632128715515137\n",
      "Iteration 2061: loss 3.797910690307617\n",
      "Iteration 2062: loss 3.957291841506958\n",
      "Iteration 2063: loss 4.170395374298096\n",
      "Iteration 2064: loss 4.377711772918701\n",
      "Iteration 2065: loss 4.722762107849121\n",
      "Iteration 2066: loss 3.995474100112915\n",
      "Iteration 2067: loss 4.490669250488281\n",
      "Iteration 2068: loss 4.263124942779541\n",
      "Iteration 2069: loss 4.807372570037842\n",
      "Iteration 2070: loss 4.657901287078857\n",
      "Iteration 2071: loss 4.58258056640625\n",
      "Iteration 2072: loss 4.648069858551025\n",
      "Iteration 2073: loss 3.9539859294891357\n",
      "Iteration 2074: loss 3.695439100265503\n",
      "Iteration 2075: loss 3.8839287757873535\n",
      "Iteration 2076: loss 3.901188850402832\n",
      "Iteration 2077: loss 3.6521661281585693\n",
      "Iteration 2078: loss 3.56618332862854\n",
      "Iteration 2079: loss 3.556191921234131\n",
      "Iteration 2080: loss 3.8425281047821045\n",
      "Iteration 2081: loss 3.840031147003174\n",
      "Iteration 2082: loss 3.716073513031006\n",
      "Iteration 2083: loss 3.5465893745422363\n",
      "Iteration 2084: loss 3.6898961067199707\n",
      "Iteration 2085: loss 3.378998279571533\n",
      "Iteration 2086: loss 3.4901671409606934\n",
      "Iteration 2087: loss 3.8347294330596924\n",
      "Iteration 2088: loss 3.8174309730529785\n",
      "Iteration 2089: loss 3.547053337097168\n",
      "Iteration 2090: loss 3.6472203731536865\n",
      "Iteration 2091: loss 3.531930685043335\n",
      "Iteration 2092: loss 3.2100725173950195\n",
      "Iteration 2093: loss 3.4848997592926025\n",
      "Iteration 2094: loss 3.248025417327881\n",
      "Iteration 2095: loss 3.251239538192749\n",
      "Iteration 2096: loss 3.268169403076172\n",
      "Iteration 2097: loss 2.998990774154663\n",
      "Iteration 2098: loss 3.1258604526519775\n",
      "Iteration 2099: loss 3.0303478240966797\n",
      "Iteration 2100: loss 3.124959945678711\n",
      "Iteration 2101: loss 3.375601053237915\n",
      "Iteration 2102: loss 3.067934513092041\n",
      "Iteration 2103: loss 3.5375866889953613\n",
      "Iteration 2104: loss 3.099294424057007\n",
      "Iteration 2105: loss 3.1164441108703613\n",
      "Iteration 2106: loss 2.9490129947662354\n",
      "Iteration 2107: loss 2.885265350341797\n",
      "Iteration 2108: loss 3.3122291564941406\n",
      "Iteration 2109: loss 3.0579116344451904\n",
      "Iteration 2110: loss 3.263627052307129\n",
      "Iteration 2111: loss 3.0820891857147217\n",
      "Iteration 2112: loss 3.1680374145507812\n",
      "Iteration 2113: loss 3.2452681064605713\n",
      "Iteration 2114: loss 3.083608627319336\n",
      "Iteration 2115: loss 3.1585726737976074\n",
      "Iteration 2116: loss 3.263615846633911\n",
      "Iteration 2117: loss 2.9932072162628174\n",
      "Iteration 2118: loss 3.166806221008301\n",
      "Iteration 2119: loss 3.2357678413391113\n",
      "Iteration 2120: loss 2.933893918991089\n",
      "Iteration 2121: loss 3.171161413192749\n",
      "Iteration 2122: loss 3.1028616428375244\n",
      "Iteration 2123: loss 3.1084444522857666\n",
      "Iteration 2124: loss 3.103624105453491\n",
      "Iteration 2125: loss 3.036425828933716\n",
      "Iteration 2126: loss 3.0449066162109375\n",
      "Iteration 2127: loss 2.8772826194763184\n",
      "Iteration 2128: loss 2.894219398498535\n",
      "Iteration 2129: loss 2.8605072498321533\n",
      "Iteration 2130: loss 2.7887234687805176\n",
      "Iteration 2131: loss 3.0021581649780273\n",
      "Iteration 2132: loss 2.8343496322631836\n",
      "Iteration 2133: loss 3.0549333095550537\n",
      "Iteration 2134: loss 3.2137157917022705\n",
      "Iteration 2135: loss 3.1438446044921875\n",
      "Iteration 2136: loss 3.1996703147888184\n",
      "Iteration 2137: loss 3.449134349822998\n",
      "Iteration 2138: loss 4.256354808807373\n",
      "Iteration 2139: loss 3.4863054752349854\n",
      "Iteration 2140: loss 3.6918580532073975\n",
      "Iteration 2141: loss 3.4572181701660156\n",
      "Iteration 2142: loss 3.110990285873413\n",
      "Iteration 2143: loss 3.512701988220215\n",
      "Iteration 2144: loss 3.79984450340271\n",
      "Iteration 2145: loss 3.37164306640625\n",
      "Iteration 2146: loss 3.2330081462860107\n",
      "Iteration 2147: loss 3.288239002227783\n",
      "Iteration 2148: loss 3.6820788383483887\n",
      "Iteration 2149: loss 4.357472896575928\n",
      "Iteration 2150: loss 3.7229037284851074\n",
      "Iteration 2151: loss 3.401895761489868\n",
      "Iteration 2152: loss 3.3903889656066895\n",
      "Iteration 2153: loss 3.6065003871917725\n",
      "Iteration 2154: loss 3.367542266845703\n",
      "Iteration 2155: loss 3.5718071460723877\n",
      "Iteration 2156: loss 3.4907000064849854\n",
      "Iteration 2157: loss 3.24284291267395\n",
      "Iteration 2158: loss 3.463975429534912\n",
      "Iteration 2159: loss 3.4167253971099854\n",
      "Iteration 2160: loss 3.4190876483917236\n",
      "Iteration 2161: loss 3.2944517135620117\n",
      "Iteration 2162: loss 3.3780338764190674\n",
      "Iteration 2163: loss 2.922715902328491\n",
      "Iteration 2164: loss 3.081554412841797\n",
      "Iteration 2165: loss 3.257155656814575\n",
      "Iteration 2166: loss 3.1318562030792236\n",
      "Iteration 2167: loss 3.3469817638397217\n",
      "Iteration 2168: loss 3.6431515216827393\n",
      "Iteration 2169: loss 3.8241045475006104\n",
      "Iteration 2170: loss 3.6907951831817627\n",
      "Iteration 2171: loss 3.9330711364746094\n",
      "Iteration 2172: loss 3.469566583633423\n",
      "Iteration 2173: loss 3.69472336769104\n",
      "Iteration 2174: loss 3.6363067626953125\n",
      "Iteration 2175: loss 3.421698570251465\n",
      "Iteration 2176: loss 3.3774468898773193\n",
      "Iteration 2177: loss 3.527811288833618\n",
      "Iteration 2178: loss 3.5377159118652344\n",
      "Iteration 2179: loss 3.277064085006714\n",
      "Iteration 2180: loss 3.077651262283325\n",
      "Iteration 2181: loss 2.948847532272339\n",
      "Iteration 2182: loss 3.255162239074707\n",
      "Iteration 2183: loss 3.6204018592834473\n",
      "Iteration 2184: loss 3.2810235023498535\n",
      "Iteration 2185: loss 3.264529228210449\n",
      "Iteration 2186: loss 3.244708776473999\n",
      "Iteration 2187: loss 3.1138243675231934\n",
      "Iteration 2188: loss 3.295241117477417\n",
      "Iteration 2189: loss 3.039881944656372\n",
      "Iteration 2190: loss 3.4114575386047363\n",
      "Iteration 2191: loss 3.2559471130371094\n",
      "Iteration 2192: loss 3.313523292541504\n",
      "Iteration 2193: loss 3.3563473224639893\n",
      "Iteration 2194: loss 3.1292781829833984\n",
      "Iteration 2195: loss 3.1623528003692627\n",
      "Iteration 2196: loss 3.104991912841797\n",
      "Iteration 2197: loss 3.259212017059326\n",
      "Iteration 2198: loss 3.1797924041748047\n",
      "Iteration 2199: loss 3.3997273445129395\n",
      "Iteration 2200: loss 3.1781368255615234\n",
      "Iteration 2201: loss 3.1583025455474854\n",
      "Iteration 2202: loss 3.1985599994659424\n",
      "Iteration 2203: loss 3.4206151962280273\n",
      "Iteration 2204: loss 3.5170414447784424\n",
      "Iteration 2205: loss 3.363492250442505\n",
      "Iteration 2206: loss 3.224247932434082\n",
      "Iteration 2207: loss 3.6145546436309814\n",
      "Iteration 2208: loss 3.3731253147125244\n",
      "Iteration 2209: loss 3.206437826156616\n",
      "Iteration 2210: loss 3.441196918487549\n",
      "Iteration 2211: loss 3.318784713745117\n",
      "Iteration 2212: loss 3.4636178016662598\n",
      "Iteration 2213: loss 3.218773126602173\n",
      "Iteration 2214: loss 3.260341167449951\n",
      "Iteration 2215: loss 3.0171849727630615\n",
      "Iteration 2216: loss 3.3494491577148438\n",
      "Iteration 2217: loss 3.3072760105133057\n",
      "Iteration 2218: loss 3.2205564975738525\n",
      "Iteration 2219: loss 3.254352569580078\n",
      "Iteration 2220: loss 3.147312641143799\n",
      "Iteration 2221: loss 3.419395685195923\n",
      "Iteration 2222: loss 2.9597761631011963\n",
      "Iteration 2223: loss 3.2547268867492676\n",
      "Iteration 2224: loss 3.3811583518981934\n",
      "Iteration 2225: loss 3.2539947032928467\n",
      "Iteration 2226: loss 3.1641576290130615\n",
      "Iteration 2227: loss 2.931246042251587\n",
      "Iteration 2228: loss 3.249861001968384\n",
      "Iteration 2229: loss 3.0820467472076416\n",
      "Iteration 2230: loss 3.351339340209961\n",
      "Iteration 2231: loss 3.108354330062866\n",
      "Iteration 2232: loss 3.2513482570648193\n",
      "Iteration 2233: loss 3.481884002685547\n",
      "Iteration 2234: loss 3.8429441452026367\n",
      "Iteration 2235: loss 3.395256280899048\n",
      "Iteration 2236: loss 3.4481773376464844\n",
      "Iteration 2237: loss 3.5129082202911377\n",
      "Iteration 2238: loss 3.2692277431488037\n",
      "Iteration 2239: loss 3.3090550899505615\n",
      "Iteration 2240: loss 3.273460626602173\n",
      "Iteration 2241: loss 3.496755599975586\n",
      "Iteration 2242: loss 3.469517230987549\n",
      "Iteration 2243: loss 3.4966464042663574\n",
      "Iteration 2244: loss 3.618870735168457\n",
      "Iteration 2245: loss 3.234539031982422\n",
      "Iteration 2246: loss 3.289479970932007\n",
      "Iteration 2247: loss 3.565075397491455\n",
      "Iteration 2248: loss 3.579070568084717\n",
      "Iteration 2249: loss 3.40012788772583\n",
      "Iteration 2250: loss 3.121389150619507\n",
      "Iteration 2251: loss 3.460669755935669\n",
      "Iteration 2252: loss 3.213137149810791\n",
      "Iteration 2253: loss 3.61484432220459\n",
      "Iteration 2254: loss 3.577533721923828\n",
      "Iteration 2255: loss 3.4836840629577637\n",
      "Iteration 2256: loss 3.268998861312866\n",
      "Iteration 2257: loss 3.3580803871154785\n",
      "Iteration 2258: loss 3.151362180709839\n",
      "Iteration 2259: loss 3.44659686088562\n",
      "Iteration 2260: loss 3.2953388690948486\n",
      "Iteration 2261: loss 3.5089714527130127\n",
      "Iteration 2262: loss 3.431490898132324\n",
      "Iteration 2263: loss 3.1896135807037354\n",
      "Iteration 2264: loss 3.2209506034851074\n",
      "Iteration 2265: loss 3.413222312927246\n",
      "Iteration 2266: loss 3.5095677375793457\n",
      "Iteration 2267: loss 3.345560312271118\n",
      "Iteration 2268: loss 3.6562554836273193\n",
      "Iteration 2269: loss 3.506706714630127\n",
      "Iteration 2270: loss 3.5464916229248047\n",
      "Iteration 2271: loss 3.3866307735443115\n",
      "Iteration 2272: loss 3.3249144554138184\n",
      "Iteration 2273: loss 3.258836030960083\n",
      "Iteration 2274: loss 3.4677979946136475\n",
      "Iteration 2275: loss 3.484454870223999\n",
      "Iteration 2276: loss 3.39205265045166\n",
      "Iteration 2277: loss 3.338869333267212\n",
      "Iteration 2278: loss 3.2003626823425293\n",
      "Iteration 2279: loss 3.17069935798645\n",
      "Iteration 2280: loss 3.1316277980804443\n",
      "Iteration 2281: loss 3.2768261432647705\n",
      "Iteration 2282: loss 3.496828317642212\n",
      "Iteration 2283: loss 3.4233181476593018\n",
      "Iteration 2284: loss 3.3631725311279297\n",
      "Iteration 2285: loss 3.3963561058044434\n",
      "Iteration 2286: loss 2.9847052097320557\n",
      "Iteration 2287: loss 3.304684638977051\n",
      "Iteration 2288: loss 3.1154747009277344\n",
      "Iteration 2289: loss 3.432267665863037\n",
      "Iteration 2290: loss 3.338787794113159\n",
      "Iteration 2291: loss 3.3832316398620605\n",
      "Iteration 2292: loss 3.363945245742798\n",
      "Iteration 2293: loss 3.294842481613159\n",
      "Iteration 2294: loss 3.26068115234375\n",
      "Iteration 2295: loss 3.2884368896484375\n",
      "Iteration 2296: loss 3.19769287109375\n",
      "Iteration 2297: loss 3.294503688812256\n",
      "Iteration 2298: loss 3.2741644382476807\n",
      "Iteration 2299: loss 3.564624547958374\n",
      "Iteration 2300: loss 3.500901699066162\n",
      "Iteration 2301: loss 3.2651798725128174\n",
      "Iteration 2302: loss 3.3274834156036377\n",
      "Iteration 2303: loss 3.3301968574523926\n",
      "Iteration 2304: loss 3.139561891555786\n",
      "Iteration 2305: loss 3.2864346504211426\n",
      "Iteration 2306: loss 3.2076971530914307\n",
      "Iteration 2307: loss 3.3733348846435547\n",
      "Iteration 2308: loss 3.6777989864349365\n",
      "Iteration 2309: loss 3.164714813232422\n",
      "Iteration 2310: loss 3.3769407272338867\n",
      "Iteration 2311: loss 3.258394718170166\n",
      "Iteration 2312: loss 3.2427830696105957\n",
      "Iteration 2313: loss 3.0669219493865967\n",
      "Iteration 2314: loss 3.047805070877075\n",
      "Iteration 2315: loss 3.2283339500427246\n",
      "Iteration 2316: loss 3.1199278831481934\n",
      "Iteration 2317: loss 3.262779474258423\n",
      "Iteration 2318: loss 3.1887834072113037\n",
      "Iteration 2319: loss 3.37111496925354\n",
      "Iteration 2320: loss 3.2720513343811035\n",
      "Iteration 2321: loss 3.3178274631500244\n",
      "Iteration 2322: loss 3.0708770751953125\n",
      "Iteration 2323: loss 3.371896982192993\n",
      "Iteration 2324: loss 2.9616808891296387\n",
      "Iteration 2325: loss 3.186356782913208\n",
      "Iteration 2326: loss 3.293210983276367\n",
      "Iteration 2327: loss 3.410292863845825\n",
      "Iteration 2328: loss 3.0497164726257324\n",
      "Iteration 2329: loss 3.1211845874786377\n",
      "Iteration 2330: loss 3.106964111328125\n",
      "Iteration 2331: loss 3.2847869396209717\n",
      "Iteration 2332: loss 3.133897542953491\n",
      "Iteration 2333: loss 3.1895604133605957\n",
      "Iteration 2334: loss 3.101362943649292\n",
      "Iteration 2335: loss 3.0297341346740723\n",
      "Iteration 2336: loss 2.840411901473999\n",
      "Iteration 2337: loss 3.289848566055298\n",
      "Iteration 2338: loss 2.9887773990631104\n",
      "Iteration 2339: loss 3.082467555999756\n",
      "Iteration 2340: loss 3.154104471206665\n",
      "Iteration 2341: loss 2.883654832839966\n",
      "Iteration 2342: loss 3.079909086227417\n",
      "Iteration 2343: loss 3.105607271194458\n",
      "Iteration 2344: loss 3.178709030151367\n",
      "Iteration 2345: loss 3.3509738445281982\n",
      "Iteration 2346: loss 3.0800485610961914\n",
      "Iteration 2347: loss 3.1938700675964355\n",
      "Iteration 2348: loss 3.1768510341644287\n",
      "Iteration 2349: loss 3.0989327430725098\n",
      "Iteration 2350: loss 2.9743309020996094\n",
      "Iteration 2351: loss 3.029751777648926\n",
      "Iteration 2352: loss 2.968022346496582\n",
      "Iteration 2353: loss 3.1721184253692627\n",
      "Iteration 2354: loss 3.045680284500122\n",
      "Iteration 2355: loss 3.0130879878997803\n",
      "Iteration 2356: loss 3.068521738052368\n",
      "Iteration 2357: loss 3.178363084793091\n",
      "Iteration 2358: loss 2.921701669692993\n",
      "Iteration 2359: loss 2.9954097270965576\n",
      "Iteration 2360: loss 3.1436617374420166\n",
      "Iteration 2361: loss 3.0709080696105957\n",
      "Iteration 2362: loss 2.8994338512420654\n",
      "Iteration 2363: loss 3.0455358028411865\n",
      "Iteration 2364: loss 3.1916310787200928\n",
      "Iteration 2365: loss 2.980264902114868\n",
      "Iteration 2366: loss 3.25885009765625\n",
      "Iteration 2367: loss 3.021649122238159\n",
      "Iteration 2368: loss 3.1725475788116455\n",
      "Iteration 2369: loss 3.3181097507476807\n",
      "Iteration 2370: loss 3.2371513843536377\n",
      "Iteration 2371: loss 3.0015575885772705\n",
      "Iteration 2372: loss 2.9884159564971924\n",
      "Iteration 2373: loss 2.865975856781006\n",
      "Iteration 2374: loss 3.0708959102630615\n",
      "Iteration 2375: loss 3.0139596462249756\n",
      "Iteration 2376: loss 3.048754930496216\n",
      "Iteration 2377: loss 2.999157667160034\n",
      "Iteration 2378: loss 2.979341745376587\n",
      "Iteration 2379: loss 2.9109301567077637\n",
      "Iteration 2380: loss 3.059260129928589\n",
      "Iteration 2381: loss 3.1837148666381836\n",
      "Iteration 2382: loss 3.0006728172302246\n",
      "Iteration 2383: loss 2.8968639373779297\n",
      "Iteration 2384: loss 2.745089292526245\n",
      "Iteration 2385: loss 2.9344232082366943\n",
      "Iteration 2386: loss 3.0107836723327637\n",
      "Iteration 2387: loss 3.0566725730895996\n",
      "Iteration 2388: loss 3.0432372093200684\n",
      "Iteration 2389: loss 3.01576566696167\n",
      "Iteration 2390: loss 3.0368003845214844\n",
      "Iteration 2391: loss 3.031378746032715\n",
      "Iteration 2392: loss 2.8284475803375244\n",
      "Iteration 2393: loss 2.9349865913391113\n",
      "Iteration 2394: loss 2.9566726684570312\n",
      "Iteration 2395: loss 3.004362106323242\n",
      "Iteration 2396: loss 2.885215997695923\n",
      "Iteration 2397: loss 2.974905014038086\n",
      "Iteration 2398: loss 2.939727783203125\n",
      "Iteration 2399: loss 3.058730363845825\n",
      "Iteration 2400: loss 2.98870587348938\n",
      "Iteration 2401: loss 3.258679151535034\n",
      "Iteration 2402: loss 3.0702247619628906\n",
      "Iteration 2403: loss 2.8335869312286377\n",
      "Iteration 2404: loss 3.1949236392974854\n",
      "Iteration 2405: loss 3.0207433700561523\n",
      "Iteration 2406: loss 3.0265519618988037\n",
      "Iteration 2407: loss 3.0698814392089844\n",
      "Iteration 2408: loss 3.1156957149505615\n",
      "Iteration 2409: loss 2.7789134979248047\n",
      "Iteration 2410: loss 2.7570104598999023\n",
      "Iteration 2411: loss 2.9954967498779297\n",
      "Iteration 2412: loss 2.751041889190674\n",
      "Iteration 2413: loss 3.045488119125366\n",
      "Iteration 2414: loss 3.013598680496216\n",
      "Iteration 2415: loss 3.0629918575286865\n",
      "Iteration 2416: loss 2.8983330726623535\n",
      "Iteration 2417: loss 2.99570894241333\n",
      "Iteration 2418: loss 3.1948888301849365\n",
      "Iteration 2419: loss 3.0711700916290283\n",
      "Iteration 2420: loss 3.1198253631591797\n",
      "Iteration 2421: loss 2.919219493865967\n",
      "Iteration 2422: loss 2.9209258556365967\n",
      "Iteration 2423: loss 3.1984310150146484\n",
      "Iteration 2424: loss 2.9327456951141357\n",
      "Iteration 2425: loss 2.8604094982147217\n",
      "Iteration 2426: loss 3.0694994926452637\n",
      "Iteration 2427: loss 2.8721675872802734\n",
      "Iteration 2428: loss 3.144771099090576\n",
      "Iteration 2429: loss 2.9678633213043213\n",
      "Iteration 2430: loss 3.0406439304351807\n",
      "Iteration 2431: loss 3.1973910331726074\n",
      "Iteration 2432: loss 2.759470224380493\n",
      "Iteration 2433: loss 3.064979076385498\n",
      "Iteration 2434: loss 2.9001219272613525\n",
      "Iteration 2435: loss 2.9847514629364014\n",
      "Iteration 2436: loss 3.0109269618988037\n",
      "Iteration 2437: loss 3.2030301094055176\n",
      "Iteration 2438: loss 3.0263216495513916\n",
      "Iteration 2439: loss 3.1045985221862793\n",
      "Iteration 2440: loss 2.799915075302124\n",
      "Iteration 2441: loss 2.9973175525665283\n",
      "Iteration 2442: loss 2.9553897380828857\n",
      "Iteration 2443: loss 3.0926005840301514\n",
      "Iteration 2444: loss 2.9865477085113525\n",
      "Iteration 2445: loss 2.8939504623413086\n",
      "Iteration 2446: loss 2.8197240829467773\n",
      "Iteration 2447: loss 2.8153135776519775\n",
      "Iteration 2448: loss 2.979388475418091\n",
      "Iteration 2449: loss 2.8545937538146973\n",
      "Iteration 2450: loss 2.731912136077881\n",
      "Iteration 2451: loss 3.121608257293701\n",
      "Iteration 2452: loss 2.872811794281006\n",
      "Iteration 2453: loss 3.3934130668640137\n",
      "Iteration 2454: loss 2.8694090843200684\n",
      "Iteration 2455: loss 3.138629674911499\n",
      "Iteration 2456: loss 3.0076725482940674\n",
      "Iteration 2457: loss 2.8959341049194336\n",
      "Iteration 2458: loss 2.803292989730835\n",
      "Iteration 2459: loss 3.025468587875366\n",
      "Iteration 2460: loss 3.1020805835723877\n",
      "Iteration 2461: loss 3.014695882797241\n",
      "Iteration 2462: loss 2.915440082550049\n",
      "Iteration 2463: loss 2.950364351272583\n",
      "Iteration 2464: loss 2.864577531814575\n",
      "Iteration 2465: loss 3.067500591278076\n",
      "Iteration 2466: loss 2.894671678543091\n",
      "Iteration 2467: loss 2.972256660461426\n",
      "Iteration 2468: loss 2.628873825073242\n",
      "Iteration 2469: loss 3.0367071628570557\n",
      "Iteration 2470: loss 2.7100796699523926\n",
      "Iteration 2471: loss 3.0104212760925293\n",
      "Iteration 2472: loss 2.961622476577759\n",
      "Iteration 2473: loss 2.8702011108398438\n",
      "Iteration 2474: loss 3.006673574447632\n",
      "Iteration 2475: loss 2.681333303451538\n",
      "Iteration 2476: loss 2.9438817501068115\n",
      "Iteration 2477: loss 2.9185290336608887\n",
      "Iteration 2478: loss 2.8393707275390625\n",
      "Iteration 2479: loss 2.845576763153076\n",
      "Iteration 2480: loss 2.705544948577881\n",
      "Iteration 2481: loss 2.784330129623413\n",
      "Iteration 2482: loss 2.9284870624542236\n",
      "Iteration 2483: loss 2.8858561515808105\n",
      "Iteration 2484: loss 2.79333233833313\n",
      "Iteration 2485: loss 2.9458134174346924\n",
      "Iteration 2486: loss 3.057600736618042\n",
      "Iteration 2487: loss 2.882014751434326\n",
      "Iteration 2488: loss 3.015212059020996\n",
      "Iteration 2489: loss 2.876936674118042\n",
      "Iteration 2490: loss 3.0146071910858154\n",
      "Iteration 2491: loss 2.9206132888793945\n",
      "Iteration 2492: loss 2.944338321685791\n",
      "Iteration 2493: loss 2.893148183822632\n",
      "Iteration 2494: loss 2.908982753753662\n",
      "Iteration 2495: loss 2.912740468978882\n",
      "Iteration 2496: loss 2.8703198432922363\n",
      "Iteration 2497: loss 2.9165539741516113\n",
      "Iteration 2498: loss 2.8978195190429688\n",
      "Iteration 2499: loss 2.922197103500366\n",
      "Iteration 2500: loss 2.753770112991333\n",
      "Iteration 2501: loss 2.6847188472747803\n",
      "Iteration 2502: loss 2.7422680854797363\n",
      "Iteration 2503: loss 2.9260520935058594\n",
      "Iteration 2504: loss 2.9704785346984863\n",
      "Iteration 2505: loss 2.86944842338562\n",
      "Iteration 2506: loss 2.8054778575897217\n",
      "Iteration 2507: loss 2.8459932804107666\n",
      "Iteration 2508: loss 2.8318982124328613\n",
      "Iteration 2509: loss 2.679349422454834\n",
      "Iteration 2510: loss 2.846849203109741\n",
      "Iteration 2511: loss 2.9742071628570557\n",
      "Iteration 2512: loss 3.095998764038086\n",
      "Iteration 2513: loss 2.730006456375122\n",
      "Iteration 2514: loss 3.329864978790283\n",
      "Iteration 2515: loss 2.850832462310791\n",
      "Iteration 2516: loss 2.8531711101531982\n",
      "Iteration 2517: loss 3.207152843475342\n",
      "Iteration 2518: loss 3.0227675437927246\n",
      "Iteration 2519: loss 2.9222793579101562\n",
      "Iteration 2520: loss 2.93365740776062\n",
      "Iteration 2521: loss 2.9622819423675537\n",
      "Iteration 2522: loss 2.917881965637207\n",
      "Iteration 2523: loss 3.0230236053466797\n",
      "Iteration 2524: loss 2.9395713806152344\n",
      "Iteration 2525: loss 2.9207592010498047\n",
      "Iteration 2526: loss 2.9865198135375977\n",
      "Iteration 2527: loss 2.876345157623291\n",
      "Iteration 2528: loss 3.0186140537261963\n",
      "Iteration 2529: loss 2.90427303314209\n",
      "Iteration 2530: loss 2.8972723484039307\n",
      "Iteration 2531: loss 3.0814239978790283\n",
      "Iteration 2532: loss 2.8988802433013916\n",
      "Iteration 2533: loss 3.023271322250366\n",
      "Iteration 2534: loss 3.0755908489227295\n",
      "Iteration 2535: loss 2.930241346359253\n",
      "Iteration 2536: loss 2.75606632232666\n",
      "Iteration 2537: loss 3.099565267562866\n",
      "Iteration 2538: loss 2.8417859077453613\n",
      "Iteration 2539: loss 2.921745538711548\n",
      "Iteration 2540: loss 2.9650421142578125\n",
      "Iteration 2541: loss 3.2666876316070557\n",
      "Iteration 2542: loss 2.8090007305145264\n",
      "Iteration 2543: loss 2.8496551513671875\n",
      "Iteration 2544: loss 3.068146228790283\n",
      "Iteration 2545: loss 2.940925121307373\n",
      "Iteration 2546: loss 2.9748265743255615\n",
      "Iteration 2547: loss 2.9208638668060303\n",
      "Iteration 2548: loss 2.993927478790283\n",
      "Iteration 2549: loss 2.82818603515625\n",
      "Iteration 2550: loss 3.021488904953003\n",
      "Iteration 2551: loss 2.8891921043395996\n",
      "Iteration 2552: loss 2.8381590843200684\n",
      "Iteration 2553: loss 2.787069082260132\n",
      "Iteration 2554: loss 2.9292705059051514\n",
      "Iteration 2555: loss 2.794368267059326\n",
      "Iteration 2556: loss 2.9257376194000244\n",
      "Iteration 2557: loss 3.129307508468628\n",
      "Iteration 2558: loss 2.808245897293091\n",
      "Iteration 2559: loss 3.0513525009155273\n",
      "Iteration 2560: loss 2.9141595363616943\n",
      "Iteration 2561: loss 2.845378875732422\n",
      "Iteration 2562: loss 3.02197265625\n",
      "Iteration 2563: loss 3.056819438934326\n",
      "Iteration 2564: loss 3.0056285858154297\n",
      "Iteration 2565: loss 2.6942362785339355\n",
      "Iteration 2566: loss 2.8495030403137207\n",
      "Iteration 2567: loss 2.813755989074707\n",
      "Iteration 2568: loss 2.802945375442505\n",
      "Iteration 2569: loss 2.80985164642334\n",
      "Iteration 2570: loss 2.7580745220184326\n",
      "Iteration 2571: loss 2.7534291744232178\n",
      "Iteration 2572: loss 2.8695714473724365\n",
      "Iteration 2573: loss 2.966946840286255\n",
      "Iteration 2574: loss 3.03582501411438\n",
      "Iteration 2575: loss 2.9135735034942627\n",
      "Iteration 2576: loss 2.8435449600219727\n",
      "Iteration 2577: loss 3.033195734024048\n",
      "Iteration 2578: loss 2.773189067840576\n",
      "Iteration 2579: loss 2.9823694229125977\n",
      "Iteration 2580: loss 2.942706823348999\n",
      "Iteration 2581: loss 3.162914276123047\n",
      "Iteration 2582: loss 2.789691925048828\n",
      "Iteration 2583: loss 2.874774694442749\n",
      "Iteration 2584: loss 2.7585272789001465\n",
      "Iteration 2585: loss 3.062278985977173\n",
      "Iteration 2586: loss 2.9731554985046387\n",
      "Iteration 2587: loss 2.9010565280914307\n",
      "Iteration 2588: loss 2.910038948059082\n",
      "Iteration 2589: loss 2.941331386566162\n",
      "Iteration 2590: loss 2.719627618789673\n",
      "Iteration 2591: loss 2.97713565826416\n",
      "Iteration 2592: loss 2.889241933822632\n",
      "Iteration 2593: loss 2.757497549057007\n",
      "Iteration 2594: loss 2.8716201782226562\n",
      "Iteration 2595: loss 2.951489210128784\n",
      "Iteration 2596: loss 2.9484453201293945\n",
      "Iteration 2597: loss 2.838608980178833\n",
      "Iteration 2598: loss 2.8332817554473877\n",
      "Iteration 2599: loss 2.921962022781372\n",
      "Iteration 2600: loss 2.7744317054748535\n",
      "Iteration 2601: loss 2.888334274291992\n",
      "Iteration 2602: loss 3.0006673336029053\n",
      "Iteration 2603: loss 2.975775718688965\n",
      "Iteration 2604: loss 2.8429887294769287\n",
      "Iteration 2605: loss 2.893979072570801\n",
      "Iteration 2606: loss 3.0185723304748535\n",
      "Iteration 2607: loss 3.01786208152771\n",
      "Iteration 2608: loss 2.9554336071014404\n",
      "Iteration 2609: loss 3.0830719470977783\n",
      "Iteration 2610: loss 2.889589548110962\n",
      "Iteration 2611: loss 3.001147985458374\n",
      "Iteration 2612: loss 3.0527970790863037\n",
      "Iteration 2613: loss 2.8586199283599854\n",
      "Iteration 2614: loss 2.854116201400757\n",
      "Iteration 2615: loss 2.9384191036224365\n",
      "Iteration 2616: loss 2.8697192668914795\n",
      "Iteration 2617: loss 2.935433864593506\n",
      "Iteration 2618: loss 2.8355495929718018\n",
      "Iteration 2619: loss 2.8207523822784424\n",
      "Iteration 2620: loss 2.825152635574341\n",
      "Iteration 2621: loss 2.768054246902466\n",
      "Iteration 2622: loss 2.8148889541625977\n",
      "Iteration 2623: loss 2.8306639194488525\n",
      "Iteration 2624: loss 2.7316203117370605\n",
      "Iteration 2625: loss 2.691098690032959\n",
      "Iteration 2626: loss 2.9281742572784424\n",
      "Iteration 2627: loss 2.774930238723755\n",
      "Iteration 2628: loss 2.8100948333740234\n",
      "Iteration 2629: loss 2.891663074493408\n",
      "Iteration 2630: loss 2.9160375595092773\n",
      "Iteration 2631: loss 2.9233927726745605\n",
      "Iteration 2632: loss 2.817783832550049\n",
      "Iteration 2633: loss 2.757007360458374\n",
      "Iteration 2634: loss 2.6757683753967285\n",
      "Iteration 2635: loss 2.726632595062256\n",
      "Iteration 2636: loss 2.6550097465515137\n",
      "Iteration 2637: loss 2.86903977394104\n",
      "Iteration 2638: loss 3.1759843826293945\n",
      "Iteration 2639: loss 2.6484408378601074\n",
      "Iteration 2640: loss 2.7010295391082764\n",
      "Iteration 2641: loss 3.0212953090667725\n",
      "Iteration 2642: loss 2.761492967605591\n",
      "Iteration 2643: loss 3.1684868335723877\n",
      "Iteration 2644: loss 2.8943557739257812\n",
      "Iteration 2645: loss 2.918748140335083\n",
      "Iteration 2646: loss 2.6837151050567627\n",
      "Iteration 2647: loss 2.946024179458618\n",
      "Iteration 2648: loss 2.9253346920013428\n",
      "Iteration 2649: loss 2.7657079696655273\n",
      "Iteration 2650: loss 2.882965564727783\n",
      "Iteration 2651: loss 2.998842716217041\n",
      "Iteration 2652: loss 3.134235382080078\n",
      "Iteration 2653: loss 2.898162841796875\n",
      "Iteration 2654: loss 3.0439350605010986\n",
      "Iteration 2655: loss 2.693790912628174\n",
      "Iteration 2656: loss 2.8137638568878174\n",
      "Iteration 2657: loss 2.879277229309082\n",
      "Iteration 2658: loss 2.864347457885742\n",
      "Iteration 2659: loss 2.758552074432373\n",
      "Iteration 2660: loss 2.8677589893341064\n",
      "Iteration 2661: loss 2.912668466567993\n",
      "Iteration 2662: loss 2.650399684906006\n",
      "Iteration 2663: loss 2.690932035446167\n",
      "Iteration 2664: loss 2.9568934440612793\n",
      "Iteration 2665: loss 2.8574538230895996\n",
      "Iteration 2666: loss 2.945679187774658\n",
      "Iteration 2667: loss 2.9314992427825928\n",
      "Iteration 2668: loss 2.854121685028076\n",
      "Iteration 2669: loss 2.8130061626434326\n",
      "Iteration 2670: loss 2.7631139755249023\n",
      "Iteration 2671: loss 2.8608880043029785\n",
      "Iteration 2672: loss 2.706650972366333\n",
      "Iteration 2673: loss 2.8335697650909424\n",
      "Iteration 2674: loss 2.695707321166992\n",
      "Iteration 2675: loss 2.710563898086548\n",
      "Iteration 2676: loss 2.857407808303833\n",
      "Iteration 2677: loss 2.8634026050567627\n",
      "Iteration 2678: loss 3.653313398361206\n",
      "Iteration 2679: loss 3.730336904525757\n",
      "Iteration 2680: loss 3.788412094116211\n",
      "Iteration 2681: loss 3.1513781547546387\n",
      "Iteration 2682: loss 3.1645872592926025\n",
      "Iteration 2683: loss 3.289536952972412\n",
      "Iteration 2684: loss 3.2898178100585938\n",
      "Iteration 2685: loss 3.2688722610473633\n",
      "Iteration 2686: loss 3.381462574005127\n",
      "Iteration 2687: loss 3.4553816318511963\n",
      "Iteration 2688: loss 3.3634634017944336\n",
      "Iteration 2689: loss 3.364877939224243\n",
      "Iteration 2690: loss 3.2500109672546387\n",
      "Iteration 2691: loss 3.305277109146118\n",
      "Iteration 2692: loss 3.198829174041748\n",
      "Iteration 2693: loss 3.368056058883667\n",
      "Iteration 2694: loss 3.4110522270202637\n",
      "Iteration 2695: loss 3.23107647895813\n",
      "Iteration 2696: loss 3.4685778617858887\n",
      "Iteration 2697: loss 2.9759490489959717\n",
      "Iteration 2698: loss 3.1645116806030273\n",
      "Iteration 2699: loss 3.205247163772583\n",
      "Iteration 2700: loss 3.3337743282318115\n",
      "Iteration 2701: loss 3.4211180210113525\n",
      "Iteration 2702: loss 3.4164702892303467\n",
      "Iteration 2703: loss 3.1886627674102783\n",
      "Iteration 2704: loss 3.322850227355957\n",
      "Iteration 2705: loss 2.9345312118530273\n",
      "Iteration 2706: loss 3.1116764545440674\n",
      "Iteration 2707: loss 3.2917962074279785\n",
      "Iteration 2708: loss 3.094761610031128\n",
      "Iteration 2709: loss 3.332736015319824\n",
      "Iteration 2710: loss 3.0784361362457275\n",
      "Iteration 2711: loss 2.992166757583618\n",
      "Iteration 2712: loss 3.405601739883423\n",
      "Iteration 2713: loss 3.2737908363342285\n",
      "Iteration 2714: loss 3.1113011837005615\n",
      "Iteration 2715: loss 3.0959582328796387\n",
      "Iteration 2716: loss 2.9695000648498535\n",
      "Iteration 2717: loss 3.1567018032073975\n",
      "Iteration 2718: loss 3.1342175006866455\n",
      "Iteration 2719: loss 3.0224626064300537\n",
      "Iteration 2720: loss 3.2201344966888428\n",
      "Iteration 2721: loss 2.9849281311035156\n",
      "Iteration 2722: loss 3.1515111923217773\n",
      "Iteration 2723: loss 3.1782031059265137\n",
      "Iteration 2724: loss 3.256114959716797\n",
      "Iteration 2725: loss 2.8474981784820557\n",
      "Iteration 2726: loss 2.9682445526123047\n",
      "Iteration 2727: loss 3.292982816696167\n",
      "Iteration 2728: loss 3.0795793533325195\n",
      "Iteration 2729: loss 2.954486608505249\n",
      "Iteration 2730: loss 3.117525577545166\n",
      "Iteration 2731: loss 2.910604238510132\n",
      "Iteration 2732: loss 3.079268217086792\n",
      "Iteration 2733: loss 2.973020553588867\n",
      "Iteration 2734: loss 3.222421169281006\n",
      "Iteration 2735: loss 3.100329637527466\n",
      "Iteration 2736: loss 3.202953338623047\n",
      "Iteration 2737: loss 2.8872082233428955\n",
      "Iteration 2738: loss 3.1162590980529785\n",
      "Iteration 2739: loss 3.130934476852417\n",
      "Iteration 2740: loss 2.941850185394287\n",
      "Iteration 2741: loss 3.0798888206481934\n",
      "Iteration 2742: loss 3.055393695831299\n",
      "Iteration 2743: loss 2.942352771759033\n",
      "Iteration 2744: loss 2.9990429878234863\n",
      "Iteration 2745: loss 3.0774307250976562\n",
      "Iteration 2746: loss 3.0729990005493164\n",
      "Iteration 2747: loss 2.8463265895843506\n",
      "Iteration 2748: loss 3.051215410232544\n",
      "Iteration 2749: loss 3.0143237113952637\n",
      "Iteration 2750: loss 3.2282354831695557\n",
      "Iteration 2751: loss 3.137000560760498\n",
      "Iteration 2752: loss 2.7869813442230225\n",
      "Iteration 2753: loss 2.9929492473602295\n",
      "Iteration 2754: loss 2.9991276264190674\n",
      "Iteration 2755: loss 2.937541961669922\n",
      "Iteration 2756: loss 3.0527684688568115\n",
      "Iteration 2757: loss 2.9223506450653076\n",
      "Iteration 2758: loss 3.2241663932800293\n",
      "Iteration 2759: loss 3.1604485511779785\n",
      "Iteration 2760: loss 2.9942986965179443\n",
      "Iteration 2761: loss 3.034580707550049\n",
      "Iteration 2762: loss 3.101576805114746\n",
      "Iteration 2763: loss 2.7233200073242188\n",
      "Iteration 2764: loss 2.935016393661499\n",
      "Iteration 2765: loss 3.065462589263916\n",
      "Iteration 2766: loss 2.8711111545562744\n",
      "Iteration 2767: loss 3.025158643722534\n",
      "Iteration 2768: loss 2.9379260540008545\n",
      "Iteration 2769: loss 2.8665502071380615\n",
      "Iteration 2770: loss 3.0256831645965576\n",
      "Iteration 2771: loss 3.0166468620300293\n",
      "Iteration 2772: loss 3.108964204788208\n",
      "Iteration 2773: loss 2.795377731323242\n",
      "Iteration 2774: loss 2.9414873123168945\n",
      "Iteration 2775: loss 2.804135322570801\n",
      "Iteration 2776: loss 2.9977200031280518\n",
      "Iteration 2777: loss 2.994277238845825\n",
      "Iteration 2778: loss 3.003636598587036\n",
      "Iteration 2779: loss 2.875274658203125\n",
      "Iteration 2780: loss 3.0209507942199707\n",
      "Iteration 2781: loss 2.8244590759277344\n",
      "Iteration 2782: loss 2.79999041557312\n",
      "Iteration 2783: loss 2.921907901763916\n",
      "Iteration 2784: loss 2.875559091567993\n",
      "Iteration 2785: loss 2.8563342094421387\n",
      "Iteration 2786: loss 2.9612791538238525\n",
      "Iteration 2787: loss 3.0658373832702637\n",
      "Iteration 2788: loss 2.922389507293701\n",
      "Iteration 2789: loss 2.745326519012451\n",
      "Iteration 2790: loss 2.897439479827881\n",
      "Iteration 2791: loss 2.8968522548675537\n",
      "Iteration 2792: loss 2.9254000186920166\n",
      "Iteration 2793: loss 2.9466493129730225\n",
      "Iteration 2794: loss 3.03771710395813\n",
      "Iteration 2795: loss 2.768712043762207\n",
      "Iteration 2796: loss 2.7963898181915283\n",
      "Iteration 2797: loss 2.9085423946380615\n",
      "Iteration 2798: loss 2.9249937534332275\n",
      "Iteration 2799: loss 2.761521577835083\n",
      "Iteration 2800: loss 2.933692216873169\n",
      "Iteration 2801: loss 2.897529125213623\n",
      "Iteration 2802: loss 3.0026402473449707\n",
      "Iteration 2803: loss 2.9357120990753174\n",
      "Iteration 2804: loss 2.819326162338257\n",
      "Iteration 2805: loss 2.9280169010162354\n",
      "Iteration 2806: loss 3.0030815601348877\n",
      "Iteration 2807: loss 2.861766815185547\n",
      "Iteration 2808: loss 3.013066530227661\n",
      "Iteration 2809: loss 2.938782215118408\n",
      "Iteration 2810: loss 2.8866353034973145\n",
      "Iteration 2811: loss 2.813941478729248\n",
      "Iteration 2812: loss 2.8371825218200684\n",
      "Iteration 2813: loss 2.8045616149902344\n",
      "Iteration 2814: loss 3.0346293449401855\n",
      "Iteration 2815: loss 2.87091064453125\n",
      "Iteration 2816: loss 2.680894136428833\n",
      "Iteration 2817: loss 2.839064359664917\n",
      "Iteration 2818: loss 2.883998394012451\n",
      "Iteration 2819: loss 2.8504016399383545\n",
      "Iteration 2820: loss 2.8556365966796875\n",
      "Iteration 2821: loss 2.908806800842285\n",
      "Iteration 2822: loss 2.8914477825164795\n",
      "Iteration 2823: loss 2.9925310611724854\n",
      "Iteration 2824: loss 3.0066075325012207\n",
      "Iteration 2825: loss 2.892260789871216\n",
      "Iteration 2826: loss 2.8264520168304443\n",
      "Iteration 2827: loss 2.7328479290008545\n",
      "Iteration 2828: loss 2.929614782333374\n",
      "Iteration 2829: loss 2.8050739765167236\n",
      "Iteration 2830: loss 2.7561585903167725\n",
      "Iteration 2831: loss 2.863638162612915\n",
      "Iteration 2832: loss 2.942439556121826\n",
      "Iteration 2833: loss 2.834836959838867\n",
      "Iteration 2834: loss 2.9391984939575195\n",
      "Iteration 2835: loss 2.953099250793457\n",
      "Iteration 2836: loss 2.8833813667297363\n",
      "Iteration 2837: loss 2.892315626144409\n",
      "Iteration 2838: loss 3.0200915336608887\n",
      "Iteration 2839: loss 2.8579113483428955\n",
      "Iteration 2840: loss 2.9650213718414307\n",
      "Iteration 2841: loss 2.9160380363464355\n",
      "Iteration 2842: loss 2.8692424297332764\n",
      "Iteration 2843: loss 2.68847918510437\n",
      "Iteration 2844: loss 2.887214183807373\n",
      "Iteration 2845: loss 2.945261240005493\n",
      "Iteration 2846: loss 2.879645347595215\n",
      "Iteration 2847: loss 2.791264295578003\n",
      "Iteration 2848: loss 2.8643734455108643\n",
      "Iteration 2849: loss 2.866245746612549\n",
      "Iteration 2850: loss 2.809283494949341\n",
      "Iteration 2851: loss 2.880629301071167\n",
      "Iteration 2852: loss 2.659860134124756\n",
      "Iteration 2853: loss 2.7988345623016357\n",
      "Iteration 2854: loss 2.9647467136383057\n",
      "Iteration 2855: loss 2.9342381954193115\n",
      "Iteration 2856: loss 2.922943115234375\n",
      "Iteration 2857: loss 2.9011645317077637\n",
      "Iteration 2858: loss 2.80367374420166\n",
      "Iteration 2859: loss 2.802448034286499\n",
      "Iteration 2860: loss 2.887657403945923\n",
      "Iteration 2861: loss 2.8020617961883545\n",
      "Iteration 2862: loss 3.011824369430542\n",
      "Iteration 2863: loss 2.8354058265686035\n",
      "Iteration 2864: loss 2.7815356254577637\n",
      "Iteration 2865: loss 2.7576074600219727\n",
      "Iteration 2866: loss 2.734236478805542\n",
      "Iteration 2867: loss 2.784461259841919\n",
      "Iteration 2868: loss 2.7148516178131104\n",
      "Iteration 2869: loss 2.7557811737060547\n",
      "Iteration 2870: loss 2.9499363899230957\n",
      "Iteration 2871: loss 2.8039915561676025\n",
      "Iteration 2872: loss 2.7555651664733887\n",
      "Iteration 2873: loss 2.8942863941192627\n",
      "Iteration 2874: loss 2.666604518890381\n",
      "Iteration 2875: loss 2.710636615753174\n",
      "Iteration 2876: loss 2.7089898586273193\n",
      "Iteration 2877: loss 2.8574893474578857\n",
      "Iteration 2878: loss 2.71478271484375\n",
      "Iteration 2879: loss 2.813930034637451\n",
      "Iteration 2880: loss 2.7484757900238037\n",
      "Iteration 2881: loss 2.840555429458618\n",
      "Iteration 2882: loss 2.8953957557678223\n",
      "Iteration 2883: loss 2.793088912963867\n",
      "Iteration 2884: loss 2.7385549545288086\n",
      "Iteration 2885: loss 2.7842681407928467\n",
      "Iteration 2886: loss 2.766407012939453\n",
      "Iteration 2887: loss 2.7394049167633057\n",
      "Iteration 2888: loss 2.754180908203125\n",
      "Iteration 2889: loss 2.7021729946136475\n",
      "Iteration 2890: loss 2.8528828620910645\n",
      "Iteration 2891: loss 2.7978601455688477\n",
      "Iteration 2892: loss 2.907062292098999\n",
      "Iteration 2893: loss 2.839343547821045\n",
      "Iteration 2894: loss 2.677178382873535\n",
      "Iteration 2895: loss 2.692197799682617\n",
      "Iteration 2896: loss 2.8464670181274414\n",
      "Iteration 2897: loss 2.548766613006592\n",
      "Iteration 2898: loss 2.7618837356567383\n",
      "Iteration 2899: loss 2.8655030727386475\n",
      "Iteration 2900: loss 2.7476067543029785\n",
      "Iteration 2901: loss 2.7456612586975098\n",
      "Iteration 2902: loss 2.7631359100341797\n",
      "Iteration 2903: loss 2.8761327266693115\n",
      "Iteration 2904: loss 2.727220296859741\n",
      "Iteration 2905: loss 2.754957914352417\n",
      "Iteration 2906: loss 2.8538670539855957\n",
      "Iteration 2907: loss 2.666440486907959\n",
      "Iteration 2908: loss 2.6791317462921143\n",
      "Iteration 2909: loss 2.694898843765259\n",
      "Iteration 2910: loss 2.7512080669403076\n",
      "Iteration 2911: loss 2.8342254161834717\n",
      "Iteration 2912: loss 2.810811758041382\n",
      "Iteration 2913: loss 2.8981564044952393\n",
      "Iteration 2914: loss 2.82842755317688\n",
      "Iteration 2915: loss 2.730074167251587\n",
      "Iteration 2916: loss 2.9924235343933105\n",
      "Iteration 2917: loss 2.706482410430908\n",
      "Iteration 2918: loss 2.744300365447998\n",
      "Iteration 2919: loss 2.795482635498047\n",
      "Iteration 2920: loss 2.948410987854004\n",
      "Iteration 2921: loss 2.7272675037384033\n",
      "Iteration 2922: loss 2.9224274158477783\n",
      "Iteration 2923: loss 2.910252094268799\n",
      "Iteration 2924: loss 2.851255416870117\n",
      "Iteration 2925: loss 2.82495379447937\n",
      "Iteration 2926: loss 2.816854238510132\n",
      "Iteration 2927: loss 2.8132567405700684\n",
      "Iteration 2928: loss 2.68038272857666\n",
      "Iteration 2929: loss 2.5371062755584717\n",
      "Iteration 2930: loss 2.764336585998535\n",
      "Iteration 2931: loss 2.741398572921753\n",
      "Iteration 2932: loss 2.806342124938965\n",
      "Iteration 2933: loss 2.8797943592071533\n",
      "Iteration 2934: loss 2.813483238220215\n",
      "Iteration 2935: loss 2.7616400718688965\n",
      "Iteration 2936: loss 2.79540753364563\n",
      "Iteration 2937: loss 2.8026750087738037\n",
      "Iteration 2938: loss 2.74453067779541\n",
      "Iteration 2939: loss 2.80352520942688\n",
      "Iteration 2940: loss 2.553403615951538\n",
      "Iteration 2941: loss 2.846233367919922\n",
      "Iteration 2942: loss 2.793773651123047\n",
      "Iteration 2943: loss 2.7495689392089844\n",
      "Iteration 2944: loss 2.877450466156006\n",
      "Iteration 2945: loss 2.812326192855835\n",
      "Iteration 2946: loss 2.7713866233825684\n",
      "Iteration 2947: loss 2.6962075233459473\n",
      "Iteration 2948: loss 2.7491438388824463\n",
      "Iteration 2949: loss 2.82513689994812\n",
      "Iteration 2950: loss 2.7377336025238037\n",
      "Iteration 2951: loss 2.9386394023895264\n",
      "Iteration 2952: loss 2.6072332859039307\n",
      "Iteration 2953: loss 3.0433921813964844\n",
      "Iteration 2954: loss 2.7887423038482666\n",
      "Iteration 2955: loss 2.859219789505005\n",
      "Iteration 2956: loss 2.713986873626709\n",
      "Iteration 2957: loss 2.683441162109375\n",
      "Iteration 2958: loss 2.665278911590576\n",
      "Iteration 2959: loss 2.6957664489746094\n",
      "Iteration 2960: loss 2.63454532623291\n",
      "Iteration 2961: loss 2.932178258895874\n",
      "Iteration 2962: loss 2.7153735160827637\n",
      "Iteration 2963: loss 2.8402159214019775\n",
      "Iteration 2964: loss 2.717346668243408\n",
      "Iteration 2965: loss 2.6966748237609863\n",
      "Iteration 2966: loss 2.6331279277801514\n",
      "Iteration 2967: loss 2.8425822257995605\n",
      "Iteration 2968: loss 2.5371410846710205\n",
      "Iteration 2969: loss 2.8706579208374023\n",
      "Iteration 2970: loss 2.654580593109131\n",
      "Iteration 2971: loss 2.6426360607147217\n",
      "Iteration 2972: loss 2.8435657024383545\n",
      "Iteration 2973: loss 2.756132125854492\n",
      "Iteration 2974: loss 2.5993306636810303\n",
      "Iteration 2975: loss 2.7792887687683105\n",
      "Iteration 2976: loss 2.58476185798645\n",
      "Iteration 2977: loss 2.8374786376953125\n",
      "Iteration 2978: loss 2.607236862182617\n",
      "Iteration 2979: loss 2.7963452339172363\n",
      "Iteration 2980: loss 3.130242347717285\n",
      "Iteration 2981: loss 2.8110909461975098\n",
      "Iteration 2982: loss 2.518970012664795\n",
      "Iteration 2983: loss 2.7513506412506104\n",
      "Iteration 2984: loss 2.85202693939209\n",
      "Iteration 2985: loss 2.8148272037506104\n",
      "Iteration 2986: loss 2.71799635887146\n",
      "Iteration 2987: loss 2.7635252475738525\n",
      "Iteration 2988: loss 2.718327045440674\n",
      "Iteration 2989: loss 2.7787539958953857\n",
      "Iteration 2990: loss 2.9440362453460693\n",
      "Iteration 2991: loss 2.8628642559051514\n",
      "Iteration 2992: loss 2.7350780963897705\n",
      "Iteration 2993: loss 2.680896520614624\n",
      "Iteration 2994: loss 2.6306393146514893\n",
      "Iteration 2995: loss 2.7884037494659424\n",
      "Iteration 2996: loss 2.9535586833953857\n",
      "Iteration 2997: loss 2.7783281803131104\n",
      "Iteration 2998: loss 2.768239736557007\n",
      "Iteration 2999: loss 2.762705087661743\n",
      "Iteration 3000: loss 2.818866491317749\n",
      "Iteration 3001: loss 2.768061399459839\n",
      "Iteration 3002: loss 2.680377721786499\n",
      "Iteration 3003: loss 2.862994909286499\n",
      "Iteration 3004: loss 2.5048961639404297\n",
      "Iteration 3005: loss 2.7921268939971924\n",
      "Iteration 3006: loss 2.8781683444976807\n",
      "Iteration 3007: loss 2.74540638923645\n",
      "Iteration 3008: loss 2.771746873855591\n",
      "Iteration 3009: loss 2.693934917449951\n",
      "Iteration 3010: loss 2.9010167121887207\n",
      "Iteration 3011: loss 2.6382577419281006\n",
      "Iteration 3012: loss 2.6332268714904785\n",
      "Iteration 3013: loss 2.814154863357544\n",
      "Iteration 3014: loss 2.986133575439453\n",
      "Iteration 3015: loss 2.7916958332061768\n",
      "Iteration 3016: loss 2.8914053440093994\n",
      "Iteration 3017: loss 2.700855016708374\n",
      "Iteration 3018: loss 2.9140498638153076\n",
      "Iteration 3019: loss 2.8535754680633545\n",
      "Iteration 3020: loss 2.7957212924957275\n",
      "Iteration 3021: loss 2.697110176086426\n",
      "Iteration 3022: loss 2.7871336936950684\n",
      "Iteration 3023: loss 2.959428548812866\n",
      "Iteration 3024: loss 2.9696364402770996\n",
      "Iteration 3025: loss 3.0348331928253174\n",
      "Iteration 3026: loss 3.045623779296875\n",
      "Iteration 3027: loss 3.0328307151794434\n",
      "Iteration 3028: loss 2.927726984024048\n",
      "Iteration 3029: loss 2.9045586585998535\n",
      "Iteration 3030: loss 2.973384380340576\n",
      "Iteration 3031: loss 2.7925713062286377\n",
      "Iteration 3032: loss 2.8729870319366455\n",
      "Iteration 3033: loss 3.0555975437164307\n",
      "Iteration 3034: loss 2.903937339782715\n",
      "Iteration 3035: loss 2.8331730365753174\n",
      "Iteration 3036: loss 2.857715606689453\n",
      "Iteration 3037: loss 2.7830326557159424\n",
      "Iteration 3038: loss 2.7317287921905518\n",
      "Iteration 3039: loss 2.773696184158325\n",
      "Iteration 3040: loss 2.9556078910827637\n",
      "Iteration 3041: loss 2.908381938934326\n",
      "Iteration 3042: loss 3.003953218460083\n",
      "Iteration 3043: loss 2.7879128456115723\n",
      "Iteration 3044: loss 2.862217903137207\n",
      "Iteration 3045: loss 3.10461163520813\n",
      "Iteration 3046: loss 2.5829412937164307\n",
      "Iteration 3047: loss 2.587367534637451\n",
      "Iteration 3048: loss 2.6649444103240967\n",
      "Iteration 3049: loss 2.8615312576293945\n",
      "Iteration 3050: loss 2.872664213180542\n",
      "Iteration 3051: loss 2.882658004760742\n",
      "Iteration 3052: loss 2.908838987350464\n",
      "Iteration 3053: loss 2.7669243812561035\n",
      "Iteration 3054: loss 2.958204507827759\n",
      "Iteration 3055: loss 2.7261886596679688\n",
      "Iteration 3056: loss 2.76651930809021\n",
      "Iteration 3057: loss 2.85964298248291\n",
      "Iteration 3058: loss 2.7359747886657715\n",
      "Iteration 3059: loss 2.6249029636383057\n",
      "Iteration 3060: loss 2.8376219272613525\n",
      "Iteration 3061: loss 2.536057472229004\n",
      "Iteration 3062: loss 2.690183401107788\n",
      "Iteration 3063: loss 2.823112726211548\n",
      "Iteration 3064: loss 2.7721612453460693\n",
      "Iteration 3065: loss 2.636444091796875\n",
      "Iteration 3066: loss 2.69317626953125\n",
      "Iteration 3067: loss 2.669473171234131\n",
      "Iteration 3068: loss 2.872159004211426\n",
      "Iteration 3069: loss 2.739201545715332\n",
      "Iteration 3070: loss 2.668961763381958\n",
      "Iteration 3071: loss 2.7107503414154053\n",
      "Iteration 3072: loss 2.8851890563964844\n",
      "Iteration 3073: loss 2.6955742835998535\n",
      "Iteration 3074: loss 2.714919328689575\n",
      "Iteration 3075: loss 2.733611583709717\n",
      "Iteration 3076: loss 2.664246082305908\n",
      "Iteration 3077: loss 2.581589937210083\n",
      "Iteration 3078: loss 2.66367506980896\n",
      "Iteration 3079: loss 2.9627151489257812\n",
      "Iteration 3080: loss 2.759777784347534\n",
      "Iteration 3081: loss 2.7020366191864014\n",
      "Iteration 3082: loss 2.775160074234009\n",
      "Iteration 3083: loss 2.836177110671997\n",
      "Iteration 3084: loss 2.6267411708831787\n",
      "Iteration 3085: loss 2.6781535148620605\n",
      "Iteration 3086: loss 2.8377819061279297\n",
      "Iteration 3087: loss 2.758233070373535\n",
      "Iteration 3088: loss 2.633507013320923\n",
      "Iteration 3089: loss 2.8707592487335205\n",
      "Iteration 3090: loss 2.6690618991851807\n",
      "Iteration 3091: loss 2.8579483032226562\n",
      "Iteration 3092: loss 2.733118772506714\n",
      "Iteration 3093: loss 2.5853404998779297\n",
      "Iteration 3094: loss 2.7281646728515625\n",
      "Iteration 3095: loss 2.7953579425811768\n",
      "Iteration 3096: loss 2.902397394180298\n",
      "Iteration 3097: loss 2.6070282459259033\n",
      "Iteration 3098: loss 2.70284104347229\n",
      "Iteration 3099: loss 2.701019525527954\n",
      "Iteration 3100: loss 2.666750431060791\n",
      "Iteration 3101: loss 2.9085185527801514\n",
      "Iteration 3102: loss 2.70516300201416\n",
      "Iteration 3103: loss 2.6849937438964844\n",
      "Iteration 3104: loss 2.7921462059020996\n",
      "Iteration 3105: loss 2.582627534866333\n",
      "Iteration 3106: loss 3.029665231704712\n",
      "Iteration 3107: loss 2.7889022827148438\n",
      "Iteration 3108: loss 2.786025285720825\n",
      "Iteration 3109: loss 2.674534797668457\n",
      "Iteration 3110: loss 2.8627231121063232\n",
      "Iteration 3111: loss 2.835630416870117\n",
      "Iteration 3112: loss 2.738926649093628\n",
      "Iteration 3113: loss 2.8443472385406494\n",
      "Iteration 3114: loss 2.631075143814087\n",
      "Iteration 3115: loss 2.784907579421997\n",
      "Iteration 3116: loss 2.8218016624450684\n",
      "Iteration 3117: loss 2.7350125312805176\n",
      "Iteration 3118: loss 2.692497730255127\n",
      "Iteration 3119: loss 2.8071093559265137\n",
      "Iteration 3120: loss 2.856729030609131\n",
      "Iteration 3121: loss 2.7151620388031006\n",
      "Iteration 3122: loss 2.660219669342041\n",
      "Iteration 3123: loss 2.7850663661956787\n",
      "Iteration 3124: loss 2.843696117401123\n",
      "Iteration 3125: loss 2.753798723220825\n",
      "Iteration 3126: loss 2.852144718170166\n",
      "Iteration 3127: loss 2.5735015869140625\n",
      "Iteration 3128: loss 2.656085968017578\n",
      "Iteration 3129: loss 2.701166868209839\n",
      "Iteration 3130: loss 2.8943886756896973\n",
      "Iteration 3131: loss 2.7508599758148193\n",
      "Iteration 3132: loss 2.527608633041382\n",
      "Iteration 3133: loss 2.562633514404297\n",
      "Iteration 3134: loss 2.682798147201538\n",
      "Iteration 3135: loss 2.838149309158325\n",
      "Iteration 3136: loss 2.7724037170410156\n",
      "Iteration 3137: loss 2.8979272842407227\n",
      "Iteration 3138: loss 2.602672576904297\n",
      "Iteration 3139: loss 2.7914340496063232\n",
      "Iteration 3140: loss 2.829862594604492\n",
      "Iteration 3141: loss 2.555446147918701\n",
      "Iteration 3142: loss 2.6598315238952637\n",
      "Iteration 3143: loss 2.8647408485412598\n",
      "Iteration 3144: loss 2.5503413677215576\n",
      "Iteration 3145: loss 2.7016797065734863\n",
      "Iteration 3146: loss 2.756618022918701\n",
      "Iteration 3147: loss 2.816915512084961\n",
      "Iteration 3148: loss 2.83418869972229\n",
      "Iteration 3149: loss 2.786543607711792\n",
      "Iteration 3150: loss 2.68465256690979\n",
      "Iteration 3151: loss 2.9747302532196045\n",
      "Iteration 3152: loss 2.973576545715332\n",
      "Iteration 3153: loss 2.7237133979797363\n",
      "Iteration 3154: loss 2.841728448867798\n",
      "Iteration 3155: loss 2.6509268283843994\n",
      "Iteration 3156: loss 2.73443865776062\n",
      "Iteration 3157: loss 2.692155599594116\n",
      "Iteration 3158: loss 2.534799337387085\n",
      "Iteration 3159: loss 2.7511420249938965\n",
      "Iteration 3160: loss 2.690854787826538\n",
      "Iteration 3161: loss 2.6881871223449707\n",
      "Iteration 3162: loss 2.840210437774658\n",
      "Iteration 3163: loss 2.829099655151367\n",
      "Iteration 3164: loss 2.7371466159820557\n",
      "Iteration 3165: loss 2.684739351272583\n",
      "Iteration 3166: loss 2.5772383213043213\n",
      "Iteration 3167: loss 2.79215407371521\n",
      "Iteration 3168: loss 2.7163500785827637\n",
      "Iteration 3169: loss 2.775132656097412\n",
      "Iteration 3170: loss 2.679560899734497\n",
      "Iteration 3171: loss 2.8101425170898438\n",
      "Iteration 3172: loss 2.620678663253784\n",
      "Iteration 3173: loss 2.8407673835754395\n",
      "Iteration 3174: loss 2.716209650039673\n",
      "Iteration 3175: loss 2.847217559814453\n",
      "Iteration 3176: loss 2.937229871749878\n",
      "Iteration 3177: loss 2.7441864013671875\n",
      "Iteration 3178: loss 2.847010374069214\n",
      "Iteration 3179: loss 2.8080782890319824\n",
      "Iteration 3180: loss 2.6859793663024902\n",
      "Iteration 3181: loss 2.8233697414398193\n",
      "Iteration 3182: loss 2.688776731491089\n",
      "Iteration 3183: loss 2.6172773838043213\n",
      "Iteration 3184: loss 2.767256498336792\n",
      "Iteration 3185: loss 2.8720664978027344\n",
      "Iteration 3186: loss 2.726130962371826\n",
      "Iteration 3187: loss 2.9027764797210693\n",
      "Iteration 3188: loss 2.747370958328247\n",
      "Iteration 3189: loss 2.978351354598999\n",
      "Iteration 3190: loss 2.654510974884033\n",
      "Iteration 3191: loss 2.5637848377227783\n",
      "Iteration 3192: loss 2.7221293449401855\n",
      "Iteration 3193: loss 2.673429012298584\n",
      "Iteration 3194: loss 2.580153703689575\n",
      "Iteration 3195: loss 2.609320640563965\n",
      "Iteration 3196: loss 2.7740678787231445\n",
      "Iteration 3197: loss 2.6489927768707275\n",
      "Iteration 3198: loss 2.736177921295166\n",
      "Iteration 3199: loss 2.7316224575042725\n",
      "Iteration 3200: loss 2.7251088619232178\n",
      "Iteration 3201: loss 2.8538599014282227\n",
      "Iteration 3202: loss 2.7226402759552\n",
      "Iteration 3203: loss 2.8582699298858643\n",
      "Iteration 3204: loss 2.7076377868652344\n",
      "Iteration 3205: loss 2.619438648223877\n",
      "Iteration 3206: loss 2.8528828620910645\n",
      "Iteration 3207: loss 2.7720303535461426\n",
      "Iteration 3208: loss 2.64762544631958\n",
      "Iteration 3209: loss 2.852722406387329\n",
      "Iteration 3210: loss 2.9266481399536133\n",
      "Iteration 3211: loss 2.7474827766418457\n",
      "Iteration 3212: loss 2.7554211616516113\n",
      "Iteration 3213: loss 2.9369661808013916\n",
      "Iteration 3214: loss 2.835427761077881\n",
      "Iteration 3215: loss 2.713768243789673\n",
      "Iteration 3216: loss 2.882634162902832\n",
      "Iteration 3217: loss 2.7158639430999756\n",
      "Iteration 3218: loss 2.767771005630493\n",
      "Iteration 3219: loss 2.9200308322906494\n",
      "Iteration 3220: loss 2.67655611038208\n",
      "Iteration 3221: loss 2.875844717025757\n",
      "Iteration 3222: loss 2.782667398452759\n",
      "Iteration 3223: loss 2.873494863510132\n",
      "Iteration 3224: loss 2.698690176010132\n",
      "Iteration 3225: loss 2.7963876724243164\n",
      "Iteration 3226: loss 2.6464500427246094\n",
      "Iteration 3227: loss 2.906048536300659\n",
      "Iteration 3228: loss 2.7162227630615234\n",
      "Iteration 3229: loss 2.7151145935058594\n",
      "Iteration 3230: loss 2.8691368103027344\n",
      "Iteration 3231: loss 2.637087345123291\n",
      "Iteration 3232: loss 2.714956521987915\n",
      "Iteration 3233: loss 2.909362316131592\n",
      "Iteration 3234: loss 2.958446502685547\n",
      "Iteration 3235: loss 2.6271345615386963\n",
      "Iteration 3236: loss 2.756925344467163\n",
      "Iteration 3237: loss 2.659050226211548\n",
      "Iteration 3238: loss 2.8737196922302246\n",
      "Iteration 3239: loss 2.9007792472839355\n",
      "Iteration 3240: loss 2.947216510772705\n",
      "Iteration 3241: loss 2.8724589347839355\n",
      "Iteration 3242: loss 2.6362876892089844\n",
      "Iteration 3243: loss 2.7341439723968506\n",
      "Iteration 3244: loss 2.663853645324707\n",
      "Iteration 3245: loss 2.7819039821624756\n",
      "Iteration 3246: loss 2.6645538806915283\n",
      "Iteration 3247: loss 2.7357592582702637\n",
      "Iteration 3248: loss 2.6959776878356934\n",
      "Iteration 3249: loss 2.732560873031616\n",
      "Iteration 3250: loss 2.678875684738159\n",
      "Iteration 3251: loss 2.80487060546875\n",
      "Iteration 3252: loss 2.8881499767303467\n",
      "Iteration 3253: loss 2.6437106132507324\n",
      "Iteration 3254: loss 2.6668925285339355\n",
      "Iteration 3255: loss 2.8154072761535645\n",
      "Iteration 3256: loss 2.7087130546569824\n",
      "Iteration 3257: loss 2.6228139400482178\n",
      "Iteration 3258: loss 2.7109837532043457\n",
      "Iteration 3259: loss 2.705559730529785\n",
      "Iteration 3260: loss 2.685972213745117\n",
      "Iteration 3261: loss 2.7098028659820557\n",
      "Iteration 3262: loss 2.781156301498413\n",
      "Iteration 3263: loss 2.6810476779937744\n",
      "Iteration 3264: loss 2.5885121822357178\n",
      "Iteration 3265: loss 2.7389614582061768\n",
      "Iteration 3266: loss 2.7215113639831543\n",
      "Iteration 3267: loss 2.754384756088257\n",
      "Iteration 3268: loss 2.826007604598999\n",
      "Iteration 3269: loss 2.5283148288726807\n",
      "Iteration 3270: loss 2.8246002197265625\n",
      "Iteration 3271: loss 2.6063616275787354\n",
      "Iteration 3272: loss 2.760899543762207\n",
      "Iteration 3273: loss 2.80706524848938\n",
      "Iteration 3274: loss 2.635952949523926\n",
      "Iteration 3275: loss 2.7319176197052\n",
      "Iteration 3276: loss 2.770200252532959\n",
      "Iteration 3277: loss 2.6504921913146973\n",
      "Iteration 3278: loss 2.7127647399902344\n",
      "Iteration 3279: loss 2.8572728633880615\n",
      "Iteration 3280: loss 2.7406413555145264\n",
      "Iteration 3281: loss 2.8766121864318848\n",
      "Iteration 3282: loss 2.7750887870788574\n",
      "Iteration 3283: loss 2.708919048309326\n",
      "Iteration 3284: loss 2.774082660675049\n",
      "Iteration 3285: loss 2.935232400894165\n",
      "Iteration 3286: loss 2.8053371906280518\n",
      "Iteration 3287: loss 2.8565709590911865\n",
      "Iteration 3288: loss 2.959186315536499\n",
      "Iteration 3289: loss 2.740809202194214\n",
      "Iteration 3290: loss 2.9980907440185547\n",
      "Iteration 3291: loss 2.872544765472412\n",
      "Iteration 3292: loss 2.8846428394317627\n",
      "Iteration 3293: loss 2.825946092605591\n",
      "Iteration 3294: loss 2.830972194671631\n",
      "Iteration 3295: loss 2.7125914096832275\n",
      "Iteration 3296: loss 2.908276081085205\n",
      "Iteration 3297: loss 2.8526580333709717\n",
      "Iteration 3298: loss 2.7425146102905273\n",
      "Iteration 3299: loss 2.824033737182617\n",
      "Iteration 3300: loss 2.8049004077911377\n",
      "Iteration 3301: loss 2.8253092765808105\n",
      "Iteration 3302: loss 2.8093059062957764\n",
      "Iteration 3303: loss 2.9108452796936035\n",
      "Iteration 3304: loss 2.7487704753875732\n",
      "Iteration 3305: loss 2.8511009216308594\n",
      "Iteration 3306: loss 2.8497085571289062\n",
      "Iteration 3307: loss 2.688016891479492\n",
      "Iteration 3308: loss 2.874776601791382\n",
      "Iteration 3309: loss 2.778578519821167\n",
      "Iteration 3310: loss 2.7075624465942383\n",
      "Iteration 3311: loss 2.796722412109375\n",
      "Iteration 3312: loss 2.602560043334961\n",
      "Iteration 3313: loss 2.8943288326263428\n",
      "Iteration 3314: loss 2.8564703464508057\n",
      "Iteration 3315: loss 2.6620166301727295\n",
      "Iteration 3316: loss 2.93058705329895\n",
      "Iteration 3317: loss 2.793614387512207\n",
      "Iteration 3318: loss 2.584026336669922\n",
      "Iteration 3319: loss 2.695347785949707\n",
      "Iteration 3320: loss 2.7190959453582764\n",
      "Iteration 3321: loss 2.7624473571777344\n",
      "Iteration 3322: loss 2.813187599182129\n",
      "Iteration 3323: loss 2.788414239883423\n",
      "Iteration 3324: loss 2.8691952228546143\n",
      "Iteration 3325: loss 2.868060827255249\n",
      "Iteration 3326: loss 2.9707536697387695\n",
      "Iteration 3327: loss 2.7295336723327637\n",
      "Iteration 3328: loss 2.7079601287841797\n",
      "Iteration 3329: loss 2.814229726791382\n",
      "Iteration 3330: loss 2.737346649169922\n",
      "Iteration 3331: loss 2.8422398567199707\n",
      "Iteration 3332: loss 2.856177568435669\n",
      "Iteration 3333: loss 2.9052257537841797\n",
      "Iteration 3334: loss 2.8443613052368164\n",
      "Iteration 3335: loss 2.7223994731903076\n",
      "Iteration 3336: loss 2.7826101779937744\n",
      "Iteration 3337: loss 2.7178056240081787\n",
      "Iteration 3338: loss 2.862356424331665\n",
      "Iteration 3339: loss 2.8645143508911133\n",
      "Iteration 3340: loss 2.8345611095428467\n",
      "Iteration 3341: loss 2.8243303298950195\n",
      "Iteration 3342: loss 2.7238306999206543\n",
      "Iteration 3343: loss 2.7916259765625\n",
      "Iteration 3344: loss 2.5178091526031494\n",
      "Iteration 3345: loss 2.8095240592956543\n",
      "Iteration 3346: loss 2.5712361335754395\n",
      "Iteration 3347: loss 2.7658910751342773\n",
      "Iteration 3348: loss 2.698944330215454\n",
      "Iteration 3349: loss 2.6768155097961426\n",
      "Iteration 3350: loss 2.5262608528137207\n",
      "Iteration 3351: loss 2.7974298000335693\n",
      "Iteration 3352: loss 2.881931781768799\n",
      "Iteration 3353: loss 2.693477153778076\n",
      "Iteration 3354: loss 2.6816956996917725\n",
      "Iteration 3355: loss 2.857240915298462\n",
      "Iteration 3356: loss 2.6318678855895996\n",
      "Iteration 3357: loss 2.758420944213867\n",
      "Iteration 3358: loss 2.626218557357788\n",
      "Iteration 3359: loss 2.63320255279541\n",
      "Iteration 3360: loss 2.538411855697632\n",
      "Iteration 3361: loss 2.6017730236053467\n",
      "Iteration 3362: loss 2.762136220932007\n",
      "Iteration 3363: loss 2.734705686569214\n",
      "Iteration 3364: loss 2.708148956298828\n",
      "Iteration 3365: loss 2.66671085357666\n",
      "Iteration 3366: loss 2.5448412895202637\n",
      "Iteration 3367: loss 2.929661273956299\n",
      "Iteration 3368: loss 2.766136407852173\n",
      "Iteration 3369: loss 2.706874370574951\n",
      "Iteration 3370: loss 2.885823965072632\n",
      "Iteration 3371: loss 2.8234198093414307\n",
      "Iteration 3372: loss 2.905780076980591\n",
      "Iteration 3373: loss 2.700517177581787\n",
      "Iteration 3374: loss 2.685563325881958\n",
      "Iteration 3375: loss 2.7455761432647705\n",
      "Iteration 3376: loss 2.7862889766693115\n",
      "Iteration 3377: loss 2.8887343406677246\n",
      "Iteration 3378: loss 2.548215627670288\n",
      "Iteration 3379: loss 2.8333466053009033\n",
      "Iteration 3380: loss 2.812112331390381\n",
      "Iteration 3381: loss 2.745296001434326\n",
      "Iteration 3382: loss 2.7167937755584717\n",
      "Iteration 3383: loss 2.6688055992126465\n",
      "Iteration 3384: loss 2.7146284580230713\n",
      "Iteration 3385: loss 2.539297342300415\n",
      "Iteration 3386: loss 2.6718432903289795\n",
      "Iteration 3387: loss 2.802992582321167\n",
      "Iteration 3388: loss 2.6807408332824707\n",
      "Iteration 3389: loss 2.8189032077789307\n",
      "Iteration 3390: loss 2.8382863998413086\n",
      "Iteration 3391: loss 2.716388463973999\n",
      "Iteration 3392: loss 2.7753994464874268\n",
      "Iteration 3393: loss 2.7107527256011963\n",
      "Iteration 3394: loss 2.580585241317749\n",
      "Iteration 3395: loss 2.8740031719207764\n",
      "Iteration 3396: loss 2.7272984981536865\n",
      "Iteration 3397: loss 2.8349924087524414\n",
      "Iteration 3398: loss 2.8901007175445557\n",
      "Iteration 3399: loss 2.7929744720458984\n",
      "Iteration 3400: loss 3.0532848834991455\n",
      "Iteration 3401: loss 2.7085704803466797\n",
      "Iteration 3402: loss 2.7821996212005615\n",
      "Iteration 3403: loss 2.716947555541992\n",
      "Iteration 3404: loss 2.718844175338745\n",
      "Iteration 3405: loss 2.6756811141967773\n",
      "Iteration 3406: loss 2.7562365531921387\n",
      "Iteration 3407: loss 2.675356149673462\n",
      "Iteration 3408: loss 2.5408358573913574\n",
      "Iteration 3409: loss 2.7107927799224854\n",
      "Iteration 3410: loss 2.7601583003997803\n",
      "Iteration 3411: loss 2.7514636516571045\n",
      "Iteration 3412: loss 2.6536238193511963\n",
      "Iteration 3413: loss 2.827376127243042\n",
      "Iteration 3414: loss 2.6178882122039795\n",
      "Iteration 3415: loss 2.759629487991333\n",
      "Iteration 3416: loss 2.7593846321105957\n",
      "Iteration 3417: loss 2.8183207511901855\n",
      "Iteration 3418: loss 2.748194456100464\n",
      "Iteration 3419: loss 2.9023377895355225\n",
      "Iteration 3420: loss 2.62176513671875\n",
      "Iteration 3421: loss 2.6068227291107178\n",
      "Iteration 3422: loss 2.741323709487915\n",
      "Iteration 3423: loss 2.728142738342285\n",
      "Iteration 3424: loss 2.7469213008880615\n",
      "Iteration 3425: loss 2.7711169719696045\n",
      "Iteration 3426: loss 2.6488237380981445\n",
      "Iteration 3427: loss 2.7193264961242676\n",
      "Iteration 3428: loss 2.6126513481140137\n",
      "Iteration 3429: loss 2.875016689300537\n",
      "Iteration 3430: loss 2.731372833251953\n",
      "Iteration 3431: loss 2.8943850994110107\n",
      "Iteration 3432: loss 2.766702175140381\n",
      "Iteration 3433: loss 2.661346673965454\n",
      "Iteration 3434: loss 2.6807093620300293\n",
      "Iteration 3435: loss 2.788548707962036\n",
      "Iteration 3436: loss 2.643265962600708\n",
      "Iteration 3437: loss 2.5120933055877686\n",
      "Iteration 3438: loss 2.784514904022217\n",
      "Iteration 3439: loss 2.6737418174743652\n",
      "Iteration 3440: loss 2.6257472038269043\n",
      "Iteration 3441: loss 2.7453346252441406\n",
      "Iteration 3442: loss 2.5955235958099365\n",
      "Iteration 3443: loss 2.6921215057373047\n",
      "Iteration 3444: loss 2.740588903427124\n",
      "Iteration 3445: loss 2.775662422180176\n",
      "Iteration 3446: loss 2.590981960296631\n",
      "Iteration 3447: loss 2.6171557903289795\n",
      "Iteration 3448: loss 2.7764687538146973\n",
      "Iteration 3449: loss 2.753552198410034\n",
      "Iteration 3450: loss 2.7237932682037354\n",
      "Iteration 3451: loss 2.6521410942077637\n",
      "Iteration 3452: loss 2.722012519836426\n",
      "Iteration 3453: loss 2.5991244316101074\n",
      "Iteration 3454: loss 2.720123291015625\n",
      "Iteration 3455: loss 2.65932297706604\n",
      "Iteration 3456: loss 2.610980987548828\n",
      "Iteration 3457: loss 2.6791186332702637\n",
      "Iteration 3458: loss 2.6406569480895996\n",
      "Iteration 3459: loss 2.721230983734131\n",
      "Iteration 3460: loss 2.621978282928467\n",
      "Iteration 3461: loss 2.7774105072021484\n",
      "Iteration 3462: loss 2.759279489517212\n",
      "Iteration 3463: loss 2.705052375793457\n",
      "Iteration 3464: loss 2.4524765014648438\n",
      "Iteration 3465: loss 2.6595022678375244\n",
      "Iteration 3466: loss 2.748566150665283\n",
      "Iteration 3467: loss 2.7550880908966064\n",
      "Iteration 3468: loss 2.640308141708374\n",
      "Iteration 3469: loss 2.6451327800750732\n",
      "Iteration 3470: loss 2.7067711353302\n",
      "Iteration 3471: loss 2.5370516777038574\n",
      "Iteration 3472: loss 2.7114336490631104\n",
      "Iteration 3473: loss 2.5474507808685303\n",
      "Iteration 3474: loss 2.6960535049438477\n",
      "Iteration 3475: loss 2.539076566696167\n",
      "Iteration 3476: loss 2.657947540283203\n",
      "Iteration 3477: loss 2.7740511894226074\n",
      "Iteration 3478: loss 2.7167046070098877\n",
      "Iteration 3479: loss 2.7153429985046387\n",
      "Iteration 3480: loss 2.5253746509552\n",
      "Iteration 3481: loss 2.5825185775756836\n",
      "Iteration 3482: loss 2.8163883686065674\n",
      "Iteration 3483: loss 2.6038260459899902\n",
      "Iteration 3484: loss 2.780656576156616\n",
      "Iteration 3485: loss 2.836818218231201\n",
      "Iteration 3486: loss 2.828005313873291\n",
      "Iteration 3487: loss 2.4809677600860596\n",
      "Iteration 3488: loss 2.6415834426879883\n",
      "Iteration 3489: loss 2.81459379196167\n",
      "Iteration 3490: loss 2.8125622272491455\n",
      "Iteration 3491: loss 2.8365654945373535\n",
      "Iteration 3492: loss 2.648589611053467\n",
      "Iteration 3493: loss 2.6281182765960693\n",
      "Iteration 3494: loss 2.724311351776123\n",
      "Iteration 3495: loss 2.6254289150238037\n",
      "Iteration 3496: loss 2.8360071182250977\n",
      "Iteration 3497: loss 2.728955030441284\n",
      "Iteration 3498: loss 2.7711377143859863\n",
      "Iteration 3499: loss 2.9924278259277344\n",
      "Iteration 3500: loss 2.659785032272339\n",
      "Iteration 3501: loss 2.7508111000061035\n",
      "Iteration 3502: loss 2.9085495471954346\n",
      "Iteration 3503: loss 2.7089760303497314\n",
      "Iteration 3504: loss 2.6933345794677734\n",
      "Iteration 3505: loss 2.7416393756866455\n",
      "Iteration 3506: loss 2.645048141479492\n",
      "Iteration 3507: loss 2.849346876144409\n",
      "Iteration 3508: loss 2.75924015045166\n",
      "Iteration 3509: loss 2.577965021133423\n",
      "Iteration 3510: loss 2.729109525680542\n",
      "Iteration 3511: loss 2.7061374187469482\n",
      "Iteration 3512: loss 2.7079200744628906\n",
      "Iteration 3513: loss 2.6331727504730225\n",
      "Iteration 3514: loss 2.738140821456909\n",
      "Iteration 3515: loss 2.8260083198547363\n",
      "Iteration 3516: loss 2.7227439880371094\n",
      "Iteration 3517: loss 2.639549732208252\n",
      "Iteration 3518: loss 2.712547779083252\n",
      "Iteration 3519: loss 2.7123422622680664\n",
      "Iteration 3520: loss 2.692089796066284\n",
      "Iteration 3521: loss 2.755122661590576\n",
      "Iteration 3522: loss 2.6920037269592285\n",
      "Iteration 3523: loss 2.6274468898773193\n",
      "Iteration 3524: loss 2.747359037399292\n",
      "Iteration 3525: loss 2.8694732189178467\n",
      "Iteration 3526: loss 2.810380697250366\n",
      "Iteration 3527: loss 2.8992059230804443\n",
      "Iteration 3528: loss 2.792464017868042\n",
      "Iteration 3529: loss 2.827280282974243\n",
      "Iteration 3530: loss 2.749595880508423\n",
      "Iteration 3531: loss 2.9171061515808105\n",
      "Iteration 3532: loss 2.7287230491638184\n",
      "Iteration 3533: loss 2.5386648178100586\n",
      "Iteration 3534: loss 2.8858642578125\n",
      "Iteration 3535: loss 2.6692662239074707\n",
      "Iteration 3536: loss 2.5826611518859863\n",
      "Iteration 3537: loss 2.8229777812957764\n",
      "Iteration 3538: loss 2.6632931232452393\n",
      "Iteration 3539: loss 2.8158981800079346\n",
      "Iteration 3540: loss 2.6606838703155518\n",
      "Iteration 3541: loss 2.5944724082946777\n",
      "Iteration 3542: loss 2.623368978500366\n",
      "Iteration 3543: loss 2.693171262741089\n",
      "Iteration 3544: loss 2.5445735454559326\n",
      "Iteration 3545: loss 2.5811352729797363\n",
      "Iteration 3546: loss 2.7251293659210205\n",
      "Iteration 3547: loss 2.433547258377075\n",
      "Iteration 3548: loss 2.715686082839966\n",
      "Iteration 3549: loss 2.676762104034424\n",
      "Iteration 3550: loss 2.6084086894989014\n",
      "Iteration 3551: loss 2.672337055206299\n",
      "Iteration 3552: loss 2.651151657104492\n",
      "Iteration 3553: loss 2.7380621433258057\n",
      "Iteration 3554: loss 2.649090528488159\n",
      "Iteration 3555: loss 2.553731679916382\n",
      "Iteration 3556: loss 2.692051649093628\n",
      "Iteration 3557: loss 2.679340124130249\n",
      "Iteration 3558: loss 2.5603911876678467\n",
      "Iteration 3559: loss 2.6424612998962402\n",
      "Iteration 3560: loss 2.7485997676849365\n",
      "Iteration 3561: loss 2.717161178588867\n",
      "Iteration 3562: loss 2.8329405784606934\n",
      "Iteration 3563: loss 2.917020082473755\n",
      "Iteration 3564: loss 2.5720231533050537\n",
      "Iteration 3565: loss 2.8067781925201416\n",
      "Iteration 3566: loss 2.6465492248535156\n",
      "Iteration 3567: loss 2.7010533809661865\n",
      "Iteration 3568: loss 2.58815336227417\n",
      "Iteration 3569: loss 2.776916027069092\n",
      "Iteration 3570: loss 2.5287201404571533\n",
      "Iteration 3571: loss 2.5301780700683594\n",
      "Iteration 3572: loss 2.7584352493286133\n",
      "Iteration 3573: loss 2.923527717590332\n",
      "Iteration 3574: loss 2.7358360290527344\n",
      "Iteration 3575: loss 2.6644339561462402\n",
      "Iteration 3576: loss 2.7031521797180176\n",
      "Iteration 3577: loss 2.803945302963257\n",
      "Iteration 3578: loss 2.571117877960205\n",
      "Iteration 3579: loss 2.735044240951538\n",
      "Iteration 3580: loss 2.7807066440582275\n",
      "Iteration 3581: loss 2.640981912612915\n",
      "Iteration 3582: loss 2.7563531398773193\n",
      "Iteration 3583: loss 2.742971181869507\n",
      "Iteration 3584: loss 2.632152557373047\n",
      "Iteration 3585: loss 2.574958324432373\n",
      "Iteration 3586: loss 2.6379897594451904\n",
      "Iteration 3587: loss 2.8309972286224365\n",
      "Iteration 3588: loss 2.5712027549743652\n",
      "Iteration 3589: loss 2.6479218006134033\n",
      "Iteration 3590: loss 2.686802387237549\n",
      "Iteration 3591: loss 2.618945837020874\n",
      "Iteration 3592: loss 2.49086332321167\n",
      "Iteration 3593: loss 2.608499765396118\n",
      "Iteration 3594: loss 2.618089437484741\n",
      "Iteration 3595: loss 2.582714080810547\n",
      "Iteration 3596: loss 2.6081628799438477\n",
      "Iteration 3597: loss 2.8289177417755127\n",
      "Iteration 3598: loss 2.547960042953491\n",
      "Iteration 3599: loss 2.7812163829803467\n",
      "Iteration 3600: loss 2.848156690597534\n",
      "Iteration 3601: loss 2.78987979888916\n",
      "Iteration 3602: loss 2.751487970352173\n",
      "Iteration 3603: loss 2.659320592880249\n",
      "Iteration 3604: loss 2.7189671993255615\n",
      "Iteration 3605: loss 2.6797924041748047\n",
      "Iteration 3606: loss 2.711397647857666\n",
      "Iteration 3607: loss 2.654437780380249\n",
      "Iteration 3608: loss 2.443154811859131\n",
      "Iteration 3609: loss 2.762547016143799\n",
      "Iteration 3610: loss 2.799595832824707\n",
      "Iteration 3611: loss 2.79683518409729\n",
      "Iteration 3612: loss 2.957798957824707\n",
      "Iteration 3613: loss 2.8245112895965576\n",
      "Iteration 3614: loss 2.7051525115966797\n",
      "Iteration 3615: loss 2.633333444595337\n",
      "Iteration 3616: loss 2.7424211502075195\n",
      "Iteration 3617: loss 2.8879668712615967\n",
      "Iteration 3618: loss 2.676466703414917\n",
      "Iteration 3619: loss 2.8663604259490967\n",
      "Iteration 3620: loss 2.883833885192871\n",
      "Iteration 3621: loss 2.6872944831848145\n",
      "Iteration 3622: loss 2.7417964935302734\n",
      "Iteration 3623: loss 2.640469551086426\n",
      "Iteration 3624: loss 2.65140438079834\n",
      "Iteration 3625: loss 2.83190655708313\n",
      "Iteration 3626: loss 2.6947076320648193\n",
      "Iteration 3627: loss 2.6956963539123535\n",
      "Iteration 3628: loss 2.8293068408966064\n",
      "Iteration 3629: loss 2.6451449394226074\n",
      "Iteration 3630: loss 2.615811347961426\n",
      "Iteration 3631: loss 2.7130649089813232\n",
      "Iteration 3632: loss 2.782442569732666\n",
      "Iteration 3633: loss 2.6956474781036377\n",
      "Iteration 3634: loss 2.7688629627227783\n",
      "Iteration 3635: loss 2.5470292568206787\n",
      "Iteration 3636: loss 2.7759013175964355\n",
      "Iteration 3637: loss 2.7426507472991943\n",
      "Iteration 3638: loss 2.696380138397217\n",
      "Iteration 3639: loss 2.624582529067993\n",
      "Iteration 3640: loss 2.8219218254089355\n",
      "Iteration 3641: loss 2.726172924041748\n",
      "Iteration 3642: loss 2.709703207015991\n",
      "Iteration 3643: loss 2.735851764678955\n",
      "Iteration 3644: loss 2.6651036739349365\n",
      "Iteration 3645: loss 2.7725820541381836\n",
      "Iteration 3646: loss 2.716604471206665\n",
      "Iteration 3647: loss 2.641843318939209\n",
      "Iteration 3648: loss 2.590847969055176\n",
      "Iteration 3649: loss 2.66896390914917\n",
      "Iteration 3650: loss 2.70290207862854\n",
      "Iteration 3651: loss 2.822333574295044\n",
      "Iteration 3652: loss 2.6967809200286865\n",
      "Iteration 3653: loss 2.67356276512146\n",
      "Iteration 3654: loss 2.7853012084960938\n",
      "Iteration 3655: loss 2.6718950271606445\n",
      "Iteration 3656: loss 2.5860259532928467\n",
      "Iteration 3657: loss 2.748857259750366\n",
      "Iteration 3658: loss 2.7101876735687256\n",
      "Iteration 3659: loss 2.5525553226470947\n",
      "Iteration 3660: loss 2.721669912338257\n",
      "Iteration 3661: loss 2.7295196056365967\n",
      "Iteration 3662: loss 2.7501144409179688\n",
      "Iteration 3663: loss 2.666862726211548\n",
      "Iteration 3664: loss 2.5986857414245605\n",
      "Iteration 3665: loss 2.6586477756500244\n",
      "Iteration 3666: loss 2.798025131225586\n",
      "Iteration 3667: loss 2.6268551349639893\n",
      "Iteration 3668: loss 2.6641948223114014\n",
      "Iteration 3669: loss 2.630692720413208\n",
      "Iteration 3670: loss 2.713527202606201\n",
      "Iteration 3671: loss 2.593592405319214\n",
      "Iteration 3672: loss 2.608736753463745\n",
      "Iteration 3673: loss 2.807595729827881\n",
      "Iteration 3674: loss 2.6554582118988037\n",
      "Iteration 3675: loss 2.7077293395996094\n",
      "Iteration 3676: loss 2.6400554180145264\n",
      "Iteration 3677: loss 2.4755077362060547\n",
      "Iteration 3678: loss 2.5784506797790527\n",
      "Iteration 3679: loss 2.601353406906128\n",
      "Iteration 3680: loss 2.556595802307129\n",
      "Iteration 3681: loss 2.69093656539917\n",
      "Iteration 3682: loss 2.7943193912506104\n",
      "Iteration 3683: loss 2.7805111408233643\n",
      "Iteration 3684: loss 2.703152656555176\n",
      "Iteration 3685: loss 2.682131290435791\n",
      "Iteration 3686: loss 2.6289398670196533\n",
      "Iteration 3687: loss 2.742849349975586\n",
      "Iteration 3688: loss 2.6708779335021973\n",
      "Iteration 3689: loss 2.734675168991089\n",
      "Iteration 3690: loss 2.689849853515625\n",
      "Iteration 3691: loss 2.659013271331787\n",
      "Iteration 3692: loss 2.6159331798553467\n",
      "Iteration 3693: loss 2.604548215866089\n",
      "Iteration 3694: loss 2.677244186401367\n",
      "Iteration 3695: loss 2.7035744190216064\n",
      "Iteration 3696: loss 2.783360719680786\n",
      "Iteration 3697: loss 2.5328667163848877\n",
      "Iteration 3698: loss 2.668895721435547\n",
      "Iteration 3699: loss 2.5805959701538086\n",
      "Iteration 3700: loss 2.632159471511841\n",
      "Iteration 3701: loss 2.592155694961548\n",
      "Iteration 3702: loss 2.6736998558044434\n",
      "Iteration 3703: loss 2.6391987800598145\n",
      "Iteration 3704: loss 2.6882050037384033\n",
      "Iteration 3705: loss 2.7389633655548096\n",
      "Iteration 3706: loss 2.565326690673828\n",
      "Iteration 3707: loss 2.6550612449645996\n",
      "Iteration 3708: loss 2.6752092838287354\n",
      "Iteration 3709: loss 2.711491584777832\n",
      "Iteration 3710: loss 2.7473764419555664\n",
      "Iteration 3711: loss 2.695413827896118\n",
      "Iteration 3712: loss 2.6905832290649414\n",
      "Iteration 3713: loss 2.803579568862915\n",
      "Iteration 3714: loss 2.644681453704834\n",
      "Iteration 3715: loss 2.775134801864624\n",
      "Iteration 3716: loss 2.664949893951416\n",
      "Iteration 3717: loss 2.7863476276397705\n",
      "Iteration 3718: loss 2.863316774368286\n",
      "Iteration 3719: loss 2.7103161811828613\n",
      "Iteration 3720: loss 2.9562478065490723\n",
      "Iteration 3721: loss 2.807680606842041\n",
      "Iteration 3722: loss 2.597759246826172\n",
      "Iteration 3723: loss 2.67696475982666\n",
      "Iteration 3724: loss 2.518981456756592\n",
      "Iteration 3725: loss 2.688912868499756\n",
      "Iteration 3726: loss 2.705260753631592\n",
      "Iteration 3727: loss 2.7091121673583984\n",
      "Iteration 3728: loss 2.7036001682281494\n",
      "Iteration 3729: loss 2.8041718006134033\n",
      "Iteration 3730: loss 2.5538461208343506\n",
      "Iteration 3731: loss 2.6605563163757324\n",
      "Iteration 3732: loss 2.6537957191467285\n",
      "Iteration 3733: loss 2.5915751457214355\n",
      "Iteration 3734: loss 2.689513683319092\n",
      "Iteration 3735: loss 2.6494030952453613\n",
      "Iteration 3736: loss 2.531743049621582\n",
      "Iteration 3737: loss 2.866438865661621\n",
      "Iteration 3738: loss 2.9877068996429443\n",
      "Iteration 3739: loss 2.7439122200012207\n",
      "Iteration 3740: loss 2.6524975299835205\n",
      "Iteration 3741: loss 2.409411668777466\n",
      "Iteration 3742: loss 2.5087828636169434\n",
      "Iteration 3743: loss 2.7883315086364746\n",
      "Iteration 3744: loss 2.6759674549102783\n",
      "Iteration 3745: loss 2.676539182662964\n",
      "Iteration 3746: loss 2.519547939300537\n",
      "Iteration 3747: loss 2.8420369625091553\n",
      "Iteration 3748: loss 2.8231794834136963\n",
      "Iteration 3749: loss 2.732294797897339\n",
      "Iteration 3750: loss 2.6886260509490967\n",
      "Iteration 3751: loss 2.567777633666992\n",
      "Iteration 3752: loss 2.759661912918091\n",
      "Iteration 3753: loss 2.5295112133026123\n",
      "Iteration 3754: loss 2.552212953567505\n",
      "Iteration 3755: loss 2.5286853313446045\n",
      "Iteration 3756: loss 2.507878541946411\n",
      "Iteration 3757: loss 2.6670145988464355\n",
      "Iteration 3758: loss 2.7585396766662598\n",
      "Iteration 3759: loss 2.599874258041382\n",
      "Iteration 3760: loss 2.7227494716644287\n",
      "Iteration 3761: loss 2.6127967834472656\n",
      "Iteration 3762: loss 2.6628811359405518\n",
      "Iteration 3763: loss 2.8353724479675293\n",
      "Iteration 3764: loss 2.765684127807617\n",
      "Iteration 3765: loss 2.649796724319458\n",
      "Iteration 3766: loss 2.7382524013519287\n",
      "Iteration 3767: loss 2.929600715637207\n",
      "Iteration 3768: loss 2.8020105361938477\n",
      "Iteration 3769: loss 2.601093053817749\n",
      "Iteration 3770: loss 2.6409928798675537\n",
      "Iteration 3771: loss 2.4650158882141113\n",
      "Iteration 3772: loss 2.8271102905273438\n",
      "Iteration 3773: loss 2.8650543689727783\n",
      "Iteration 3774: loss 2.6477463245391846\n",
      "Iteration 3775: loss 2.7367138862609863\n",
      "Iteration 3776: loss 2.6602532863616943\n",
      "Iteration 3777: loss 2.642223358154297\n",
      "Iteration 3778: loss 2.603327512741089\n",
      "Iteration 3779: loss 2.5764238834381104\n",
      "Iteration 3780: loss 2.632887125015259\n",
      "Iteration 3781: loss 2.7539291381835938\n",
      "Iteration 3782: loss 2.702800750732422\n",
      "Iteration 3783: loss 2.696519136428833\n",
      "Iteration 3784: loss 2.6508169174194336\n",
      "Iteration 3785: loss 2.6997532844543457\n",
      "Iteration 3786: loss 2.635148525238037\n",
      "Iteration 3787: loss 2.7867867946624756\n",
      "Iteration 3788: loss 2.644340753555298\n",
      "Iteration 3789: loss 2.744389057159424\n",
      "Iteration 3790: loss 2.686605453491211\n",
      "Iteration 3791: loss 2.571444272994995\n",
      "Iteration 3792: loss 2.740595579147339\n",
      "Iteration 3793: loss 2.6731064319610596\n",
      "Iteration 3794: loss 2.624910831451416\n",
      "Iteration 3795: loss 2.6584808826446533\n",
      "Iteration 3796: loss 2.712981700897217\n",
      "Iteration 3797: loss 2.5377206802368164\n",
      "Iteration 3798: loss 2.6853251457214355\n",
      "Iteration 3799: loss 2.814887046813965\n",
      "Iteration 3800: loss 2.710308790206909\n",
      "Iteration 3801: loss 2.7733819484710693\n",
      "Iteration 3802: loss 3.0109469890594482\n",
      "Iteration 3803: loss 2.8154938220977783\n",
      "Iteration 3804: loss 2.786983013153076\n",
      "Iteration 3805: loss 2.7086329460144043\n",
      "Iteration 3806: loss 2.756819486618042\n",
      "Iteration 3807: loss 2.9343903064727783\n",
      "Iteration 3808: loss 2.975112199783325\n",
      "Iteration 3809: loss 2.9985148906707764\n",
      "Iteration 3810: loss 2.8162059783935547\n",
      "Iteration 3811: loss 2.7003753185272217\n",
      "Iteration 3812: loss 2.994980812072754\n",
      "Iteration 3813: loss 2.5776467323303223\n",
      "Iteration 3814: loss 2.7036454677581787\n",
      "Iteration 3815: loss 2.80373477935791\n",
      "Iteration 3816: loss 2.6721303462982178\n",
      "Iteration 3817: loss 2.9484899044036865\n",
      "Iteration 3818: loss 2.7113211154937744\n",
      "Iteration 3819: loss 2.866206645965576\n",
      "Iteration 3820: loss 2.559689998626709\n",
      "Iteration 3821: loss 2.965240478515625\n",
      "Iteration 3822: loss 2.5099337100982666\n",
      "Iteration 3823: loss 2.6728224754333496\n",
      "Iteration 3824: loss 2.8107364177703857\n",
      "Iteration 3825: loss 2.7740941047668457\n",
      "Iteration 3826: loss 2.863905191421509\n",
      "Iteration 3827: loss 2.834707021713257\n",
      "Iteration 3828: loss 2.7184417247772217\n",
      "Iteration 3829: loss 2.628316640853882\n",
      "Iteration 3830: loss 2.862426280975342\n",
      "Iteration 3831: loss 2.728172540664673\n",
      "Iteration 3832: loss 2.8618578910827637\n",
      "Iteration 3833: loss 2.85282826423645\n",
      "Iteration 3834: loss 2.904069185256958\n",
      "Iteration 3835: loss 2.7786450386047363\n",
      "Iteration 3836: loss 2.7813093662261963\n",
      "Iteration 3837: loss 2.6799893379211426\n",
      "Iteration 3838: loss 2.716207265853882\n",
      "Iteration 3839: loss 2.65826678276062\n",
      "Iteration 3840: loss 2.5697855949401855\n",
      "Iteration 3841: loss 2.630756139755249\n",
      "Iteration 3842: loss 2.726475238800049\n",
      "Iteration 3843: loss 2.895164728164673\n",
      "Iteration 3844: loss 2.7230420112609863\n",
      "Iteration 3845: loss 2.5729308128356934\n",
      "Iteration 3846: loss 2.7816436290740967\n",
      "Iteration 3847: loss 2.6489245891571045\n",
      "Iteration 3848: loss 2.642505645751953\n",
      "Iteration 3849: loss 2.8284294605255127\n",
      "Iteration 3850: loss 2.614089250564575\n",
      "Iteration 3851: loss 2.7767882347106934\n",
      "Iteration 3852: loss 2.4014668464660645\n",
      "Iteration 3853: loss 2.8049871921539307\n",
      "Iteration 3854: loss 2.716813087463379\n",
      "Iteration 3855: loss 2.6477208137512207\n",
      "Iteration 3856: loss 2.8022704124450684\n",
      "Iteration 3857: loss 2.7310197353363037\n",
      "Iteration 3858: loss 2.7684123516082764\n",
      "Iteration 3859: loss 2.6757266521453857\n",
      "Iteration 3860: loss 2.746741771697998\n",
      "Iteration 3861: loss 2.7186179161071777\n",
      "Iteration 3862: loss 2.675690174102783\n",
      "Iteration 3863: loss 2.8060600757598877\n",
      "Iteration 3864: loss 2.7748773097991943\n",
      "Iteration 3865: loss 2.7244746685028076\n",
      "Iteration 3866: loss 2.8696985244750977\n",
      "Iteration 3867: loss 2.943593740463257\n",
      "Iteration 3868: loss 3.0175845623016357\n",
      "Iteration 3869: loss 3.0645811557769775\n",
      "Iteration 3870: loss 3.0119850635528564\n",
      "Iteration 3871: loss 2.696530818939209\n",
      "Iteration 3872: loss 2.930182456970215\n",
      "Iteration 3873: loss 3.004152774810791\n",
      "Iteration 3874: loss 2.942340850830078\n",
      "Iteration 3875: loss 2.6418471336364746\n",
      "Iteration 3876: loss 2.8962371349334717\n",
      "Iteration 3877: loss 2.7731969356536865\n",
      "Iteration 3878: loss 2.7964956760406494\n",
      "Iteration 3879: loss 2.7420904636383057\n",
      "Iteration 3880: loss 2.8322556018829346\n",
      "Iteration 3881: loss 2.792229652404785\n",
      "Iteration 3882: loss 2.781676769256592\n",
      "Iteration 3883: loss 2.695737838745117\n",
      "Iteration 3884: loss 2.8680834770202637\n",
      "Iteration 3885: loss 2.810708522796631\n",
      "Iteration 3886: loss 2.673762798309326\n",
      "Iteration 3887: loss 2.689531087875366\n",
      "Iteration 3888: loss 2.7785046100616455\n",
      "Iteration 3889: loss 2.7423272132873535\n",
      "Iteration 3890: loss 2.493180990219116\n",
      "Iteration 3891: loss 2.8002824783325195\n",
      "Iteration 3892: loss 2.7503609657287598\n",
      "Iteration 3893: loss 2.802891492843628\n",
      "Iteration 3894: loss 2.769354820251465\n",
      "Iteration 3895: loss 2.480788469314575\n",
      "Iteration 3896: loss 2.709106683731079\n",
      "Iteration 3897: loss 2.490971803665161\n",
      "Iteration 3898: loss 2.8204076290130615\n",
      "Iteration 3899: loss 2.626544237136841\n",
      "Iteration 3900: loss 2.8642046451568604\n",
      "Iteration 3901: loss 2.67960524559021\n",
      "Iteration 3902: loss 2.6231298446655273\n",
      "Iteration 3903: loss 2.862848997116089\n",
      "Iteration 3904: loss 2.764874219894409\n",
      "Iteration 3905: loss 2.6914515495300293\n",
      "Iteration 3906: loss 2.7834389209747314\n",
      "Iteration 3907: loss 2.8260366916656494\n",
      "Iteration 3908: loss 2.609062433242798\n",
      "Iteration 3909: loss 2.680051803588867\n",
      "Iteration 3910: loss 2.8141438961029053\n",
      "Iteration 3911: loss 2.585136651992798\n",
      "Iteration 3912: loss 2.5840020179748535\n",
      "Iteration 3913: loss 2.9166765213012695\n",
      "Iteration 3914: loss 2.7067131996154785\n",
      "Iteration 3915: loss 2.7601916790008545\n",
      "Iteration 3916: loss 2.9332079887390137\n",
      "Iteration 3917: loss 2.634350538253784\n",
      "Iteration 3918: loss 2.7567334175109863\n",
      "Iteration 3919: loss 2.5925211906433105\n",
      "Iteration 3920: loss 2.7696123123168945\n",
      "Iteration 3921: loss 2.894706964492798\n",
      "Iteration 3922: loss 2.775726318359375\n",
      "Iteration 3923: loss 2.6772027015686035\n",
      "Iteration 3924: loss 2.7765963077545166\n",
      "Iteration 3925: loss 2.685765266418457\n",
      "Iteration 3926: loss 2.7541472911834717\n",
      "Iteration 3927: loss 2.687870502471924\n",
      "Iteration 3928: loss 2.6867117881774902\n",
      "Iteration 3929: loss 2.7447938919067383\n",
      "Iteration 3930: loss 2.5617730617523193\n",
      "Iteration 3931: loss 2.837144136428833\n",
      "Iteration 3932: loss 2.7525267601013184\n",
      "Iteration 3933: loss 2.721254825592041\n",
      "Iteration 3934: loss 2.7460849285125732\n",
      "Iteration 3935: loss 2.772132158279419\n",
      "Iteration 3936: loss 2.690739631652832\n",
      "Iteration 3937: loss 2.69008731842041\n",
      "Iteration 3938: loss 2.5990734100341797\n",
      "Iteration 3939: loss 2.760355234146118\n",
      "Iteration 3940: loss 2.555562973022461\n",
      "Iteration 3941: loss 2.6077446937561035\n",
      "Iteration 3942: loss 2.7916183471679688\n",
      "Iteration 3943: loss 2.579132080078125\n",
      "Iteration 3944: loss 2.6006579399108887\n",
      "Iteration 3945: loss 2.670524835586548\n",
      "Iteration 3946: loss 2.6675221920013428\n",
      "Iteration 3947: loss 2.7304277420043945\n",
      "Iteration 3948: loss 2.7644009590148926\n",
      "Iteration 3949: loss 2.701650857925415\n",
      "Iteration 3950: loss 2.686542272567749\n",
      "Iteration 3951: loss 2.623474359512329\n",
      "Iteration 3952: loss 2.6284236907958984\n",
      "Iteration 3953: loss 2.593280076980591\n",
      "Iteration 3954: loss 2.568751096725464\n",
      "Iteration 3955: loss 2.700906991958618\n",
      "Iteration 3956: loss 2.8642332553863525\n",
      "Iteration 3957: loss 2.5482897758483887\n",
      "Iteration 3958: loss 2.611764669418335\n",
      "Iteration 3959: loss 2.5931897163391113\n",
      "Iteration 3960: loss 2.5032384395599365\n",
      "Iteration 3961: loss 2.674299478530884\n",
      "Iteration 3962: loss 2.8351237773895264\n",
      "Iteration 3963: loss 2.738300085067749\n",
      "Iteration 3964: loss 2.5841102600097656\n",
      "Iteration 3965: loss 2.6695573329925537\n",
      "Iteration 3966: loss 2.6126091480255127\n",
      "Iteration 3967: loss 2.7298011779785156\n",
      "Iteration 3968: loss 2.856863021850586\n",
      "Iteration 3969: loss 2.6424560546875\n",
      "Iteration 3970: loss 2.562628746032715\n",
      "Iteration 3971: loss 2.8321163654327393\n",
      "Iteration 3972: loss 2.750779867172241\n",
      "Iteration 3973: loss 2.7769317626953125\n",
      "Iteration 3974: loss 2.6556572914123535\n",
      "Iteration 3975: loss 2.7577338218688965\n",
      "Iteration 3976: loss 2.6647050380706787\n",
      "Iteration 3977: loss 2.5000946521759033\n",
      "Iteration 3978: loss 2.7355570793151855\n",
      "Iteration 3979: loss 2.671893358230591\n",
      "Iteration 3980: loss 2.694650888442993\n",
      "Iteration 3981: loss 2.6317403316497803\n",
      "Iteration 3982: loss 2.6618685722351074\n",
      "Iteration 3983: loss 2.7214088439941406\n",
      "Iteration 3984: loss 2.699296474456787\n",
      "Iteration 3985: loss 2.638380765914917\n",
      "Iteration 3986: loss 2.7716357707977295\n",
      "Iteration 3987: loss 2.556745767593384\n",
      "Iteration 3988: loss 2.6028459072113037\n",
      "Iteration 3989: loss 2.5304112434387207\n",
      "Iteration 3990: loss 2.6234848499298096\n",
      "Iteration 3991: loss 2.555691719055176\n",
      "Iteration 3992: loss 2.58426570892334\n",
      "Iteration 3993: loss 2.6869757175445557\n",
      "Iteration 3994: loss 2.6004843711853027\n",
      "Iteration 3995: loss 2.467773199081421\n",
      "Iteration 3996: loss 2.541574001312256\n",
      "Iteration 3997: loss 2.6995294094085693\n",
      "Iteration 3998: loss 2.8665411472320557\n",
      "Iteration 3999: loss 2.724575996398926\n",
      "Iteration 4000: loss 2.725419282913208\n",
      "Iteration 4001: loss 2.428342342376709\n",
      "Iteration 4002: loss 2.706395149230957\n",
      "Iteration 4003: loss 2.680304527282715\n",
      "Iteration 4004: loss 2.6903631687164307\n",
      "Iteration 4005: loss 2.72054123878479\n",
      "Iteration 4006: loss 2.535722017288208\n",
      "Iteration 4007: loss 2.5753941535949707\n",
      "Iteration 4008: loss 2.829854965209961\n",
      "Iteration 4009: loss 2.6308581829071045\n",
      "Iteration 4010: loss 2.7223305702209473\n",
      "Iteration 4011: loss 2.681819438934326\n",
      "Iteration 4012: loss 2.570669174194336\n",
      "Iteration 4013: loss 2.6354358196258545\n",
      "Iteration 4014: loss 2.639349937438965\n",
      "Iteration 4015: loss 2.4336869716644287\n",
      "Iteration 4016: loss 2.6740527153015137\n",
      "Iteration 4017: loss 2.710892915725708\n",
      "Iteration 4018: loss 2.64321231842041\n",
      "Iteration 4019: loss 2.650360584259033\n",
      "Iteration 4020: loss 3.0178780555725098\n",
      "Iteration 4021: loss 2.572070360183716\n",
      "Iteration 4022: loss 2.9175243377685547\n",
      "Iteration 4023: loss 2.7299389839172363\n",
      "Iteration 4024: loss 2.964452028274536\n",
      "Iteration 4025: loss 2.881094217300415\n",
      "Iteration 4026: loss 2.7631731033325195\n",
      "Iteration 4027: loss 2.8373498916625977\n",
      "Iteration 4028: loss 2.6737124919891357\n",
      "Iteration 4029: loss 2.767073392868042\n",
      "Iteration 4030: loss 2.584167957305908\n",
      "Iteration 4031: loss 2.691659450531006\n",
      "Iteration 4032: loss 2.745842218399048\n",
      "Iteration 4033: loss 2.8530609607696533\n",
      "Iteration 4034: loss 2.824416399002075\n",
      "Iteration 4035: loss 2.7735610008239746\n",
      "Iteration 4036: loss 2.716254711151123\n",
      "Iteration 4037: loss 2.7696056365966797\n",
      "Iteration 4038: loss 2.797050952911377\n",
      "Iteration 4039: loss 2.6666555404663086\n",
      "Iteration 4040: loss 2.659362316131592\n",
      "Iteration 4041: loss 2.6162309646606445\n",
      "Iteration 4042: loss 2.8906402587890625\n",
      "Iteration 4043: loss 2.695873737335205\n",
      "Iteration 4044: loss 2.693880558013916\n",
      "Iteration 4045: loss 2.7971954345703125\n",
      "Iteration 4046: loss 2.713965892791748\n",
      "Iteration 4047: loss 2.756298780441284\n",
      "Iteration 4048: loss 2.623185873031616\n",
      "Iteration 4049: loss 2.6009044647216797\n",
      "Iteration 4050: loss 2.623661518096924\n",
      "Iteration 4051: loss 2.623055934906006\n",
      "Iteration 4052: loss 2.6352319717407227\n",
      "Iteration 4053: loss 2.7190492153167725\n",
      "Iteration 4054: loss 2.5760271549224854\n",
      "Iteration 4055: loss 2.813403367996216\n",
      "Iteration 4056: loss 2.6859002113342285\n",
      "Iteration 4057: loss 2.544337749481201\n",
      "Iteration 4058: loss 2.709336519241333\n",
      "Iteration 4059: loss 2.602146625518799\n",
      "Iteration 4060: loss 2.6639561653137207\n",
      "Iteration 4061: loss 2.842996120452881\n",
      "Iteration 4062: loss 2.6371099948883057\n",
      "Iteration 4063: loss 2.8180558681488037\n",
      "Iteration 4064: loss 2.658834218978882\n",
      "Iteration 4065: loss 2.482778310775757\n",
      "Iteration 4066: loss 2.66585111618042\n",
      "Iteration 4067: loss 2.7508387565612793\n",
      "Iteration 4068: loss 2.5816404819488525\n",
      "Iteration 4069: loss 2.9337992668151855\n",
      "Iteration 4070: loss 2.658024787902832\n",
      "Iteration 4071: loss 2.71498966217041\n",
      "Iteration 4072: loss 2.795825719833374\n",
      "Iteration 4073: loss 2.8157365322113037\n",
      "Iteration 4074: loss 2.6705267429351807\n",
      "Iteration 4075: loss 2.830540657043457\n",
      "Iteration 4076: loss 2.723720073699951\n",
      "Iteration 4077: loss 2.699758768081665\n",
      "Iteration 4078: loss 2.690248966217041\n",
      "Iteration 4079: loss 2.5722334384918213\n",
      "Iteration 4080: loss 2.6586508750915527\n",
      "Iteration 4081: loss 2.516449451446533\n",
      "Iteration 4082: loss 2.6768603324890137\n",
      "Iteration 4083: loss 2.749366283416748\n",
      "Iteration 4084: loss 2.473982095718384\n",
      "Iteration 4085: loss 2.5973029136657715\n",
      "Iteration 4086: loss 2.71405029296875\n",
      "Iteration 4087: loss 2.9186785221099854\n",
      "Iteration 4088: loss 2.649467945098877\n",
      "Iteration 4089: loss 2.6986889839172363\n",
      "Iteration 4090: loss 2.7892906665802\n",
      "Iteration 4091: loss 2.5207414627075195\n",
      "Iteration 4092: loss 2.7768208980560303\n",
      "Iteration 4093: loss 2.7821223735809326\n",
      "Iteration 4094: loss 2.5770039558410645\n",
      "Iteration 4095: loss 2.878807306289673\n",
      "Iteration 4096: loss 2.752692222595215\n",
      "Iteration 4097: loss 2.6825637817382812\n",
      "Iteration 4098: loss 2.738940477371216\n",
      "Iteration 4099: loss 2.634859561920166\n",
      "Iteration 4100: loss 2.5456619262695312\n",
      "Iteration 4101: loss 2.7442643642425537\n",
      "Iteration 4102: loss 2.435943841934204\n",
      "Iteration 4103: loss 2.8038594722747803\n",
      "Iteration 4104: loss 2.556248188018799\n",
      "Iteration 4105: loss 2.6936004161834717\n",
      "Iteration 4106: loss 2.614374876022339\n",
      "Iteration 4107: loss 2.6208724975585938\n",
      "Iteration 4108: loss 2.609605550765991\n",
      "Iteration 4109: loss 2.703400135040283\n",
      "Iteration 4110: loss 2.620312213897705\n",
      "Iteration 4111: loss 2.6612799167633057\n",
      "Iteration 4112: loss 2.66940975189209\n",
      "Iteration 4113: loss 2.604161262512207\n",
      "Iteration 4114: loss 2.5608339309692383\n",
      "Iteration 4115: loss 2.574761390686035\n",
      "Iteration 4116: loss 2.6818246841430664\n",
      "Iteration 4117: loss 2.5181069374084473\n",
      "Iteration 4118: loss 2.4907851219177246\n",
      "Iteration 4119: loss 2.6654694080352783\n",
      "Iteration 4120: loss 2.666369676589966\n",
      "Iteration 4121: loss 2.654294729232788\n",
      "Iteration 4122: loss 2.7482941150665283\n",
      "Iteration 4123: loss 2.625150442123413\n",
      "Iteration 4124: loss 2.5794529914855957\n",
      "Iteration 4125: loss 2.852309465408325\n",
      "Iteration 4126: loss 2.775212287902832\n",
      "Iteration 4127: loss 2.580209255218506\n",
      "Iteration 4128: loss 2.7429263591766357\n",
      "Iteration 4129: loss 2.907115936279297\n",
      "Iteration 4130: loss 2.6387956142425537\n",
      "Iteration 4131: loss 2.82243275642395\n",
      "Iteration 4132: loss 2.8682591915130615\n",
      "Iteration 4133: loss 2.685314655303955\n",
      "Iteration 4134: loss 2.540017604827881\n",
      "Iteration 4135: loss 2.598691463470459\n",
      "Iteration 4136: loss 2.7463219165802\n",
      "Iteration 4137: loss 2.7026402950286865\n",
      "Iteration 4138: loss 2.7470574378967285\n",
      "Iteration 4139: loss 2.8666107654571533\n",
      "Iteration 4140: loss 2.6180310249328613\n",
      "Iteration 4141: loss 2.5594117641448975\n",
      "Iteration 4142: loss 2.5690298080444336\n",
      "Iteration 4143: loss 2.5378646850585938\n",
      "Iteration 4144: loss 2.7128992080688477\n",
      "Iteration 4145: loss 2.655670642852783\n",
      "Iteration 4146: loss 2.625040292739868\n",
      "Iteration 4147: loss 2.6405694484710693\n",
      "Iteration 4148: loss 2.7672760486602783\n",
      "Iteration 4149: loss 2.59303879737854\n",
      "Iteration 4150: loss 2.48974609375\n",
      "Iteration 4151: loss 2.6237435340881348\n",
      "Iteration 4152: loss 2.6243181228637695\n",
      "Iteration 4153: loss 2.5349669456481934\n",
      "Iteration 4154: loss 2.553088665008545\n",
      "Iteration 4155: loss 2.779322385787964\n",
      "Iteration 4156: loss 2.486219644546509\n",
      "Iteration 4157: loss 2.5798397064208984\n",
      "Iteration 4158: loss 2.5952389240264893\n",
      "Iteration 4159: loss 2.786729097366333\n",
      "Iteration 4160: loss 2.666449546813965\n",
      "Iteration 4161: loss 2.451457977294922\n",
      "Iteration 4162: loss 2.7366397380828857\n",
      "Iteration 4163: loss 2.6305959224700928\n",
      "Iteration 4164: loss 2.6633949279785156\n",
      "Iteration 4165: loss 2.8014070987701416\n",
      "Iteration 4166: loss 2.727404832839966\n",
      "Iteration 4167: loss 2.715813636779785\n",
      "Iteration 4168: loss 2.871445655822754\n",
      "Iteration 4169: loss 2.6792678833007812\n",
      "Iteration 4170: loss 2.6271703243255615\n",
      "Iteration 4171: loss 2.8876476287841797\n",
      "Iteration 4172: loss 2.6068596839904785\n",
      "Iteration 4173: loss 2.7273924350738525\n",
      "Iteration 4174: loss 2.760890483856201\n",
      "Iteration 4175: loss 2.750678062438965\n",
      "Iteration 4176: loss 2.7077314853668213\n",
      "Iteration 4177: loss 2.5063836574554443\n",
      "Iteration 4178: loss 2.6294074058532715\n",
      "Iteration 4179: loss 2.6231906414031982\n",
      "Iteration 4180: loss 2.582277774810791\n",
      "Iteration 4181: loss 2.648998260498047\n",
      "Iteration 4182: loss 2.5532214641571045\n",
      "Iteration 4183: loss 2.654773235321045\n",
      "Iteration 4184: loss 2.4875166416168213\n",
      "Iteration 4185: loss 2.680473566055298\n",
      "Iteration 4186: loss 2.4678969383239746\n",
      "Iteration 4187: loss 2.5657026767730713\n",
      "Iteration 4188: loss 2.5309252738952637\n",
      "Iteration 4189: loss 2.5396440029144287\n",
      "Iteration 4190: loss 2.757829427719116\n",
      "Iteration 4191: loss 2.6570849418640137\n",
      "Iteration 4192: loss 2.737449884414673\n",
      "Iteration 4193: loss 2.464217185974121\n",
      "Iteration 4194: loss 2.7077877521514893\n",
      "Iteration 4195: loss 2.651876211166382\n",
      "Iteration 4196: loss 2.7555670738220215\n",
      "Iteration 4197: loss 2.725602149963379\n",
      "Iteration 4198: loss 2.964486837387085\n",
      "Iteration 4199: loss 2.7031304836273193\n",
      "Iteration 4200: loss 2.629809617996216\n",
      "Iteration 4201: loss 2.704525947570801\n",
      "Iteration 4202: loss 2.538400650024414\n",
      "Iteration 4203: loss 2.5294103622436523\n",
      "Iteration 4204: loss 2.530447483062744\n",
      "Iteration 4205: loss 2.8648345470428467\n",
      "Iteration 4206: loss 2.745166063308716\n",
      "Iteration 4207: loss 2.8000590801239014\n",
      "Iteration 4208: loss 2.8116774559020996\n",
      "Iteration 4209: loss 2.787677049636841\n",
      "Iteration 4210: loss 2.5286307334899902\n",
      "Iteration 4211: loss 2.507871150970459\n",
      "Iteration 4212: loss 2.5194132328033447\n",
      "Iteration 4213: loss 2.6541824340820312\n",
      "Iteration 4214: loss 2.803753614425659\n",
      "Iteration 4215: loss 2.7561309337615967\n",
      "Iteration 4216: loss 2.6953184604644775\n",
      "Iteration 4217: loss 2.720229148864746\n",
      "Iteration 4218: loss 2.5028343200683594\n",
      "Iteration 4219: loss 2.58585524559021\n",
      "Iteration 4220: loss 2.7179477214813232\n",
      "Iteration 4221: loss 2.6516191959381104\n",
      "Iteration 4222: loss 2.767556667327881\n",
      "Iteration 4223: loss 2.670154571533203\n",
      "Iteration 4224: loss 2.6209447383880615\n",
      "Iteration 4225: loss 2.748521327972412\n",
      "Iteration 4226: loss 2.637486457824707\n",
      "Iteration 4227: loss 2.5753166675567627\n",
      "Iteration 4228: loss 2.571885108947754\n",
      "Iteration 4229: loss 2.6501543521881104\n",
      "Iteration 4230: loss 2.6378023624420166\n",
      "Iteration 4231: loss 2.719754219055176\n",
      "Iteration 4232: loss 2.5603396892547607\n",
      "Iteration 4233: loss 2.6213624477386475\n",
      "Iteration 4234: loss 2.4621849060058594\n",
      "Iteration 4235: loss 2.7457334995269775\n",
      "Iteration 4236: loss 2.8439691066741943\n",
      "Iteration 4237: loss 2.642392635345459\n",
      "Iteration 4238: loss 2.59136962890625\n",
      "Iteration 4239: loss 2.6392951011657715\n",
      "Iteration 4240: loss 2.659423351287842\n",
      "Iteration 4241: loss 2.4732184410095215\n",
      "Iteration 4242: loss 2.654285192489624\n",
      "Iteration 4243: loss 2.4352777004241943\n",
      "Iteration 4244: loss 2.5974535942077637\n",
      "Iteration 4245: loss 2.600151300430298\n",
      "Iteration 4246: loss 2.76908540725708\n",
      "Iteration 4247: loss 2.638045072555542\n",
      "Iteration 4248: loss 2.6060211658477783\n",
      "Iteration 4249: loss 2.8049776554107666\n",
      "Iteration 4250: loss 2.506659984588623\n",
      "Iteration 4251: loss 2.6194963455200195\n",
      "Iteration 4252: loss 2.4497811794281006\n",
      "Iteration 4253: loss 2.8734750747680664\n",
      "Iteration 4254: loss 2.7631311416625977\n",
      "Iteration 4255: loss 2.624143123626709\n",
      "Iteration 4256: loss 2.4668524265289307\n",
      "Iteration 4257: loss 2.6037936210632324\n",
      "Iteration 4258: loss 2.6559176445007324\n",
      "Iteration 4259: loss 2.5413708686828613\n",
      "Iteration 4260: loss 2.694817066192627\n",
      "Iteration 4261: loss 2.5377402305603027\n",
      "Iteration 4262: loss 2.589663028717041\n",
      "Iteration 4263: loss 2.6939172744750977\n",
      "Iteration 4264: loss 2.479506731033325\n",
      "Iteration 4265: loss 2.6027867794036865\n",
      "Iteration 4266: loss 2.689286470413208\n",
      "Iteration 4267: loss 2.5702226161956787\n",
      "Iteration 4268: loss 2.8983559608459473\n",
      "Iteration 4269: loss 2.610461950302124\n",
      "Iteration 4270: loss 2.723888397216797\n",
      "Iteration 4271: loss 2.7498435974121094\n",
      "Iteration 4272: loss 2.6650733947753906\n",
      "Iteration 4273: loss 2.6216704845428467\n",
      "Iteration 4274: loss 2.6745948791503906\n",
      "Iteration 4275: loss 2.4714601039886475\n",
      "Iteration 4276: loss 2.630793333053589\n",
      "Iteration 4277: loss 2.6475987434387207\n",
      "Iteration 4278: loss 2.6597044467926025\n",
      "Iteration 4279: loss 2.658773183822632\n",
      "Iteration 4280: loss 2.625973701477051\n",
      "Iteration 4281: loss 2.435882568359375\n",
      "Iteration 4282: loss 2.708514928817749\n",
      "Iteration 4283: loss 2.6905341148376465\n",
      "Iteration 4284: loss 2.5866036415100098\n",
      "Iteration 4285: loss 2.6104564666748047\n",
      "Iteration 4286: loss 2.657092809677124\n",
      "Iteration 4287: loss 2.509199380874634\n",
      "Iteration 4288: loss 2.5044331550598145\n",
      "Iteration 4289: loss 2.4957807064056396\n",
      "Iteration 4290: loss 2.4463536739349365\n",
      "Iteration 4291: loss 2.7453649044036865\n",
      "Iteration 4292: loss 2.518038511276245\n",
      "Iteration 4293: loss 2.6420419216156006\n",
      "Iteration 4294: loss 2.6051952838897705\n",
      "Iteration 4295: loss 2.639634609222412\n",
      "Iteration 4296: loss 2.6193203926086426\n",
      "Iteration 4297: loss 2.5675530433654785\n",
      "Iteration 4298: loss 2.6238837242126465\n",
      "Iteration 4299: loss 2.5622498989105225\n",
      "Iteration 4300: loss 2.6474385261535645\n",
      "Iteration 4301: loss 3.598248243331909\n",
      "Iteration 4302: loss 3.416553497314453\n",
      "Iteration 4303: loss 3.144017219543457\n",
      "Iteration 4304: loss 3.112502098083496\n",
      "Iteration 4305: loss 3.0174624919891357\n",
      "Iteration 4306: loss 2.9507315158843994\n",
      "Iteration 4307: loss 2.9880058765411377\n",
      "Iteration 4308: loss 3.031308889389038\n",
      "Iteration 4309: loss 3.1745214462280273\n",
      "Iteration 4310: loss 3.143411874771118\n",
      "Iteration 4311: loss 3.096950054168701\n",
      "Iteration 4312: loss 3.03517484664917\n",
      "Iteration 4313: loss 3.0335094928741455\n",
      "Iteration 4314: loss 3.069800853729248\n",
      "Iteration 4315: loss 3.09309983253479\n",
      "Iteration 4316: loss 2.946049690246582\n",
      "Iteration 4317: loss 2.7471532821655273\n",
      "Iteration 4318: loss 3.0214245319366455\n",
      "Iteration 4319: loss 2.8844048976898193\n",
      "Iteration 4320: loss 2.970215082168579\n",
      "Iteration 4321: loss 2.7175323963165283\n",
      "Iteration 4322: loss 2.8437981605529785\n",
      "Iteration 4323: loss 2.726337194442749\n",
      "Iteration 4324: loss 2.94150447845459\n",
      "Iteration 4325: loss 2.8711178302764893\n",
      "Iteration 4326: loss 2.8936283588409424\n",
      "Iteration 4327: loss 2.821202278137207\n",
      "Iteration 4328: loss 2.7676799297332764\n",
      "Iteration 4329: loss 2.8482987880706787\n",
      "Iteration 4330: loss 2.846376657485962\n",
      "Iteration 4331: loss 2.979278564453125\n",
      "Iteration 4332: loss 2.7290804386138916\n",
      "Iteration 4333: loss 2.8897829055786133\n",
      "Iteration 4334: loss 2.9279234409332275\n",
      "Iteration 4335: loss 2.7244036197662354\n",
      "Iteration 4336: loss 2.7366747856140137\n",
      "Iteration 4337: loss 2.787431240081787\n",
      "Iteration 4338: loss 2.837461471557617\n",
      "Iteration 4339: loss 2.6532201766967773\n",
      "Iteration 4340: loss 2.8446171283721924\n",
      "Iteration 4341: loss 2.7203338146209717\n",
      "Iteration 4342: loss 2.7389235496520996\n",
      "Iteration 4343: loss 2.8674333095550537\n",
      "Iteration 4344: loss 2.812831163406372\n",
      "Iteration 4345: loss 2.729142904281616\n",
      "Iteration 4346: loss 3.017742872238159\n",
      "Iteration 4347: loss 2.6914725303649902\n",
      "Iteration 4348: loss 2.715876340866089\n",
      "Iteration 4349: loss 2.4635744094848633\n",
      "Iteration 4350: loss 2.617112874984741\n",
      "Iteration 4351: loss 2.7897708415985107\n",
      "Iteration 4352: loss 2.7986791133880615\n",
      "Iteration 4353: loss 2.6547136306762695\n",
      "Iteration 4354: loss 2.58327579498291\n",
      "Iteration 4355: loss 2.593043088912964\n",
      "Iteration 4356: loss 2.6186070442199707\n",
      "Iteration 4357: loss 2.6541476249694824\n",
      "Iteration 4358: loss 2.3733632564544678\n",
      "Iteration 4359: loss 2.6744749546051025\n",
      "Iteration 4360: loss 2.7936851978302\n",
      "Iteration 4361: loss 2.859825372695923\n",
      "Iteration 4362: loss 2.724593162536621\n",
      "Iteration 4363: loss 2.8690099716186523\n",
      "Iteration 4364: loss 2.874404191970825\n",
      "Iteration 4365: loss 2.4221880435943604\n",
      "Iteration 4366: loss 2.9334557056427\n",
      "Iteration 4367: loss 2.8843181133270264\n",
      "Iteration 4368: loss 2.7078471183776855\n",
      "Iteration 4369: loss 2.5730769634246826\n",
      "Iteration 4370: loss 2.656867504119873\n",
      "Iteration 4371: loss 2.8781301975250244\n",
      "Iteration 4372: loss 2.7756543159484863\n",
      "Iteration 4373: loss 2.6614203453063965\n",
      "Iteration 4374: loss 2.907521963119507\n",
      "Iteration 4375: loss 2.5871024131774902\n",
      "Iteration 4376: loss 2.750389337539673\n",
      "Iteration 4377: loss 2.686159372329712\n",
      "Iteration 4378: loss 2.742462158203125\n",
      "Iteration 4379: loss 2.714064359664917\n",
      "Iteration 4380: loss 2.663214683532715\n",
      "Iteration 4381: loss 2.7284109592437744\n",
      "Iteration 4382: loss 2.595705509185791\n",
      "Iteration 4383: loss 2.5882577896118164\n",
      "Iteration 4384: loss 2.6106579303741455\n",
      "Iteration 4385: loss 2.799121141433716\n",
      "Iteration 4386: loss 2.6412761211395264\n",
      "Iteration 4387: loss 2.825247049331665\n",
      "Iteration 4388: loss 2.680333137512207\n",
      "Iteration 4389: loss 2.7321977615356445\n",
      "Iteration 4390: loss 2.647754430770874\n",
      "Iteration 4391: loss 2.609600782394409\n",
      "Iteration 4392: loss 2.6266729831695557\n",
      "Iteration 4393: loss 2.7801098823547363\n",
      "Iteration 4394: loss 2.705437183380127\n",
      "Iteration 4395: loss 2.735130548477173\n",
      "Iteration 4396: loss 2.737671375274658\n",
      "Iteration 4397: loss 2.6301050186157227\n",
      "Iteration 4398: loss 2.6782281398773193\n",
      "Iteration 4399: loss 2.590521812438965\n",
      "Iteration 4400: loss 2.688401937484741\n",
      "Iteration 4401: loss 2.6264262199401855\n",
      "Iteration 4402: loss 2.6729204654693604\n",
      "Iteration 4403: loss 2.6743762493133545\n",
      "Iteration 4404: loss 2.5935375690460205\n",
      "Iteration 4405: loss 2.7144076824188232\n",
      "Iteration 4406: loss 2.896444082260132\n",
      "Iteration 4407: loss 2.502980947494507\n",
      "Iteration 4408: loss 2.673903703689575\n",
      "Iteration 4409: loss 2.7459306716918945\n",
      "Iteration 4410: loss 2.8699309825897217\n",
      "Iteration 4411: loss 2.598109006881714\n",
      "Iteration 4412: loss 2.645359992980957\n",
      "Iteration 4413: loss 2.6445062160491943\n",
      "Iteration 4414: loss 2.7410707473754883\n",
      "Iteration 4415: loss 2.6230597496032715\n",
      "Iteration 4416: loss 2.6206729412078857\n",
      "Iteration 4417: loss 2.5953667163848877\n",
      "Iteration 4418: loss 2.6770036220550537\n",
      "Iteration 4419: loss 2.3757846355438232\n",
      "Iteration 4420: loss 2.661485433578491\n",
      "Iteration 4421: loss 2.8858590126037598\n",
      "Iteration 4422: loss 2.6341214179992676\n",
      "Iteration 4423: loss 2.826443672180176\n",
      "Iteration 4424: loss 2.6060991287231445\n",
      "Iteration 4425: loss 2.6233062744140625\n",
      "Iteration 4426: loss 2.5212528705596924\n",
      "Iteration 4427: loss 2.8088653087615967\n",
      "Iteration 4428: loss 2.528703212738037\n",
      "Iteration 4429: loss 2.9071452617645264\n",
      "Iteration 4430: loss 2.6507458686828613\n",
      "Iteration 4431: loss 2.7783114910125732\n",
      "Iteration 4432: loss 2.8497579097747803\n",
      "Iteration 4433: loss 2.6339714527130127\n",
      "Iteration 4434: loss 2.678629159927368\n",
      "Iteration 4435: loss 2.788395404815674\n",
      "Iteration 4436: loss 2.680121660232544\n",
      "Iteration 4437: loss 2.6567060947418213\n",
      "Iteration 4438: loss 2.666844367980957\n",
      "Iteration 4439: loss 2.700615167617798\n",
      "Iteration 4440: loss 2.566898822784424\n",
      "Iteration 4441: loss 2.690803050994873\n",
      "Iteration 4442: loss 2.507739782333374\n",
      "Iteration 4443: loss 2.800034761428833\n",
      "Iteration 4444: loss 2.7356796264648438\n",
      "Iteration 4445: loss 2.5871639251708984\n",
      "Iteration 4446: loss 2.72729754447937\n",
      "Iteration 4447: loss 2.6801540851593018\n",
      "Iteration 4448: loss 2.6873693466186523\n",
      "Iteration 4449: loss 2.6654443740844727\n",
      "Iteration 4450: loss 2.5515666007995605\n",
      "Iteration 4451: loss 2.730170488357544\n",
      "Iteration 4452: loss 2.5218498706817627\n",
      "Iteration 4453: loss 2.4181413650512695\n",
      "Iteration 4454: loss 2.5741662979125977\n",
      "Iteration 4455: loss 2.585822105407715\n",
      "Iteration 4456: loss 2.573129177093506\n",
      "Iteration 4457: loss 2.686937093734741\n",
      "Iteration 4458: loss 2.731605052947998\n",
      "Iteration 4459: loss 2.67059326171875\n",
      "Iteration 4460: loss 2.5935864448547363\n",
      "Iteration 4461: loss 2.547077178955078\n",
      "Iteration 4462: loss 2.6887850761413574\n",
      "Iteration 4463: loss 2.5678346157073975\n",
      "Iteration 4464: loss 2.556074380874634\n",
      "Iteration 4465: loss 2.573418617248535\n",
      "Iteration 4466: loss 2.641771078109741\n",
      "Iteration 4467: loss 2.692528247833252\n",
      "Iteration 4468: loss 2.598896026611328\n",
      "Iteration 4469: loss 2.806849241256714\n",
      "Iteration 4470: loss 2.777454137802124\n",
      "Iteration 4471: loss 2.616762638092041\n",
      "Iteration 4472: loss 2.613024950027466\n",
      "Iteration 4473: loss 2.778313636779785\n",
      "Iteration 4474: loss 2.5749778747558594\n",
      "Iteration 4475: loss 2.6972579956054688\n",
      "Iteration 4476: loss 2.6917150020599365\n",
      "Iteration 4477: loss 2.677441358566284\n",
      "Iteration 4478: loss 2.6684858798980713\n",
      "Iteration 4479: loss 2.5962605476379395\n",
      "Iteration 4480: loss 2.6174678802490234\n",
      "Iteration 4481: loss 2.588505268096924\n",
      "Iteration 4482: loss 2.809311866760254\n",
      "Iteration 4483: loss 2.667140483856201\n",
      "Iteration 4484: loss 2.6228904724121094\n",
      "Iteration 4485: loss 2.737053871154785\n",
      "Iteration 4486: loss 2.562319278717041\n",
      "Iteration 4487: loss 2.488801956176758\n",
      "Iteration 4488: loss 2.7424535751342773\n",
      "Iteration 4489: loss 2.835709810256958\n",
      "Iteration 4490: loss 2.691559314727783\n",
      "Iteration 4491: loss 2.5931570529937744\n",
      "Iteration 4492: loss 2.8016319274902344\n",
      "Iteration 4493: loss 2.8816800117492676\n",
      "Iteration 4494: loss 2.6346466541290283\n",
      "Iteration 4495: loss 2.6809821128845215\n",
      "Iteration 4496: loss 3.3370537757873535\n",
      "Iteration 4497: loss 2.8884990215301514\n",
      "Iteration 4498: loss 2.5945754051208496\n",
      "Iteration 4499: loss 2.775049924850464\n",
      "Iteration 4500: loss 3.226598024368286\n",
      "Iteration 4501: loss 2.8172905445098877\n",
      "Iteration 4502: loss 2.7933685779571533\n",
      "Iteration 4503: loss 2.904747247695923\n",
      "Iteration 4504: loss 2.9236345291137695\n",
      "Iteration 4505: loss 3.0120747089385986\n",
      "Iteration 4506: loss 2.7756454944610596\n",
      "Iteration 4507: loss 2.850567579269409\n",
      "Iteration 4508: loss 2.9860386848449707\n",
      "Iteration 4509: loss 3.0831689834594727\n",
      "Iteration 4510: loss 2.733058452606201\n",
      "Iteration 4511: loss 2.7723608016967773\n",
      "Iteration 4512: loss 3.1891980171203613\n",
      "Iteration 4513: loss 2.56270432472229\n",
      "Iteration 4514: loss 2.791060209274292\n",
      "Iteration 4515: loss 2.5948359966278076\n",
      "Iteration 4516: loss 2.5955734252929688\n",
      "Iteration 4517: loss 2.677786111831665\n",
      "Iteration 4518: loss 2.743741750717163\n",
      "Iteration 4519: loss 2.729924201965332\n",
      "Iteration 4520: loss 2.624950408935547\n",
      "Iteration 4521: loss 2.541146993637085\n",
      "Iteration 4522: loss 2.642359495162964\n",
      "Iteration 4523: loss 2.618886709213257\n",
      "Iteration 4524: loss 3.0951778888702393\n",
      "Iteration 4525: loss 2.677046537399292\n",
      "Iteration 4526: loss 2.898993492126465\n",
      "Iteration 4527: loss 3.1903929710388184\n",
      "Iteration 4528: loss 2.9645836353302\n",
      "Iteration 4529: loss 2.713148832321167\n",
      "Iteration 4530: loss 2.871236562728882\n",
      "Iteration 4531: loss 2.856510877609253\n",
      "Iteration 4532: loss 3.0605905055999756\n",
      "Iteration 4533: loss 2.8103256225585938\n",
      "Iteration 4534: loss 2.758889675140381\n",
      "Iteration 4535: loss 2.611431121826172\n",
      "Iteration 4536: loss 2.8952629566192627\n",
      "Iteration 4537: loss 2.531740427017212\n",
      "Iteration 4538: loss 2.6267924308776855\n",
      "Iteration 4539: loss 2.6521599292755127\n",
      "Iteration 4540: loss 2.6545093059539795\n",
      "Iteration 4541: loss 2.893315315246582\n",
      "Iteration 4542: loss 2.714296817779541\n",
      "Iteration 4543: loss 3.043428659439087\n",
      "Iteration 4544: loss 2.7485551834106445\n",
      "Iteration 4545: loss 2.7244110107421875\n",
      "Iteration 4546: loss 2.7831671237945557\n",
      "Iteration 4547: loss 2.825329303741455\n",
      "Iteration 4548: loss 2.6473333835601807\n",
      "Iteration 4549: loss 3.1093597412109375\n",
      "Iteration 4550: loss 2.7519476413726807\n",
      "Iteration 4551: loss 2.67366361618042\n",
      "Iteration 4552: loss 2.801494598388672\n",
      "Iteration 4553: loss 2.7210230827331543\n",
      "Iteration 4554: loss 2.490663766860962\n",
      "Iteration 4555: loss 2.6686863899230957\n",
      "Iteration 4556: loss 2.7102508544921875\n",
      "Iteration 4557: loss 2.7402610778808594\n",
      "Iteration 4558: loss 2.4975411891937256\n",
      "Iteration 4559: loss 2.8285815715789795\n",
      "Iteration 4560: loss 2.630251407623291\n",
      "Iteration 4561: loss 2.71710205078125\n",
      "Iteration 4562: loss 2.6956865787506104\n",
      "Iteration 4563: loss 2.798994779586792\n",
      "Iteration 4564: loss 2.759704113006592\n",
      "Iteration 4565: loss 2.7416887283325195\n",
      "Iteration 4566: loss 2.985762357711792\n",
      "Iteration 4567: loss 2.9251463413238525\n",
      "Iteration 4568: loss 2.77750563621521\n",
      "Iteration 4569: loss 2.7423524856567383\n",
      "Iteration 4570: loss 3.062009811401367\n",
      "Iteration 4571: loss 2.7960264682769775\n",
      "Iteration 4572: loss 3.2996020317077637\n",
      "Iteration 4573: loss 2.6989214420318604\n",
      "Iteration 4574: loss 2.7277960777282715\n",
      "Iteration 4575: loss 3.026681423187256\n",
      "Iteration 4576: loss 2.783599853515625\n",
      "Iteration 4577: loss 2.7164580821990967\n",
      "Iteration 4578: loss 2.8780949115753174\n",
      "Iteration 4579: loss 3.3173701763153076\n",
      "Iteration 4580: loss 3.6854255199432373\n",
      "Iteration 4581: loss 6.621813774108887\n",
      "Iteration 4582: loss 3.774589776992798\n",
      "Iteration 4583: loss 4.905213356018066\n",
      "Iteration 4584: loss 4.340829372406006\n",
      "Iteration 4585: loss 4.176754474639893\n",
      "Iteration 4586: loss 4.120998382568359\n",
      "Iteration 4587: loss 4.362226963043213\n",
      "Iteration 4588: loss 3.6250905990600586\n",
      "Iteration 4589: loss 6.2540483474731445\n",
      "Iteration 4590: loss 4.259215831756592\n",
      "Iteration 4591: loss 4.632326126098633\n",
      "Iteration 4592: loss 4.329408645629883\n",
      "Iteration 4593: loss 4.2171783447265625\n",
      "Iteration 4594: loss 4.300674915313721\n",
      "Iteration 4595: loss 4.320324420928955\n",
      "Iteration 4596: loss 3.9497129917144775\n",
      "Iteration 4597: loss 4.303721904754639\n",
      "Iteration 4598: loss 4.335966110229492\n",
      "Iteration 4599: loss 3.7332262992858887\n",
      "Iteration 4600: loss 3.839655637741089\n",
      "Iteration 4601: loss 3.849370002746582\n",
      "Iteration 4602: loss 4.059360027313232\n",
      "Iteration 4603: loss 3.9502646923065186\n",
      "Iteration 4604: loss 3.7922050952911377\n",
      "Iteration 4605: loss 3.695779323577881\n",
      "Iteration 4606: loss 3.324687957763672\n",
      "Iteration 4607: loss 3.4445812702178955\n",
      "Iteration 4608: loss 3.960843324661255\n",
      "Iteration 4609: loss 4.018604755401611\n",
      "Iteration 4610: loss 3.656769275665283\n",
      "Iteration 4611: loss 4.044891357421875\n",
      "Iteration 4612: loss 3.9191694259643555\n",
      "Iteration 4613: loss 3.5844337940216064\n",
      "Iteration 4614: loss 3.643019676208496\n",
      "Iteration 4615: loss 3.8281493186950684\n",
      "Iteration 4616: loss 3.4542644023895264\n",
      "Iteration 4617: loss 3.5978355407714844\n",
      "Iteration 4618: loss 3.52779221534729\n",
      "Iteration 4619: loss 4.122888565063477\n",
      "Iteration 4620: loss 3.80348539352417\n",
      "Iteration 4621: loss 3.6384899616241455\n",
      "Iteration 4622: loss 3.5507049560546875\n",
      "Iteration 4623: loss 3.623117685317993\n",
      "Iteration 4624: loss 3.613485097885132\n",
      "Iteration 4625: loss 3.4447054862976074\n",
      "Iteration 4626: loss 3.6793181896209717\n",
      "Iteration 4627: loss 3.558741331100464\n",
      "Iteration 4628: loss 3.926720142364502\n",
      "Iteration 4629: loss 4.026031494140625\n",
      "Iteration 4630: loss 3.51287841796875\n",
      "Iteration 4631: loss 3.551711082458496\n",
      "Iteration 4632: loss 3.447169780731201\n",
      "Iteration 4633: loss 3.419133424758911\n",
      "Iteration 4634: loss 3.7072908878326416\n",
      "Iteration 4635: loss 3.4596645832061768\n",
      "Iteration 4636: loss 3.280376434326172\n",
      "Iteration 4637: loss 3.5379488468170166\n",
      "Iteration 4638: loss 3.714380979537964\n",
      "Iteration 4639: loss 3.5588865280151367\n",
      "Iteration 4640: loss 3.534505605697632\n",
      "Iteration 4641: loss 3.4736316204071045\n",
      "Iteration 4642: loss 3.6716198921203613\n",
      "Iteration 4643: loss 3.276492118835449\n",
      "Iteration 4644: loss 3.7782506942749023\n",
      "Iteration 4645: loss 3.505406618118286\n",
      "Iteration 4646: loss 3.513918876647949\n",
      "Iteration 4647: loss 3.51513409614563\n",
      "Iteration 4648: loss 3.3896751403808594\n",
      "Iteration 4649: loss 3.3601531982421875\n",
      "Iteration 4650: loss 3.531022548675537\n",
      "Iteration 4651: loss 3.27925968170166\n",
      "Iteration 4652: loss 3.439152956008911\n",
      "Iteration 4653: loss 3.641946315765381\n",
      "Iteration 4654: loss 3.15571928024292\n",
      "Iteration 4655: loss 3.4829933643341064\n",
      "Iteration 4656: loss 3.464050769805908\n",
      "Iteration 4657: loss 3.5244810581207275\n",
      "Iteration 4658: loss 3.6719493865966797\n",
      "Iteration 4659: loss 3.6014769077301025\n",
      "Iteration 4660: loss 3.924708843231201\n",
      "Iteration 4661: loss 3.392892599105835\n",
      "Iteration 4662: loss 3.6192009449005127\n",
      "Iteration 4663: loss 3.7769901752471924\n",
      "Iteration 4664: loss 3.89910626411438\n",
      "Iteration 4665: loss 3.3472166061401367\n",
      "Iteration 4666: loss 3.542916774749756\n",
      "Iteration 4667: loss 3.413433790206909\n",
      "Iteration 4668: loss 3.6632323265075684\n",
      "Iteration 4669: loss 3.6199522018432617\n",
      "Iteration 4670: loss 3.403066873550415\n",
      "Iteration 4671: loss 3.3633108139038086\n",
      "Iteration 4672: loss 3.5963499546051025\n",
      "Iteration 4673: loss 3.746039867401123\n",
      "Iteration 4674: loss 3.575002431869507\n",
      "Iteration 4675: loss 3.251774311065674\n",
      "Iteration 4676: loss 3.933558225631714\n",
      "Iteration 4677: loss 3.629117250442505\n",
      "Iteration 4678: loss 3.2833099365234375\n",
      "Iteration 4679: loss 3.998055934906006\n",
      "Iteration 4680: loss 3.70639967918396\n",
      "Iteration 4681: loss 3.453866481781006\n",
      "Iteration 4682: loss 3.6647582054138184\n",
      "Iteration 4683: loss 3.3106071949005127\n",
      "Iteration 4684: loss 3.114490509033203\n",
      "Iteration 4685: loss 3.5141563415527344\n",
      "Iteration 4686: loss 3.3017497062683105\n",
      "Iteration 4687: loss 3.0046422481536865\n",
      "Iteration 4688: loss 3.4194676876068115\n",
      "Iteration 4689: loss 3.2994682788848877\n",
      "Iteration 4690: loss 3.282931327819824\n",
      "Iteration 4691: loss 3.279059886932373\n",
      "Iteration 4692: loss 3.2407984733581543\n",
      "Iteration 4693: loss 3.562191963195801\n",
      "Iteration 4694: loss 3.2168893814086914\n",
      "Iteration 4695: loss 3.5040245056152344\n",
      "Iteration 4696: loss 3.0800652503967285\n",
      "Iteration 4697: loss 3.3990087509155273\n",
      "Iteration 4698: loss 3.5584990978240967\n",
      "Iteration 4699: loss 3.646592378616333\n",
      "Iteration 4700: loss 3.160210609436035\n",
      "Iteration 4701: loss 3.2833611965179443\n",
      "Iteration 4702: loss 3.570929527282715\n",
      "Iteration 4703: loss 3.2643542289733887\n",
      "Iteration 4704: loss 3.34248948097229\n",
      "Iteration 4705: loss 3.4765684604644775\n",
      "Iteration 4706: loss 3.4689180850982666\n",
      "Iteration 4707: loss 3.21331524848938\n",
      "Iteration 4708: loss 3.001878023147583\n",
      "Iteration 4709: loss 3.3734326362609863\n",
      "Iteration 4710: loss 3.490844249725342\n",
      "Iteration 4711: loss 3.1444270610809326\n",
      "Iteration 4712: loss 3.6837832927703857\n",
      "Iteration 4713: loss 3.554337978363037\n",
      "Iteration 4714: loss 3.613798141479492\n",
      "Iteration 4715: loss 3.2946488857269287\n",
      "Iteration 4716: loss 3.841928005218506\n",
      "Iteration 4717: loss 3.706343412399292\n",
      "Iteration 4718: loss 3.63822340965271\n",
      "Iteration 4719: loss 3.6077189445495605\n",
      "Iteration 4720: loss 3.5467426776885986\n",
      "Iteration 4721: loss 3.693709373474121\n",
      "Iteration 4722: loss 3.115291118621826\n",
      "Iteration 4723: loss 3.162668466567993\n",
      "Iteration 4724: loss 3.380993604660034\n",
      "Iteration 4725: loss 3.7630934715270996\n",
      "Iteration 4726: loss 4.702295303344727\n",
      "Iteration 4727: loss 4.071371555328369\n",
      "Iteration 4728: loss 3.524564743041992\n",
      "Iteration 4729: loss 3.928176164627075\n",
      "Iteration 4730: loss 4.505298137664795\n",
      "Iteration 4731: loss 4.204697132110596\n",
      "Iteration 4732: loss 4.102659702301025\n",
      "Iteration 4733: loss 3.7689895629882812\n",
      "Iteration 4734: loss 3.7913308143615723\n",
      "Iteration 4735: loss 3.8124804496765137\n",
      "Iteration 4736: loss 3.8013362884521484\n",
      "Iteration 4737: loss 4.525249004364014\n",
      "Iteration 4738: loss 3.9943530559539795\n",
      "Iteration 4739: loss 3.5201683044433594\n",
      "Iteration 4740: loss 4.0192389488220215\n",
      "Iteration 4741: loss 4.3828935623168945\n",
      "Iteration 4742: loss 4.093924522399902\n",
      "Iteration 4743: loss 3.8518998622894287\n",
      "Iteration 4744: loss 3.7921440601348877\n",
      "Iteration 4745: loss 5.048060417175293\n",
      "Iteration 4746: loss 5.266269207000732\n",
      "Iteration 4747: loss 4.580934524536133\n",
      "Iteration 4748: loss 4.613937854766846\n",
      "Iteration 4749: loss 4.022201061248779\n",
      "Iteration 4750: loss 3.9355545043945312\n",
      "Iteration 4751: loss 4.689506530761719\n",
      "Iteration 4752: loss 4.5548930168151855\n",
      "Iteration 4753: loss 3.924023151397705\n",
      "Iteration 4754: loss 4.155632972717285\n",
      "Iteration 4755: loss 4.175304889678955\n",
      "Iteration 4756: loss 4.059083938598633\n",
      "Iteration 4757: loss 4.010158538818359\n",
      "Iteration 4758: loss 4.111029148101807\n",
      "Iteration 4759: loss 3.8500325679779053\n",
      "Iteration 4760: loss 4.004297733306885\n",
      "Iteration 4761: loss 3.5254664421081543\n",
      "Iteration 4762: loss 3.7319414615631104\n",
      "Iteration 4763: loss 3.6153666973114014\n",
      "Iteration 4764: loss 3.837684154510498\n",
      "Iteration 4765: loss 3.6820104122161865\n",
      "Iteration 4766: loss 3.9033589363098145\n",
      "Iteration 4767: loss 4.115748882293701\n",
      "Iteration 4768: loss 3.6291518211364746\n",
      "Iteration 4769: loss 3.863426923751831\n",
      "Iteration 4770: loss 3.921509265899658\n",
      "Iteration 4771: loss 3.8501274585723877\n",
      "Iteration 4772: loss 4.696876525878906\n",
      "Iteration 4773: loss 4.5400261878967285\n",
      "Iteration 4774: loss 4.466134548187256\n",
      "Iteration 4775: loss 6.338640213012695\n",
      "Iteration 4776: loss 4.566143035888672\n",
      "Iteration 4777: loss 4.083827018737793\n",
      "Iteration 4778: loss 3.834968090057373\n",
      "Iteration 4779: loss 4.406864643096924\n",
      "Iteration 4780: loss 4.464010238647461\n",
      "Iteration 4781: loss 4.347847938537598\n",
      "Iteration 4782: loss 3.804311990737915\n",
      "Iteration 4783: loss 4.141412734985352\n",
      "Iteration 4784: loss 4.314830303192139\n",
      "Iteration 4785: loss 4.0785956382751465\n",
      "Iteration 4786: loss 3.9358904361724854\n",
      "Iteration 4787: loss 4.092735290527344\n",
      "Iteration 4788: loss 4.030422210693359\n",
      "Iteration 4789: loss 4.208732604980469\n",
      "Iteration 4790: loss 4.205500602722168\n",
      "Iteration 4791: loss 3.9923274517059326\n",
      "Iteration 4792: loss 3.9639837741851807\n",
      "Iteration 4793: loss 3.9766979217529297\n",
      "Iteration 4794: loss 4.165248870849609\n",
      "Iteration 4795: loss 4.370165824890137\n",
      "Iteration 4796: loss 4.015616416931152\n",
      "Iteration 4797: loss 4.179107189178467\n",
      "Iteration 4798: loss 4.466418743133545\n",
      "Iteration 4799: loss 4.282484531402588\n",
      "Iteration 4800: loss 4.566528797149658\n",
      "Iteration 4801: loss 4.3583149909973145\n",
      "Iteration 4802: loss 4.202707767486572\n",
      "Iteration 4803: loss 4.305594444274902\n",
      "Iteration 4804: loss 3.810216188430786\n",
      "Iteration 4805: loss 3.9134979248046875\n",
      "Iteration 4806: loss 4.0342488288879395\n",
      "Iteration 4807: loss 3.871055841445923\n",
      "Iteration 4808: loss 4.516181468963623\n",
      "Iteration 4809: loss 4.461652755737305\n",
      "Iteration 4810: loss 4.371667385101318\n",
      "Iteration 4811: loss 4.268518447875977\n",
      "Iteration 4812: loss 4.7808074951171875\n",
      "Iteration 4813: loss 4.524791240692139\n",
      "Iteration 4814: loss 4.466780185699463\n",
      "Iteration 4815: loss 3.9245805740356445\n",
      "Iteration 4816: loss 4.490143775939941\n",
      "Iteration 4817: loss 5.038809776306152\n",
      "Iteration 4818: loss 3.755385398864746\n",
      "Iteration 4819: loss 4.4330854415893555\n",
      "Iteration 4820: loss 4.121326923370361\n",
      "Iteration 4821: loss 4.525916576385498\n",
      "Iteration 4822: loss 4.144235610961914\n",
      "Iteration 4823: loss 4.151704788208008\n",
      "Iteration 4824: loss 4.016022682189941\n",
      "Iteration 4825: loss 4.614846229553223\n",
      "Iteration 4826: loss 3.94341778755188\n",
      "Iteration 4827: loss 4.499935150146484\n",
      "Iteration 4828: loss 3.841022253036499\n",
      "Iteration 4829: loss 3.712162494659424\n",
      "Iteration 4830: loss 4.437628269195557\n",
      "Iteration 4831: loss 4.3346848487854\n",
      "Iteration 4832: loss 4.062432289123535\n",
      "Iteration 4833: loss 4.351700305938721\n",
      "Iteration 4834: loss 3.7032036781311035\n",
      "Iteration 4835: loss 3.670602321624756\n",
      "Iteration 4836: loss 4.253066539764404\n",
      "Iteration 4837: loss 4.437108516693115\n",
      "Iteration 4838: loss 4.003920555114746\n",
      "Iteration 4839: loss 4.422156810760498\n",
      "Iteration 4840: loss 3.9460058212280273\n",
      "Iteration 4841: loss 4.059361457824707\n",
      "Iteration 4842: loss 4.070222854614258\n",
      "Iteration 4843: loss 4.2242255210876465\n",
      "Iteration 4844: loss 4.052818298339844\n",
      "Iteration 4845: loss 4.445044040679932\n",
      "Iteration 4846: loss 4.566482067108154\n",
      "Iteration 4847: loss 4.814497947692871\n",
      "Iteration 4848: loss 4.391058444976807\n",
      "Iteration 4849: loss 4.472320556640625\n",
      "Iteration 4850: loss 4.274360179901123\n",
      "Iteration 4851: loss 3.949039936065674\n",
      "Iteration 4852: loss 4.003389358520508\n",
      "Iteration 4853: loss 3.658705711364746\n",
      "Iteration 4854: loss 3.8334810733795166\n",
      "Iteration 4855: loss 3.541133403778076\n",
      "Iteration 4856: loss 3.9007720947265625\n",
      "Iteration 4857: loss 4.082546234130859\n",
      "Iteration 4858: loss 3.974148988723755\n",
      "Iteration 4859: loss 4.00870943069458\n",
      "Iteration 4860: loss 4.113577842712402\n",
      "Iteration 4861: loss 3.6405019760131836\n",
      "Iteration 4862: loss 3.785980224609375\n",
      "Iteration 4863: loss 4.364028453826904\n",
      "Iteration 4864: loss 4.6386308670043945\n",
      "Iteration 4865: loss 4.857818603515625\n",
      "Iteration 4866: loss 4.723744869232178\n",
      "Iteration 4867: loss 4.317777156829834\n",
      "Iteration 4868: loss 4.449059963226318\n",
      "Iteration 4869: loss 4.543762683868408\n",
      "Iteration 4870: loss 4.29988431930542\n",
      "Iteration 4871: loss 4.938547134399414\n",
      "Iteration 4872: loss 4.195302486419678\n",
      "Iteration 4873: loss 4.82867956161499\n",
      "Iteration 4874: loss 4.682063579559326\n",
      "Iteration 4875: loss 4.485866069793701\n",
      "Iteration 4876: loss 4.201067924499512\n",
      "Iteration 4877: loss 4.086246967315674\n",
      "Iteration 4878: loss 4.298644542694092\n",
      "Iteration 4879: loss 3.5318706035614014\n",
      "Iteration 4880: loss 4.234680652618408\n",
      "Iteration 4881: loss 4.316780090332031\n",
      "Iteration 4882: loss 4.092601776123047\n",
      "Iteration 4883: loss 4.181049823760986\n",
      "Iteration 4884: loss 3.7093052864074707\n",
      "Iteration 4885: loss 4.24947452545166\n",
      "Iteration 4886: loss 4.295915603637695\n",
      "Iteration 4887: loss 4.06873893737793\n",
      "Iteration 4888: loss 3.5783135890960693\n",
      "Iteration 4889: loss 3.6452879905700684\n",
      "Iteration 4890: loss 3.6697890758514404\n",
      "Iteration 4891: loss 3.9441230297088623\n",
      "Iteration 4892: loss 3.385338306427002\n",
      "Iteration 4893: loss 3.916107416152954\n",
      "Iteration 4894: loss 4.204404354095459\n",
      "Iteration 4895: loss 3.858487844467163\n",
      "Iteration 4896: loss 3.475273609161377\n",
      "Iteration 4897: loss 3.881744861602783\n",
      "Iteration 4898: loss 3.8746745586395264\n",
      "Iteration 4899: loss 3.7447128295898438\n",
      "Iteration 4900: loss 3.440687417984009\n",
      "Iteration 4901: loss 3.6750755310058594\n",
      "Iteration 4902: loss 3.438044309616089\n",
      "Iteration 4903: loss 3.6764354705810547\n",
      "Iteration 4904: loss 3.404564142227173\n",
      "Iteration 4905: loss 3.5318822860717773\n",
      "Iteration 4906: loss 3.7501304149627686\n",
      "Iteration 4907: loss 3.659127712249756\n",
      "Iteration 4908: loss 3.380913019180298\n",
      "Iteration 4909: loss 3.675994873046875\n",
      "Iteration 4910: loss 3.5061116218566895\n",
      "Iteration 4911: loss 3.6021459102630615\n",
      "Iteration 4912: loss 3.6692302227020264\n",
      "Iteration 4913: loss 3.4609780311584473\n",
      "Iteration 4914: loss 4.218554496765137\n",
      "Iteration 4915: loss 3.633845329284668\n",
      "Iteration 4916: loss 3.6291379928588867\n",
      "Iteration 4917: loss 3.828777313232422\n",
      "Iteration 4918: loss 3.90470552444458\n",
      "Iteration 4919: loss 3.787576913833618\n",
      "Iteration 4920: loss 4.03702974319458\n",
      "Iteration 4921: loss 3.766603708267212\n",
      "Iteration 4922: loss 3.853846311569214\n",
      "Iteration 4923: loss 3.680664539337158\n",
      "Iteration 4924: loss 3.6533164978027344\n",
      "Iteration 4925: loss 3.831712484359741\n",
      "Iteration 4926: loss 3.5013420581817627\n",
      "Iteration 4927: loss 3.4500818252563477\n",
      "Iteration 4928: loss 3.682279348373413\n",
      "Iteration 4929: loss 3.456590414047241\n",
      "Iteration 4930: loss 3.6356029510498047\n",
      "Iteration 4931: loss 3.748060941696167\n",
      "Iteration 4932: loss 3.8042802810668945\n",
      "Iteration 4933: loss 3.7025463581085205\n",
      "Iteration 4934: loss 3.5157880783081055\n",
      "Iteration 4935: loss 3.5174357891082764\n",
      "Iteration 4936: loss 3.4348254203796387\n",
      "Iteration 4937: loss 3.128933906555176\n",
      "Iteration 4938: loss 3.4950129985809326\n",
      "Iteration 4939: loss 3.463743209838867\n",
      "Iteration 4940: loss 3.1989641189575195\n",
      "Iteration 4941: loss 3.175421953201294\n",
      "Iteration 4942: loss 3.3311431407928467\n",
      "Iteration 4943: loss 3.1853413581848145\n",
      "Iteration 4944: loss 3.559312582015991\n",
      "Iteration 4945: loss 3.3960697650909424\n",
      "Iteration 4946: loss 3.270512819290161\n",
      "Iteration 4947: loss 3.368410348892212\n",
      "Iteration 4948: loss 3.4957470893859863\n",
      "Iteration 4949: loss 3.453707695007324\n",
      "Iteration 4950: loss 3.371992826461792\n",
      "Iteration 4951: loss 3.3063440322875977\n",
      "Iteration 4952: loss 3.2029380798339844\n",
      "Iteration 4953: loss 3.1814825534820557\n",
      "Iteration 4954: loss 3.3869967460632324\n",
      "Iteration 4955: loss 3.6153581142425537\n",
      "Iteration 4956: loss 3.3580479621887207\n",
      "Iteration 4957: loss 3.2629776000976562\n",
      "Iteration 4958: loss 3.3121492862701416\n",
      "Iteration 4959: loss 3.424161911010742\n",
      "Iteration 4960: loss 3.379040241241455\n",
      "Iteration 4961: loss 3.7521071434020996\n",
      "Iteration 4962: loss 3.403275728225708\n",
      "Iteration 4963: loss 3.302704334259033\n",
      "Iteration 4964: loss 3.258884906768799\n",
      "Iteration 4965: loss 2.991589307785034\n",
      "Iteration 4966: loss 3.347703695297241\n",
      "Iteration 4967: loss 3.115385055541992\n",
      "Iteration 4968: loss 2.994473457336426\n",
      "Iteration 4969: loss 3.0968878269195557\n",
      "Iteration 4970: loss 3.5205657482147217\n",
      "Iteration 4971: loss 3.3591203689575195\n",
      "Iteration 4972: loss 3.2489962577819824\n",
      "Iteration 4973: loss 3.1501214504241943\n",
      "Iteration 4974: loss 3.165733575820923\n",
      "Iteration 4975: loss 3.2029366493225098\n",
      "Iteration 4976: loss 3.194985866546631\n",
      "Iteration 4977: loss 2.868705987930298\n",
      "Iteration 4978: loss 3.4391376972198486\n",
      "Iteration 4979: loss 3.464827537536621\n",
      "Iteration 4980: loss 3.15170955657959\n",
      "Iteration 4981: loss 2.9037296772003174\n",
      "Iteration 4982: loss 3.414987802505493\n",
      "Iteration 4983: loss 3.4782354831695557\n",
      "Iteration 4984: loss 2.8815295696258545\n",
      "Iteration 4985: loss 3.3891265392303467\n",
      "Iteration 4986: loss 3.492952585220337\n",
      "Iteration 4987: loss 3.4353344440460205\n",
      "Iteration 4988: loss 3.373478889465332\n",
      "Iteration 4989: loss 3.2668938636779785\n",
      "Iteration 4990: loss 3.081942081451416\n",
      "Iteration 4991: loss 3.195331335067749\n",
      "Iteration 4992: loss 3.290552854537964\n",
      "Iteration 4993: loss 3.395176887512207\n",
      "Iteration 4994: loss 3.6217525005340576\n",
      "Iteration 4995: loss 3.497300863265991\n",
      "Iteration 4996: loss 3.176964282989502\n",
      "Iteration 4997: loss 3.046588182449341\n",
      "Iteration 4998: loss 3.10098934173584\n",
      "Iteration 4999: loss 3.3711602687835693\n"
     ]
    }
   ],
   "source": [
    "for j in range(5000):\n",
    "    theta, x = generate_data(mb_size, return_theta=True)\n",
    "    optimizer.zero_grad()\n",
    "    loss = -1*encoder.log_prob(theta.to(device), x.to(device)).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Iteration {}: loss {}'.format(j, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "694f24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"lotka_volterra.nf\", \"wb\") as f:\n",
    "#     pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471f6c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow(\n",
       "  (_transform): CompositeTransform(\n",
       "    (_transforms): ModuleList(\n",
       "      (0): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=2003, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=2002, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LULinear()\n",
       "      (2): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=2003, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=2002, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LULinear()\n",
       "      (4): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=2003, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=2002, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): LULinear()\n",
       "      (6): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=2003, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=2002, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): LULinear()\n",
       "      (8): PiecewiseRationalQuadraticCouplingTransform(\n",
       "        (transform_net): ResidualNet(\n",
       "          (initial_layer): Linear(in_features=2003, out_features=50, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x ResidualBlock(\n",
       "              (context_layer): Linear(in_features=2002, out_features=50, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x Linear(in_features=50, out_features=50, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): Linear(in_features=50, out_features=29, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): LULinear()\n",
       "    )\n",
       "  )\n",
       "  (_distribution): StandardNormal()\n",
       "  (_embedding_net): Identity()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"lotka_volterra.nf\", \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3cb41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cal_scores = []\n",
    "for calibration_theta_pt, calibration_x_pt in zip(calibration_theta, calibration_x):\n",
    "    log_prob = encoder.log_prob(calibration_theta_pt.view(1,-1).to(device), calibration_x_pt.view(1,-1).to(device)).detach()\n",
    "    prob = log_prob.cpu().exp().numpy()\n",
    "    cal_scores.append(1 / prob)\n",
    "cal_scores = np.array(cal_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot the true posterior density\n",
    "def plot(j, x, theta, encoder, **kwargs):\n",
    "    device = 'cuda:0'\n",
    "\n",
    "    # Plot exact density\n",
    "    nrows = 4\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24,24))\n",
    "\n",
    "    discretization = .1\n",
    "    vals = torch.arange(-5., 5., discretization)\n",
    "    eval_pts = torch.cartesian_prod(vals, vals)\n",
    "    lps = encoder.log_prob(eval_pts.to(device), x[j].view(1,-1).repeat(eval_pts.shape[0],1).to(device)).detach()\n",
    "    X, Y = torch.meshgrid(vals, vals)\n",
    "    Z = lps.view(X.shape)\n",
    "    ax[0,1].plot(theta[j][0], theta[j][1], marker=\"x\", color=\"r\")\n",
    "    ax[0,1].pcolormesh(X.cpu().numpy(), Y.cpu().numpy(), Z.cpu().exp().numpy())\n",
    "    ax[0,1].set_title('Approximate Posterior Flow')\n",
    "\n",
    "    remaining_spots = nrows * ncols - 2\n",
    "    for k in range(remaining_spots):\n",
    "        coverage_guarantee = 0.1 * (k + 1)\n",
    "        qhat = np.quantile(cal_scores, q = coverage_guarantee)\n",
    "        prob_min = 1 / qhat\n",
    "\n",
    "        graphic_idx = k + 2\n",
    "        row_idx = graphic_idx // ncols\n",
    "        col_idx = graphic_idx - row_idx * ncols\n",
    "\n",
    "        prediction_interval = (Z.cpu().exp().numpy() > prob_min).astype(\"bool\")\n",
    "        \n",
    "        # find corresponding indices of matrix for lookup: have to invert y convention, since down is positive in index\n",
    "        ax[row_idx,col_idx].plot(theta[j][0], theta[j][1], marker=\"x\", color=\"r\")\n",
    "        ax[row_idx,col_idx].pcolormesh(X.cpu().numpy(), Y.cpu().numpy(), prediction_interval)\n",
    "        ax[row_idx,col_idx].set_title(f'Conformalized Posterior: q={coverage_guarantee}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955455ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x2400 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(j=5, x=test_x, theta=test_theta, encoder=encoder, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_coverage(coverage_trials = 1000, num_coverage_pts = 20):\n",
    "    empirical_coverages = np.zeros(num_coverage_pts)\n",
    "    variational_coverages = np.zeros(num_coverage_pts)\n",
    "    desired_coverages = [(1 / num_coverage_pts) * (k + 1) for k in range(num_coverage_pts)]\n",
    "    quantiles = np.array([1 / np.quantile(cal_scores, q = coverage) for coverage in desired_coverages])\n",
    "    \n",
    "    for j in range(coverage_trials):\n",
    "        predicted_lps = encoder.log_prob(test_theta[j].view(1,-1).to(device), test_x[j].view(1,-1).to(device)).detach()\n",
    "        predicted_prob = predicted_lps.cpu().exp().numpy()\n",
    "        empirical_coverages += predicted_prob > quantiles\n",
    "\n",
    "        empirical_theta_dist = encoder.sample(10_000, test_x[j].view(1,-1).to(device)).cpu().detach().numpy()[0]\n",
    "        for k, desired_coverage in enumerate(desired_coverages):\n",
    "            alpha = (1 - desired_coverage) / 2\n",
    "            lower_quantile = np.quantile(empirical_theta_dist, q = alpha, axis=0)\n",
    "            upper_quantile = np.quantile(empirical_theta_dist, q = 1 - alpha, axis=0)\n",
    "            variational_coverages[k] += int(\n",
    "                np.all(lower_quantile <= test_theta[j].cpu().detach().numpy()) and \n",
    "                np.all(test_theta[j].cpu().detach().numpy() <= upper_quantile)\n",
    "            )\n",
    "\n",
    "    return empirical_coverages / coverage_trials, variational_coverages / coverage_trials, desired_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efab282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_coverages, variational_coverages, desired_coverages = assess_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29ba4831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Desired vs. Empirical Coverage')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(desired_coverages, empirical_coverages, label=\"Empirical\")\n",
    "plt.plot(variational_coverages, empirical_coverages, label=\"Variational\")\n",
    "plt.plot(desired_coverages, desired_coverages, label=\"Desired\")\n",
    "plt.legend()\n",
    "plt.title(\"Desired vs. Empirical Coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac521a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "025fdf49e09ee838b0c05e971129fbc14df70fae1b22b06a04398c8d66c2f675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
